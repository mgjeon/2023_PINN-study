{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from pinf.analytical_field import get_analytic_b_field\n",
    "from pinf.unpack import load_cube\n",
    "from pinf.plot import pv_plot\n",
    "from pinf.performance_metrics import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = get_analytic_b_field(n=1, m=1, l=0.3, psi=np.pi/2, resolution=64, bounds=[-1, 1, -1, 1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.72it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.12it/s]\n"
     ]
    }
   ],
   "source": [
    "pv_plot(b, vtk_path=f'./output/vtk/b.vtk', points=((16, 49, 8), (16, 49, 8)), title='LL', overwrite=True, imgpath=f'./output/plot/b.pdf')\n",
    "metrics(b, b, base_path=f'./output/eval/b.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.03it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.07it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.98it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.87it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.32it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.16it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.99it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.11it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.12it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.90it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.62it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.60it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.89it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.61it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.02it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.01it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.81it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.16it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.29it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.19it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.09it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.20it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.16it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.29it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.15it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.71it/s]\n",
      "Potential Field:  83%|████████▎ | 5/6 [00:01<00:00,  4.36it/s]ERROR: Unexpected segmentation fault encountered in worker.\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.17it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 39889) is killed by signal: Segmentation fault: 11. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m B \u001b[39m=\u001b[39m load_cube(f)\n\u001b[1;32m      4\u001b[0m pv_plot(B, vtk_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./output/vtk/\u001b[39m\u001b[39m{\u001b[39;00mtitle\u001b[39m}\u001b[39;00m\u001b[39m.vtk\u001b[39m\u001b[39m'\u001b[39m, points\u001b[39m=\u001b[39m((\u001b[39m16\u001b[39m, \u001b[39m49\u001b[39m, \u001b[39m8\u001b[39m), (\u001b[39m16\u001b[39m, \u001b[39m49\u001b[39m, \u001b[39m8\u001b[39m)), title\u001b[39m=\u001b[39mtitle, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, imgpath\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./output/plot/\u001b[39m\u001b[39m{\u001b[39;00mtitle\u001b[39m}\u001b[39;00m\u001b[39m.pdf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m metrics(B, b, base_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./output/eval/\u001b[39;49m\u001b[39m{\u001b[39;49;00mtitle\u001b[39m}\u001b[39;49;00m\u001b[39m.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Workspace/pinn_study/organize/pinf/performance_metrics.py:23\u001b[0m, in \u001b[0;36mmetrics\u001b[0;34m(B, b, base_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m E_m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m M \u001b[39m*\u001b[39m (vector_norm(B \u001b[39m-\u001b[39m b) \u001b[39m/\u001b[39m vector_norm(b))\u001b[39m.\u001b[39msum()\n\u001b[1;32m     21\u001b[0m eps \u001b[39m=\u001b[39m (vector_norm(B) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m (vector_norm(b) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[0;32m---> 23\u001b[0m B_potential \u001b[39m=\u001b[39m get_potential(B[:, :, \u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m], B\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     24\u001b[0m eps_p \u001b[39m=\u001b[39m (vector_norm(B) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m (vector_norm(B_potential) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     26\u001b[0m b_potential \u001b[39m=\u001b[39m get_potential(b[:, :, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m], b\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Workspace/pinn_study/organize/pinf/potential_field.py:47\u001b[0m, in \u001b[0;36mget_potential\u001b[0;34m(b_n, height, batch_size, strides, progress)\u001b[0m\n\u001b[1;32m     45\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(TensorDataset(coords), batch_size\u001b[39m=\u001b[39mbatch_size, num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[1;32m     46\u001b[0m it \u001b[39m=\u001b[39m tqdm(loader, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPotential Field\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m progress \u001b[39melse\u001b[39;00m loader\n\u001b[0;32m---> 47\u001b[0m \u001b[39mfor\u001b[39;00m coord, \u001b[39min\u001b[39;00m it:\n\u001b[1;32m     48\u001b[0m     coord \u001b[39m=\u001b[39m coord\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     49\u001b[0m     p_batch \u001b[39m=\u001b[39m model(coord)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1318\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \n\u001b[1;32m   1323\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1443\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1439\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1443\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1444\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1445\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[39massert\u001b[39;00m callable(previous_handler)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 39889) is killed by signal: Segmentation fault: 11. "
     ]
    }
   ],
   "source": [
    "for f in sorted(glob.glob('run/dim256_bin1_pfTrue_ld0.1_lf0.1/fields_*.nf2')):\n",
    "    title = 'PINN' + '_' + os.path.basename(f).split('.')[0][7:]\n",
    "    B = load_cube(f)\n",
    "    pv_plot(B, vtk_path=f'./output/vtk/{title}.vtk', points=((16, 49, 8), (16, 49, 8)), title=title, overwrite=True, imgpath=f'./output/plot/{title}.pdf')\n",
    "    metrics(B, b, base_path=f'./output/eval/{title}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
