{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvtk.api import tvtk, write_data\n",
    "import pyvista as pv \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def pv_plot(B, vtk_path='./evaluation.vtk', points=((7, 64, 8), (7, 64, 8)), title='LL', overwrite=False):\n",
    "\n",
    "    if not os.path.exists(vtk_path) or overwrite:\n",
    "        dim = B.shape[:-1]\n",
    "        pts = np.stack(np.mgrid[0:dim[0], 0:dim[1], 0:dim[2]], -1).astype(np.float32)\n",
    "        pts = pts.transpose(2, 1, 0, 3)\n",
    "        pts = pts.reshape((-1, 3))\n",
    "        vectors = B.transpose(2, 1, 0, 3)\n",
    "        vectors = vectors.reshape((-1, 3))\n",
    "        sg = tvtk.StructuredGrid(dimensions=dim, points=pts)\n",
    "        sg.point_data.vectors = vectors\n",
    "        sg.point_data.vectors.name = 'B'\n",
    "        write_data(sg, str(vtk_path))\n",
    "\n",
    "    mesh = pv.read(vtk_path)\n",
    "    xindmax, yindmax, zindmax = mesh.dimensions\n",
    "    xcenter, ycenter, zcenter = mesh.center\n",
    "\n",
    "    p = pv.Plotter()\n",
    "    p.add_mesh(mesh.outline())\n",
    "\n",
    "    sargs_B = dict(\n",
    "        title='Bz [G]',\n",
    "        title_font_size=15,\n",
    "        height=0.25,\n",
    "        width=0.05,\n",
    "        vertical=True,\n",
    "        position_x = 0.05,\n",
    "        position_y = 0.05,\n",
    "    )\n",
    "    dargs_B = dict(\n",
    "        scalars='B', \n",
    "        component=2, \n",
    "        clim=(-150, 150), \n",
    "        scalar_bar_args=sargs_B, \n",
    "        show_scalar_bar=False, \n",
    "        lighting=False\n",
    "    )\n",
    "    p.add_mesh(mesh.extract_subset((0, xindmax, 0, yindmax, 0, 0)), \n",
    "            cmap='gray', **dargs_B)\n",
    "\n",
    "    def draw_streamlines(pts):\n",
    "        stream, src = mesh.streamlines(\n",
    "            return_source=True,\n",
    "            start_position = pts,\n",
    "            integration_direction='both',\n",
    "            max_time=1000,\n",
    "        )\n",
    "        # print(pts)\n",
    "        key = pts[0]*pts[1] + (pts[0]//pts[1]) + (pts[0] - pts[1])\n",
    "        # print(key)\n",
    "        np.random.seed(key)\n",
    "        colors = np.random.rand(3)\n",
    "        # if pts[0] == 16 and pts[1] == 48:\n",
    "        #     colors = 'white'\n",
    "        # print(colors)\n",
    "        p.add_mesh(stream.tube(radius=0.2), lighting=False, color=colors)\n",
    "        p.add_mesh(src, point_size=7, color=colors)\n",
    "\n",
    "    xrange = points[0]\n",
    "    yrange = points[1]\n",
    "    for i in np.arange(*xrange):\n",
    "        for j in np.arange(*yrange):\n",
    "            try: \n",
    "                draw_streamlines((i, j, 0))\n",
    "            except:\n",
    "                print(i, j)\n",
    "\n",
    "    p.camera_position = 'xy'\n",
    "    p.show_bounds()\n",
    "    # p.add_title(title)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from pinf.metric import vector_norm, curl, divergence\n",
    "\n",
    "def metrics(B, b, B_potential, b_potential):\n",
    "    \"\"\"\n",
    "    B is the numerical solution\n",
    "    b is the reference magnetic field\n",
    "    \"\"\"\n",
    "\n",
    "    c_vec = np.sum((B * b).sum(-1)) / np.sqrt((B ** 2).sum(-1).sum() * (b ** 2).sum(-1).sum())\n",
    "\n",
    "    M = np.prod(B.shape[:-1])\n",
    "    c_cs = 1 / M * np.sum((B * b).sum(-1) / vector_norm(B) / vector_norm(b))\n",
    "\n",
    "    E_n = vector_norm(B - b).sum() / vector_norm(b).sum()\n",
    "\n",
    "    E_m = 1 / M * (vector_norm(B - b) / vector_norm(b)).sum()\n",
    "\n",
    "    eps = (vector_norm(B) ** 2).sum() / (vector_norm(b) ** 2).sum()\n",
    "\n",
    "    # B_potential = get_potential(B[:, :, 0, 2], B.shape[-1])\n",
    "    eps_p = (vector_norm(B) ** 2).sum() / (vector_norm(B_potential) ** 2).sum()\n",
    "\n",
    "    # b_potential = get_potential(b[:, :, 0, 2], b.shape[-1])\n",
    "    eps_p_b = (vector_norm(b) ** 2).sum() / (vector_norm(b_potential) ** 2).sum()\n",
    "\n",
    "    j = curl(B)\n",
    "    sig_J = (vector_norm(np.cross(j, B, -1)) / vector_norm(B)).sum() / vector_norm(j).sum()\n",
    "    L1 = (vector_norm(np.cross(j, B, -1)) ** 2 / vector_norm(B) ** 2).mean()\n",
    "    L2 = (divergence(B) ** 2).mean()\n",
    "\n",
    "    j_b = curl(b)\n",
    "    sig_J_b = (vector_norm(np.cross(j_b, b, -1)) / vector_norm(b)).sum() / vector_norm(j_b).sum()\n",
    "    L1_b = (vector_norm(np.cross(j_b, b, -1)) ** 2 / vector_norm(b) ** 2).mean()\n",
    "    L2_b = (divergence(b) ** 2).mean()\n",
    "\n",
    "    key = [\"C_vec\", \"C_cs\", \"1-En\", \"1-Em\", \"eps\", \"eps_p\", \"sig_J\", \"L1\", \"L2\", \"eps_p_b\", \"sig_J_b\", \"L1_b\", \"L2_b\"]\n",
    "    metric = [c_vec, c_cs, 1-E_n, 1-E_m, eps, eps_p, sig_J, L1, L2, eps_p_b, sig_J_b, L1_b, L2_b]\n",
    "    return dict(zip(key, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from pinf.analytical_field import get_analytic_b_field\n",
    "from pinf.unpack import load_cube\n",
    "from pinf.potential_field import get_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtk_path = './output/vtk'\n",
    "metric_path = './output/eval'\n",
    "plot_path = './output/plot'\n",
    "os.makedirs(vtk_path, exist_ok=True)\n",
    "os.makedirs(metric_path, exist_ok=True)\n",
    "os.makedirs(plot_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = get_analytic_b_field(n=1, m=1, l=0.3, psi=np.pi/2, resolution=64, bounds=[-1, 1, -1, 1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential Field: 100%|██████████| 6/6 [00:00<00:00, 19.29it/s]\n"
     ]
    }
   ],
   "source": [
    "b_potential = get_potential(b[:, :, 0, 2], b.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'LL'\n",
    "vtk_file = os.path.join(vtk_path, f'{title}.vtk')\n",
    "p = pv_plot(B=b, vtk_path=vtk_file, points=((16, 49, 8), (16, 49, 8)), title=title)\n",
    "\n",
    "p.camera_position = 'xy'\n",
    "p.save_graphic(os.path.join(plot_path, f'{title}_xy.pdf'))\n",
    "p.camera_position = 'yz'\n",
    "p.save_graphic(os.path.join(plot_path, f'{title}_yz.pdf'))\n",
    "p.camera_position = 'xz'\n",
    "p.save_graphic(os.path.join(plot_path, f'{title}_xz.pdf'))\n",
    "p.camera_position = 'xz'\n",
    "p.camera.azimuth = -30\n",
    "p.camera.elevation = 25\n",
    "p.save_graphic(os.path.join(plot_path, f'{title}_xz_tilted.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics(B=b, b=b, B_potential=b_potential, b_potential=b_potential)\n",
    "iterinfo = {'iter': -1}\n",
    "metric = {**iterinfo, **metric}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>C_vec</th>\n",
       "      <th>C_cs</th>\n",
       "      <th>1-En</th>\n",
       "      <th>1-Em</th>\n",
       "      <th>eps</th>\n",
       "      <th>eps_p</th>\n",
       "      <th>sig_J</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>eps_p_b</th>\n",
       "      <th>sig_J_b</th>\n",
       "      <th>L1_b</th>\n",
       "      <th>L2_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130138</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.130138</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  C_vec  C_cs  1-En  1-Em  eps     eps_p    sig_J        L1        L2   \n",
       "0    -1    1.0   1.0   1.0   1.0  1.0  0.130138  0.01308  0.002065  0.002024  \\\n",
       "\n",
       "    eps_p_b  sig_J_b      L1_b      L2_b  \n",
       "0  0.130138  0.01308  0.002065  0.002024  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict([metric])\n",
    "df.to_csv(os.path.join(metric_path, 'metric.csv'), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.03it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.07it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.98it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.87it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.32it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.16it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.99it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.11it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.12it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.90it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.62it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.60it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.89it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.61it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.02it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.01it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.81it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.16it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.29it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.19it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.09it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.20it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.16it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.29it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.15it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:02<00:00,  2.71it/s]\n",
      "Potential Field:  83%|████████▎ | 5/6 [00:01<00:00,  4.36it/s]ERROR: Unexpected segmentation fault encountered in worker.\n",
      "Potential Field: 100%|██████████| 6/6 [00:01<00:00,  3.17it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 39889) is killed by signal: Segmentation fault: 11. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m B \u001b[39m=\u001b[39m load_cube(f)\n\u001b[1;32m      4\u001b[0m pv_plot(B, vtk_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./output/vtk/\u001b[39m\u001b[39m{\u001b[39;00mtitle\u001b[39m}\u001b[39;00m\u001b[39m.vtk\u001b[39m\u001b[39m'\u001b[39m, points\u001b[39m=\u001b[39m((\u001b[39m16\u001b[39m, \u001b[39m49\u001b[39m, \u001b[39m8\u001b[39m), (\u001b[39m16\u001b[39m, \u001b[39m49\u001b[39m, \u001b[39m8\u001b[39m)), title\u001b[39m=\u001b[39mtitle, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, imgpath\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./output/plot/\u001b[39m\u001b[39m{\u001b[39;00mtitle\u001b[39m}\u001b[39;00m\u001b[39m.pdf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m metrics(B, b, base_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./output/eval/\u001b[39;49m\u001b[39m{\u001b[39;49;00mtitle\u001b[39m}\u001b[39;49;00m\u001b[39m.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Workspace/pinn_study/organize/pinf/performance_metrics.py:23\u001b[0m, in \u001b[0;36mmetrics\u001b[0;34m(B, b, base_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m E_m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m M \u001b[39m*\u001b[39m (vector_norm(B \u001b[39m-\u001b[39m b) \u001b[39m/\u001b[39m vector_norm(b))\u001b[39m.\u001b[39msum()\n\u001b[1;32m     21\u001b[0m eps \u001b[39m=\u001b[39m (vector_norm(B) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m (vector_norm(b) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[0;32m---> 23\u001b[0m B_potential \u001b[39m=\u001b[39m get_potential(B[:, :, \u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m], B\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     24\u001b[0m eps_p \u001b[39m=\u001b[39m (vector_norm(B) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m (vector_norm(B_potential) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     26\u001b[0m b_potential \u001b[39m=\u001b[39m get_potential(b[:, :, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m], b\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Workspace/pinn_study/organize/pinf/potential_field.py:47\u001b[0m, in \u001b[0;36mget_potential\u001b[0;34m(b_n, height, batch_size, strides, progress)\u001b[0m\n\u001b[1;32m     45\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(TensorDataset(coords), batch_size\u001b[39m=\u001b[39mbatch_size, num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[1;32m     46\u001b[0m it \u001b[39m=\u001b[39m tqdm(loader, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPotential Field\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m progress \u001b[39melse\u001b[39;00m loader\n\u001b[0;32m---> 47\u001b[0m \u001b[39mfor\u001b[39;00m coord, \u001b[39min\u001b[39;00m it:\n\u001b[1;32m     48\u001b[0m     coord \u001b[39m=\u001b[39m coord\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     49\u001b[0m     p_batch \u001b[39m=\u001b[39m model(coord)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1318\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \n\u001b[1;32m   1323\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1443\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1439\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1443\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1444\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1445\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[39massert\u001b[39;00m callable(previous_handler)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 39889) is killed by signal: Segmentation fault: 11. "
     ]
    }
   ],
   "source": [
    "for file_path in sorted(glob.glob('run/dim256_bin1_pfTrue_ld0.1_lf0.1/fields_*.nf2')):\n",
    "    iters = os.path.basename(file_path).split('.')[0][7:]\n",
    "    title = 'PINN' + '_' + iters\n",
    "    B = load_cube(file_path)\n",
    "    vtk_file = os.path.join(vtk_path, f'{title}.vtk')\n",
    "    p = pv_plot(B=B, vtk_path=vtk_file, points=((16, 49, 8), (16, 49, 8)), title=title)\n",
    "    p.camera_position = 'xy'\n",
    "    p.save_graphic(os.path.join(plot_path, f'{title}_xy.pdf'))\n",
    "    p.camera_position = 'yz'\n",
    "    p.save_graphic(os.path.join(plot_path, f'{title}_yz.pdf'))\n",
    "    p.camera_position = 'xz'\n",
    "    p.save_graphic(os.path.join(plot_path, f'{title}_xz.pdf'))\n",
    "    p.camera_position = 'xz'\n",
    "    p.camera.azimuth = -30\n",
    "    p.camera.elevation = 25\n",
    "    p.save_graphic(os.path.join(plot_path, f'{title}_xz_tilted.pdf'))\n",
    "\n",
    "    metric = metrics(B=B, b=b, B_potential=b_potential, b_potential=b_potential)\n",
    "    iterinfo = {'iter': int(iters)}\n",
    "    metric = {**iterinfo, **metric}\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame([metric])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
