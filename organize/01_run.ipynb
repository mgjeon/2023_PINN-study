{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from pinf.analytical_field import get_analytic_b_field\n",
    "from pinf.performance_metrics import metrics\n",
    "from pinf.trainer import NF2Trainer\n",
    "from pinf.unpack import load_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = get_analytic_b_field(n=1, m=1, l=0.3, psi=np.pi/2, resolution=64, bounds=[-1, 1, -1, 1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "dim: 256, lambda_div: 0.100000, lambda_ff: 0.100000, decay_iterations: 25000, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA GeForce RTX 3060']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "base_path = './run'\n",
    "meta_path = None\n",
    "\n",
    "bin = 1\n",
    "\n",
    "height = 64\n",
    "spatial_norm = 32\n",
    "b_norm = 100\n",
    "\n",
    "meta_info = None\n",
    "dim = 256\n",
    "positional_encoding = False\n",
    "use_potential_boundary = True\n",
    "potential_strides = 1\n",
    "use_vector_potential = False\n",
    "lambda_div = 1e-1\n",
    "lambda_ff = 1e-1\n",
    "decay_iterations = 25000\n",
    "device = None\n",
    "work_directory = None\n",
    "\n",
    "total_iterations = 50000\n",
    "batch_size = 10000\n",
    "log_interval = 100\n",
    "validation_interval = 1000\n",
    "num_workers = 4\n",
    "\n",
    "# init logging\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)\n",
    "for hdlr in log.handlers[:]:  # remove all old handlers\n",
    "    log.removeHandler(hdlr)\n",
    "log.addHandler(logging.FileHandler(\"{0}/{1}.log\".format(base_path, \"info_log\")))  # set the new file handler\n",
    "log.addHandler(logging.StreamHandler())  # set the new console handler\n",
    "\n",
    "base_path = os.path.join(base_path, 'dim%d_bin%d_pf%s_ld%s_lf%s' % (\n",
    "        dim, bin, str(use_potential_boundary), lambda_div, lambda_ff))\n",
    "\n",
    "b_cube = b[:, :, 0, :]\n",
    "\n",
    "trainer = NF2Trainer(base_path, b_cube, height, spatial_norm, b_norm, \n",
    "                     meta_info=meta_info, dim=dim, positional_encoding=positional_encoding, \n",
    "                     meta_path=meta_path, use_potential_boundary=use_potential_boundary, \n",
    "                     potential_strides=potential_strides, use_vector_potential=use_vector_potential,\n",
    "                     lambda_div=lambda_div, lambda_ff=lambda_ff, decay_iterations=decay_iterations,\n",
    "                     device=device, work_directory=work_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 99/50000 [00:13<1:52:08,  7.42it/s][Iteration 000100/050000] [BC: 0.03243637; Div: 0.00004523; For: 0.00074829] [0:00:13.806674]\n",
      "Lambda B: 972.747224\n",
      "LR: 0.000498\n",
      "Training:   0%|          | 199/50000 [00:27<1:52:14,  7.39it/s][Iteration 000200/050000] [BC: 0.03159330; Div: 0.00057075; For: 0.00402706] [0:00:28.134830]\n",
      "Lambda B: 946.237161\n",
      "LR: 0.000495\n",
      "Training:   1%|          | 299/50000 [00:42<1:51:51,  7.40it/s][Iteration 000300/050000] [BC: 0.03076068; Div: 0.00214445; For: 0.00919786] [0:00:42.469103]\n",
      "Lambda B: 920.449572\n",
      "LR: 0.000493\n",
      "Training:   1%|          | 399/50000 [00:56<1:53:17,  7.30it/s][Iteration 000400/050000] [BC: 0.02959176; Div: 0.00929697; For: 0.02268718] [0:00:56.690517]\n",
      "Lambda B: 895.364766\n",
      "LR: 0.000491\n",
      "Training:   1%|          | 499/50000 [01:10<1:52:02,  7.36it/s][Iteration 000500/050000] [BC: 0.02820952; Div: 0.01205610; For: 0.03572670] [0:01:11.069107]\n",
      "Lambda B: 870.963590\n",
      "LR: 0.000489\n",
      "Training:   1%|          | 599/50000 [01:25<1:48:48,  7.57it/s][Iteration 000600/050000] [BC: 0.02667167; Div: 0.01067095; For: 0.06694973] [0:01:25.299071]\n",
      "Lambda B: 847.227414\n",
      "LR: 0.000486\n",
      "Training:   1%|▏         | 699/50000 [01:38<1:49:09,  7.53it/s][Iteration 000700/050000] [BC: 0.02482068; Div: 0.02638825; For: 0.10805158] [0:01:39.210604]\n",
      "Lambda B: 824.138115\n",
      "LR: 0.000484\n",
      "Training:   2%|▏         | 799/50000 [01:53<1:55:06,  7.12it/s][Iteration 000800/050000] [BC: 0.02021292; Div: 0.14409816; For: 0.21752813] [0:01:53.704604]\n",
      "Lambda B: 801.678063\n",
      "LR: 0.000482\n",
      "Training:   2%|▏         | 899/50000 [02:08<1:48:52,  7.52it/s][Iteration 000900/050000] [BC: 0.01361890; Div: 0.22619654; For: 0.49392787] [0:02:08.390020]\n",
      "Lambda B: 779.830111\n",
      "LR: 0.000480\n",
      "Training:   2%|▏         | 999/50000 [02:22<1:51:33,  7.32it/s][Iteration 001000/050000] [BC: 0.00952264; Div: 0.34123015; For: 0.71646738] [0:02:22.500177]\n",
      "Lambda B: 758.577575\n",
      "LR: 0.000477\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.01it/s]\n",
      "Validation [Cube: BC: 13.558; Div: 0.096; For: 1.411; Sig: 52.104]\n",
      "Training:   2%|▏         | 1099/50000 [02:37<1:50:44,  7.36it/s][Iteration 001100/050000] [BC: 0.00675561; Div: 0.39820307; For: 0.75373369] [0:02:37.585212]\n",
      "Lambda B: 737.904230\n",
      "LR: 0.000475\n",
      "Training:   2%|▏         | 1199/50000 [02:51<1:50:53,  7.33it/s][Iteration 001200/050000] [BC: 0.00527073; Div: 0.42213723; For: 0.69395471] [0:02:52.189458]\n",
      "Lambda B: 717.794291\n",
      "LR: 0.000473\n",
      "Training:   3%|▎         | 1299/50000 [03:06<1:51:13,  7.30it/s][Iteration 001300/050000] [BC: 0.00412693; Div: 0.47036117; For: 0.64744109] [0:03:06.590749]\n",
      "Lambda B: 698.232404\n",
      "LR: 0.000471\n",
      "Training:   3%|▎         | 1399/50000 [03:21<1:50:17,  7.34it/s][Iteration 001400/050000] [BC: 0.00320249; Div: 0.50383455; For: 0.63851094] [0:03:21.270922]\n",
      "Lambda B: 679.203633\n",
      "LR: 0.000469\n",
      "Training:   3%|▎         | 1499/50000 [03:35<1:50:28,  7.32it/s][Iteration 001500/050000] [BC: 0.00293372; Div: 0.52663684; For: 0.63340801] [0:03:35.929161]\n",
      "Lambda B: 660.693448\n",
      "LR: 0.000467\n",
      "Training:   3%|▎         | 1599/50000 [03:50<1:49:47,  7.35it/s][Iteration 001600/050000] [BC: 0.00182111; Div: 0.57514453; For: 0.63241941] [0:03:50.234100]\n",
      "Lambda B: 642.687717\n",
      "LR: 0.000464\n",
      "Training:   3%|▎         | 1699/50000 [04:04<1:50:02,  7.32it/s][Iteration 001700/050000] [BC: 0.00156720; Div: 0.57647115; For: 0.64718229] [0:04:04.551107]\n",
      "Lambda B: 625.172693\n",
      "LR: 0.000462\n",
      "Training:   4%|▎         | 1799/50000 [04:19<1:50:57,  7.24it/s][Iteration 001800/050000] [BC: 0.00101710; Div: 0.59413767; For: 0.60814726] [0:04:19.448896]\n",
      "Lambda B: 608.135001\n",
      "LR: 0.000460\n",
      "Training:   4%|▍         | 1899/50000 [04:33<1:49:13,  7.34it/s][Iteration 001900/050000] [BC: 0.00120214; Div: 0.56580687; For: 0.58570617] [0:04:33.738639]\n",
      "Lambda B: 591.561634\n",
      "LR: 0.000458\n",
      "Training:   4%|▍         | 1999/50000 [04:48<1:49:06,  7.33it/s][Iteration 002000/050000] [BC: 0.00088968; Div: 0.56573594; For: 0.58147496] [0:04:48.448581]\n",
      "Lambda B: 575.439937\n",
      "LR: 0.000456\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.51it/s]\n",
      "Validation [Cube: BC: 3.474; Div: 0.107; For: 0.855; Sig: 43.177]\n",
      "Training:   4%|▍         | 2099/50000 [05:03<1:49:01,  7.32it/s][Iteration 002100/050000] [BC: 0.00055277; Div: 0.49935800; For: 0.54300654] [0:05:03.541728]\n",
      "Lambda B: 559.757601\n",
      "LR: 0.000454\n",
      "Training:   4%|▍         | 2199/50000 [05:17<1:49:21,  7.28it/s][Iteration 002200/050000] [BC: 0.00065579; Div: 0.48035961; For: 0.52116615] [0:05:17.916494]\n",
      "Lambda B: 544.502653\n",
      "LR: 0.000452\n",
      "Training:   5%|▍         | 2299/50000 [05:32<1:49:25,  7.27it/s][Iteration 002300/050000] [BC: 0.00065180; Div: 0.45366287; For: 0.50081193] [0:05:32.316782]\n",
      "Lambda B: 529.663444\n",
      "LR: 0.000450\n",
      "Training:   5%|▍         | 2399/50000 [05:47<1:58:38,  6.69it/s][Iteration 002400/050000] [BC: 0.00048350; Div: 0.47391972; For: 0.51169509] [0:05:47.318727]\n",
      "Lambda B: 515.228645\n",
      "LR: 0.000448\n",
      "Training:   5%|▍         | 2499/50000 [06:01<1:51:12,  7.12it/s][Iteration 002500/050000] [BC: 0.00057728; Div: 0.42056504; For: 0.47957191] [0:06:01.990329]\n",
      "Lambda B: 501.187234\n",
      "LR: 0.000446\n",
      "Training:   5%|▌         | 2599/50000 [06:17<1:58:25,  6.67it/s][Iteration 002600/050000] [BC: 0.00066028; Div: 0.45388833; For: 0.50025463] [0:06:17.423246]\n",
      "Lambda B: 487.528490\n",
      "LR: 0.000444\n",
      "Training:   5%|▌         | 2699/50000 [06:31<1:48:14,  7.28it/s][Iteration 002700/050000] [BC: 0.00028865; Div: 0.39437646; For: 0.44337529] [0:06:31.862167]\n",
      "Lambda B: 474.241985\n",
      "LR: 0.000442\n",
      "Training:   6%|▌         | 2799/50000 [06:46<1:48:03,  7.28it/s][Iteration 002800/050000] [BC: 0.00048000; Div: 0.35863784; For: 0.43045905] [0:06:46.251321]\n",
      "Lambda B: 461.317575\n",
      "LR: 0.000440\n",
      "Training:   6%|▌         | 2899/50000 [07:00<1:48:07,  7.26it/s][Iteration 002900/050000] [BC: 0.00057558; Div: 0.37010098; For: 0.44761062] [0:07:00.647776]\n",
      "Lambda B: 448.745390\n",
      "LR: 0.000437\n",
      "Training:   6%|▌         | 2999/50000 [07:14<1:47:27,  7.29it/s][Iteration 003000/050000] [BC: 0.00032975; Div: 0.35985684; For: 0.42757374] [0:07:15.019630]\n",
      "Lambda B: 436.515832\n",
      "LR: 0.000435\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 65.89it/s]\n",
      "Validation [Cube: BC: 2.282; Div: 0.108; For: 0.712; Sig: 47.807]\n",
      "Training:   6%|▌         | 3099/50000 [07:30<1:47:29,  7.27it/s] [Iteration 003100/050000] [BC: 0.00034165; Div: 0.31114957; For: 0.38569352] [0:07:31.121046]\n",
      "Lambda B: 424.619564\n",
      "LR: 0.000433\n",
      "Training:   6%|▋         | 3199/50000 [07:45<1:47:16,  7.27it/s][Iteration 003200/050000] [BC: 0.00041609; Div: 0.31704599; For: 0.38888001] [0:07:45.526607]\n",
      "Lambda B: 413.047502\n",
      "LR: 0.000431\n",
      "Training:   7%|▋         | 3299/50000 [07:59<1:47:05,  7.27it/s][Iteration 003300/050000] [BC: 0.00049200; Div: 0.31406224; For: 0.39115193] [0:07:59.941157]\n",
      "Lambda B: 401.790811\n",
      "LR: 0.000430\n",
      "Training:   7%|▋         | 3399/50000 [08:14<1:46:53,  7.27it/s][Iteration 003400/050000] [BC: 0.00036974; Div: 0.30319709; For: 0.37263247] [0:08:14.333466]\n",
      "Lambda B: 390.840896\n",
      "LR: 0.000428\n",
      "Training:   7%|▋         | 3499/50000 [08:28<1:46:34,  7.27it/s][Iteration 003500/050000] [BC: 0.00025654; Div: 0.29444024; For: 0.34745225] [0:08:28.732300]\n",
      "Lambda B: 380.189396\n",
      "LR: 0.000426\n",
      "Training:   7%|▋         | 3599/50000 [08:42<1:46:18,  7.27it/s][Iteration 003600/050000] [BC: 0.00028522; Div: 0.26306495; For: 0.32431954] [0:08:43.123740]\n",
      "Lambda B: 369.828180\n",
      "LR: 0.000424\n",
      "Training:   7%|▋         | 3699/50000 [08:57<1:46:03,  7.28it/s][Iteration 003700/050000] [BC: 0.00022636; Div: 0.25545329; For: 0.32755700] [0:08:57.519629]\n",
      "Lambda B: 359.749335\n",
      "LR: 0.000422\n",
      "Training:   8%|▊         | 3799/50000 [09:12<1:45:48,  7.28it/s][Iteration 003800/050000] [BC: 0.00023501; Div: 0.23472969; For: 0.31516051] [0:09:12.669128]\n",
      "Lambda B: 349.945167\n",
      "LR: 0.000420\n",
      "Training:   8%|▊         | 3899/50000 [09:26<1:45:36,  7.28it/s][Iteration 003900/050000] [BC: 0.00043500; Div: 0.25823575; For: 0.32301098] [0:09:27.068952]\n",
      "Lambda B: 340.408190\n",
      "LR: 0.000418\n",
      "Training:   8%|▊         | 3999/50000 [09:41<1:45:28,  7.27it/s][Iteration 004000/050000] [BC: 0.00022632; Div: 0.23647261; For: 0.30508685] [0:09:41.489470]\n",
      "Lambda B: 331.131121\n",
      "LR: 0.000416\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.00it/s]\n",
      "Validation [Cube: BC: 1.685; Div: 0.111; For: 0.555; Sig: 46.751]\n",
      "Training:   8%|▊         | 4099/50000 [09:56<1:44:16,  7.34it/s][Iteration 004100/050000] [BC: 0.00016943; Div: 0.19878569; For: 0.27303442] [0:09:57.004144]\n",
      "Lambda B: 322.106879\n",
      "LR: 0.000414\n",
      "Training:   8%|▊         | 4199/50000 [10:11<1:44:04,  7.33it/s][Iteration 004200/050000] [BC: 0.00021510; Div: 0.19772452; For: 0.26160949] [0:10:11.301157]\n",
      "Lambda B: 313.328572\n",
      "LR: 0.000412\n",
      "Training:   9%|▊         | 4299/50000 [10:25<1:43:57,  7.33it/s][Iteration 004300/050000] [BC: 0.00027036; Div: 0.21002360; For: 0.26487386] [0:10:25.628785]\n",
      "Lambda B: 304.789499\n",
      "LR: 0.000410\n",
      "Training:   9%|▉         | 4399/50000 [10:39<1:43:35,  7.34it/s][Iteration 004400/050000] [BC: 0.00013155; Div: 0.18123080; For: 0.22931220] [0:10:39.920674]\n",
      "Lambda B: 296.483139\n",
      "LR: 0.000408\n",
      "Training:   9%|▉         | 4499/50000 [10:53<1:43:32,  7.32it/s][Iteration 004500/050000] [BC: 0.00022040; Div: 0.16728130; For: 0.21380883] [0:10:54.219373]\n",
      "Lambda B: 288.403150\n",
      "LR: 0.000406\n",
      "Training:   9%|▉         | 4599/50000 [11:08<1:43:53,  7.28it/s][Iteration 004600/050000] [BC: 0.00034089; Div: 0.17200938; For: 0.21891360] [0:11:08.528861]\n",
      "Lambda B: 280.543364\n",
      "LR: 0.000405\n",
      "Training:   9%|▉         | 4699/50000 [11:23<1:42:49,  7.34it/s][Iteration 004700/050000] [BC: 0.00018798; Div: 0.15675052; For: 0.21043974] [0:11:23.755165]\n",
      "Lambda B: 272.897778\n",
      "LR: 0.000403\n",
      "Training:  10%|▉         | 4799/50000 [11:37<1:42:40,  7.34it/s][Iteration 004800/050000] [BC: 0.00012671; Div: 0.13285649; For: 0.18807793] [0:11:38.052229]\n",
      "Lambda B: 265.460556\n",
      "LR: 0.000401\n",
      "Training:  10%|▉         | 4899/50000 [11:52<1:42:46,  7.31it/s][Iteration 004900/050000] [BC: 0.00018699; Div: 0.12886663; For: 0.17792177] [0:11:52.338776]\n",
      "Lambda B: 258.226019\n",
      "LR: 0.000399\n",
      "Training:  10%|▉         | 4999/50000 [12:06<1:43:08,  7.27it/s][Iteration 005000/050000] [BC: 0.00013391; Div: 0.12421192; For: 0.15344870] [0:12:06.673313]\n",
      "Lambda B: 251.188643\n",
      "LR: 0.000397\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 65.51it/s]\n",
      "Validation [Cube: BC: 2.368; Div: 0.086; For: 0.413; Sig: 43.523]\n",
      "Training:  10%|█         | 5099/50000 [12:21<1:42:01,  7.33it/s][Iteration 005100/050000] [BC: 0.00033621; Div: 0.13534889; For: 0.18315683] [0:12:21.744285]\n",
      "Lambda B: 244.343055\n",
      "LR: 0.000395\n",
      "Training:  10%|█         | 5199/50000 [12:35<1:41:47,  7.34it/s][Iteration 005200/050000] [BC: 0.00031622; Div: 0.12755346; For: 0.17340477] [0:12:36.020205]\n",
      "Lambda B: 237.684029\n",
      "LR: 0.000394\n",
      "Training:  11%|█         | 5299/50000 [12:50<1:41:42,  7.33it/s][Iteration 005300/050000] [BC: 0.00013139; Div: 0.10755549; For: 0.14775020] [0:12:50.310378]\n",
      "Lambda B: 231.206479\n",
      "LR: 0.000392\n",
      "Training:  11%|█         | 5399/50000 [13:04<1:41:11,  7.35it/s][Iteration 005400/050000] [BC: 0.00021684; Div: 0.09857927; For: 0.13562378] [0:13:04.589968]\n",
      "Lambda B: 224.905461\n",
      "LR: 0.000390\n",
      "Training:  11%|█         | 5499/50000 [13:18<1:41:15,  7.33it/s][Iteration 005500/050000] [BC: 0.00022135; Div: 0.09222881; For: 0.13124268] [0:13:18.887437]\n",
      "Lambda B: 218.776162\n",
      "LR: 0.000388\n",
      "Training:  11%|█         | 5599/50000 [13:32<1:40:42,  7.35it/s][Iteration 005600/050000] [BC: 0.00026998; Div: 0.08869768; For: 0.12594257] [0:13:33.179680]\n",
      "Lambda B: 212.813905\n",
      "LR: 0.000386\n",
      "Training:  11%|█▏        | 5699/50000 [13:47<1:40:42,  7.33it/s][Iteration 005700/050000] [BC: 0.00013034; Div: 0.07330030; For: 0.11201032] [0:13:47.453773]\n",
      "Lambda B: 207.014135\n",
      "LR: 0.000385\n",
      "Training:  12%|█▏        | 5799/50000 [14:02<1:40:17,  7.35it/s][Iteration 005800/050000] [BC: 0.00021965; Div: 0.06282042; For: 0.09769651] [0:14:02.862389]\n",
      "Lambda B: 201.372425\n",
      "LR: 0.000383\n",
      "Training:  12%|█▏        | 5899/50000 [14:16<1:40:12,  7.34it/s][Iteration 005900/050000] [BC: 0.00012566; Div: 0.06054423; For: 0.09664302] [0:14:17.147689]\n",
      "Lambda B: 195.884467\n",
      "LR: 0.000381\n",
      "Training:  12%|█▏        | 5999/50000 [14:31<1:43:02,  7.12it/s][Iteration 006000/050000] [BC: 0.00016325; Div: 0.05010488; For: 0.08383270] [0:14:31.540148]\n",
      "Lambda B: 190.546072\n",
      "LR: 0.000379\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 64.76it/s]\n",
      "Validation [Cube: BC: 2.409; Div: 0.080; For: 0.298; Sig: 38.985]\n",
      "Training:  12%|█▏        | 6099/50000 [14:46<1:40:33,  7.28it/s][Iteration 006100/050000] [BC: 0.00019678; Div: 0.05172634; For: 0.08567013] [0:14:46.793193]\n",
      "Lambda B: 185.353162\n",
      "LR: 0.000378\n",
      "Training:  12%|█▏        | 6199/50000 [15:00<1:39:29,  7.34it/s][Iteration 006200/050000] [BC: 0.00010420; Div: 0.04128310; For: 0.07016531] [0:15:01.108439]\n",
      "Lambda B: 180.301774\n",
      "LR: 0.000376\n",
      "Training:  13%|█▎        | 6299/50000 [15:15<1:39:54,  7.29it/s][Iteration 006300/050000] [BC: 0.00013413; Div: 0.03498630; For: 0.06085506] [0:15:15.392392]\n",
      "Lambda B: 175.388050\n",
      "LR: 0.000374\n",
      "Training:  13%|█▎        | 6399/50000 [15:29<1:38:50,  7.35it/s][Iteration 006400/050000] [BC: 0.00020198; Div: 0.03736171; For: 0.06373861] [0:15:29.676914]\n",
      "Lambda B: 170.608239\n",
      "LR: 0.000372\n",
      "Training:  13%|█▎        | 6499/50000 [15:43<1:38:48,  7.34it/s][Iteration 006500/050000] [BC: 0.00010149; Div: 0.03202586; For: 0.05191212] [0:15:43.951820]\n",
      "Lambda B: 165.958691\n",
      "LR: 0.000371\n",
      "Training:  13%|█▎        | 6599/50000 [15:58<1:38:29,  7.34it/s][Iteration 006600/050000] [BC: 0.00008801; Div: 0.02500891; For: 0.04101712] [0:15:58.258805]\n",
      "Lambda B: 161.435856\n",
      "LR: 0.000369\n",
      "Training:  13%|█▎        | 6699/50000 [16:12<1:38:43,  7.31it/s][Iteration 006700/050000] [BC: 0.00016282; Div: 0.02457024; For: 0.04012094] [0:16:12.553742]\n",
      "Lambda B: 157.036280\n",
      "LR: 0.000367\n",
      "Training:  14%|█▎        | 6799/50000 [16:26<1:38:09,  7.34it/s][Iteration 006800/050000] [BC: 0.00023137; Div: 0.02999382; For: 0.04698202] [0:16:26.844534]\n",
      "Lambda B: 152.756606\n",
      "LR: 0.000366\n",
      "Training:  14%|█▍        | 6899/50000 [16:40<1:37:59,  7.33it/s][Iteration 006900/050000] [BC: 0.00010978; Div: 0.02390370; For: 0.03525358] [0:16:41.134778]\n",
      "Lambda B: 148.593564\n",
      "LR: 0.000364\n",
      "Training:  14%|█▍        | 6999/50000 [16:55<1:38:46,  7.26it/s][Iteration 007000/050000] [BC: 0.00008607; Div: 0.01952455; For: 0.02915237] [0:16:55.522366]\n",
      "Lambda B: 144.543977\n",
      "LR: 0.000362\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.20it/s]\n",
      "Validation [Cube: BC: 1.138; Div: 0.067; For: 0.208; Sig: 29.789]\n",
      "Training:  14%|█▍        | 7099/50000 [17:10<1:38:22,  7.27it/s][Iteration 007100/050000] [BC: 0.00012459; Div: 0.01806164; For: 0.02773136] [0:17:10.636354]\n",
      "Lambda B: 140.604752\n",
      "LR: 0.000361\n",
      "Training:  14%|█▍        | 7199/50000 [17:26<1:37:53,  7.29it/s][Iteration 007200/050000] [BC: 0.00007819; Div: 0.01613145; For: 0.02363855] [0:17:26.487177]\n",
      "Lambda B: 136.772883\n",
      "LR: 0.000359\n",
      "Training:  15%|█▍        | 7299/50000 [17:40<1:37:41,  7.28it/s][Iteration 007300/050000] [BC: 0.00007140; Div: 0.01371257; For: 0.01835112] [0:17:40.868950]\n",
      "Lambda B: 133.045442\n",
      "LR: 0.000357\n",
      "Training:  15%|█▍        | 7399/50000 [17:55<1:37:44,  7.26it/s][Iteration 007400/050000] [BC: 0.00018380; Div: 0.01743633; For: 0.02415767] [0:17:55.259833]\n",
      "Lambda B: 129.419584\n",
      "LR: 0.000356\n",
      "Training:  15%|█▍        | 7499/50000 [18:09<1:37:22,  7.27it/s][Iteration 007500/050000] [BC: 0.00018497; Div: 0.01877498; For: 0.02529578] [0:18:09.637838]\n",
      "Lambda B: 125.892541\n",
      "LR: 0.000354\n",
      "Training:  15%|█▌        | 7599/50000 [18:23<1:37:02,  7.28it/s][Iteration 007600/050000] [BC: 0.00014061; Div: 0.01515790; For: 0.02159518] [0:18:24.021063]\n",
      "Lambda B: 122.461620\n",
      "LR: 0.000352\n",
      "Training:  15%|█▌        | 7699/50000 [18:38<1:36:49,  7.28it/s][Iteration 007700/050000] [BC: 0.00006902; Div: 0.01089799; For: 0.01607479] [0:18:38.401033]\n",
      "Lambda B: 119.124201\n",
      "LR: 0.000351\n",
      "Training:  16%|█▌        | 7799/50000 [18:52<1:36:48,  7.27it/s][Iteration 007800/050000] [BC: 0.00006316; Div: 0.00940110; For: 0.01357180] [0:18:52.787536]\n",
      "Lambda B: 115.877736\n",
      "LR: 0.000349\n",
      "Training:  16%|█▌        | 7899/50000 [19:06<1:36:13,  7.29it/s][Iteration 007900/050000] [BC: 0.00007358; Div: 0.00889227; For: 0.01238407] [0:19:07.150592]\n",
      "Lambda B: 112.719746\n",
      "LR: 0.000348\n",
      "Training:  16%|█▌        | 7999/50000 [19:21<1:36:19,  7.27it/s][Iteration 008000/050000] [BC: 0.00005832; Div: 0.00790918; For: 0.01087872] [0:19:21.513001]\n",
      "Lambda B: 109.647820\n",
      "LR: 0.000346\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.65it/s]\n",
      "Validation [Cube: BC: 1.052; Div: 0.060; For: 0.151; Sig: 23.427]\n",
      "Training:  16%|█▌        | 8099/50000 [19:36<1:35:58,  7.28it/s][Iteration 008100/050000] [BC: 0.00013751; Div: 0.00932942; For: 0.01240537] [0:19:36.620539]\n",
      "Lambda B: 106.659612\n",
      "LR: 0.000344\n",
      "Training:  16%|█▋        | 8199/50000 [19:50<1:35:41,  7.28it/s][Iteration 008200/050000] [BC: 0.00016436; Div: 0.01108965; For: 0.01534197] [0:19:51.006962]\n",
      "Lambda B: 103.752842\n",
      "LR: 0.000343\n",
      "Training:  17%|█▋        | 8299/50000 [20:05<1:35:31,  7.28it/s][Iteration 008300/050000] [BC: 0.00006574; Div: 0.00745343; For: 0.01030977] [0:20:05.401618]\n",
      "Lambda B: 100.925289\n",
      "LR: 0.000341\n",
      "Training:  17%|█▋        | 8399/50000 [20:19<1:35:16,  7.28it/s][Iteration 008400/050000] [BC: 0.00016917; Div: 0.00911879; For: 0.01275677] [0:20:19.774276]\n",
      "Lambda B: 98.174794\n",
      "LR: 0.000340\n",
      "Training:  17%|█▋        | 8499/50000 [20:33<1:35:13,  7.26it/s][Iteration 008500/050000] [BC: 0.00006454; Div: 0.00658905; For: 0.00977184] [0:20:34.157053]\n",
      "Lambda B: 95.499259\n",
      "LR: 0.000338\n",
      "Training:  17%|█▋        | 8599/50000 [20:48<1:34:27,  7.30it/s][Iteration 008600/050000] [BC: 0.00005585; Div: 0.00567994; For: 0.00885808] [0:20:48.560791]\n",
      "Lambda B: 92.896639\n",
      "LR: 0.000336\n",
      "Training:  17%|█▋        | 8699/50000 [21:02<1:34:39,  7.27it/s][Iteration 008700/050000] [BC: 0.00006756; Div: 0.00529141; For: 0.00805406] [0:21:02.938161]\n",
      "Lambda B: 90.364947\n",
      "LR: 0.000335\n",
      "Training:  18%|█▊        | 8799/50000 [21:18<1:33:51,  7.32it/s][Iteration 008800/050000] [BC: 0.00017733; Div: 0.00839000; For: 0.01170111] [0:21:19.120434]\n",
      "Lambda B: 87.902252\n",
      "LR: 0.000333\n",
      "Training:  18%|█▊        | 8899/50000 [21:33<1:33:07,  7.36it/s][Iteration 008900/050000] [BC: 0.00007397; Div: 0.00526526; For: 0.00794689] [0:21:33.406959]\n",
      "Lambda B: 85.506671\n",
      "LR: 0.000332\n",
      "Training:  18%|█▊        | 8999/50000 [21:47<1:33:13,  7.33it/s][Iteration 009000/050000] [BC: 0.00009775; Div: 0.00546845; For: 0.00791938] [0:21:47.692190]\n",
      "Lambda B: 83.176377\n",
      "LR: 0.000330\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.23it/s]\n",
      "Validation [Cube: BC: 1.516; Div: 0.072; For: 0.125; Sig: 20.248]\n",
      "Training:  18%|█▊        | 9099/50000 [22:02<1:32:52,  7.34it/s][Iteration 009100/050000] [BC: 0.00009173; Div: 0.00508707; For: 0.00789235] [0:22:02.742653]\n",
      "Lambda B: 80.909590\n",
      "LR: 0.000329\n",
      "Training:  18%|█▊        | 9199/50000 [22:16<1:32:55,  7.32it/s][Iteration 009200/050000] [BC: 0.00004274; Div: 0.00387749; For: 0.00602374] [0:22:17.020889]\n",
      "Lambda B: 78.704579\n",
      "LR: 0.000327\n",
      "Training:  19%|█▊        | 9299/50000 [22:31<1:32:16,  7.35it/s][Iteration 009300/050000] [BC: 0.00010201; Div: 0.00504180; For: 0.00740610] [0:22:31.310909]\n",
      "Lambda B: 76.559661\n",
      "LR: 0.000326\n",
      "Training:  19%|█▉        | 9399/50000 [22:45<1:32:19,  7.33it/s][Iteration 009400/050000] [BC: 0.00008400; Div: 0.00409570; For: 0.00684130] [0:22:45.599771]\n",
      "Lambda B: 74.473197\n",
      "LR: 0.000324\n",
      "Training:  19%|█▉        | 9499/50000 [22:59<1:32:13,  7.32it/s][Iteration 009500/050000] [BC: 0.00004398; Div: 0.00335189; For: 0.00567841] [0:22:59.898586]\n",
      "Lambda B: 72.443596\n",
      "LR: 0.000323\n",
      "Training:  19%|█▉        | 9599/50000 [23:13<1:31:44,  7.34it/s][Iteration 009600/050000] [BC: 0.00004258; Div: 0.00307533; For: 0.00528576] [0:23:14.198584]\n",
      "Lambda B: 70.469307\n",
      "LR: 0.000321\n",
      "Training:  19%|█▉        | 9699/50000 [23:28<1:31:23,  7.35it/s][Iteration 009700/050000] [BC: 0.00006430; Div: 0.00327876; For: 0.00528553] [0:23:28.480887]\n",
      "Lambda B: 68.548823\n",
      "LR: 0.000320\n",
      "Training:  20%|█▉        | 9799/50000 [23:42<1:31:49,  7.30it/s][Iteration 009800/050000] [BC: 0.00007336; Div: 0.00363032; For: 0.00547249] [0:23:42.784305]\n",
      "Lambda B: 66.680677\n",
      "LR: 0.000318\n",
      "Training:  20%|█▉        | 9899/50000 [23:56<1:31:03,  7.34it/s][Iteration 009900/050000] [BC: 0.00008098; Div: 0.00343476; For: 0.00557433] [0:23:57.076295]\n",
      "Lambda B: 64.863443\n",
      "LR: 0.000317\n",
      "Training:  20%|█▉        | 9999/50000 [24:11<1:31:02,  7.32it/s][Iteration 010000/050000] [BC: 0.00009126; Div: 0.00331452; For: 0.00536585] [0:24:11.378029]\n",
      "Lambda B: 63.095734\n",
      "LR: 0.000315\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.48it/s]\n",
      "Validation [Cube: BC: 1.270; Div: 0.055; For: 0.100; Sig: 17.239]\n",
      "Training:  20%|██        | 10099/50000 [24:26<1:30:33,  7.34it/s][Iteration 010100/050000] [BC: 0.00006211; Div: 0.00283202; For: 0.00452683] [0:24:26.397014]\n",
      "Lambda B: 61.376201\n",
      "LR: 0.000314\n",
      "Training:  20%|██        | 10199/50000 [24:40<1:30:24,  7.34it/s][Iteration 010200/050000] [BC: 0.00007529; Div: 0.00300540; For: 0.00473104] [0:24:40.696954]\n",
      "Lambda B: 59.703529\n",
      "LR: 0.000313\n",
      "Training:  21%|██        | 10299/50000 [24:54<1:30:10,  7.34it/s][Iteration 010300/050000] [BC: 0.00004961; Div: 0.00240893; For: 0.00400814] [0:24:54.982107]\n",
      "Lambda B: 58.076442\n",
      "LR: 0.000311\n",
      "Training:  21%|██        | 10399/50000 [25:09<1:30:03,  7.33it/s][Iteration 010400/050000] [BC: 0.00004821; Div: 0.00230634; For: 0.00379076] [0:25:09.279445]\n",
      "Lambda B: 56.493697\n",
      "LR: 0.000310\n",
      "Training:  21%|██        | 10499/50000 [25:23<1:29:40,  7.34it/s][Iteration 010500/050000] [BC: 0.00003390; Div: 0.00211697; For: 0.00349308] [0:25:23.569492]\n",
      "Lambda B: 54.954087\n",
      "LR: 0.000308\n",
      "Training:  21%|██        | 10599/50000 [25:37<1:29:53,  7.30it/s][Iteration 010600/050000] [BC: 0.00003184; Div: 0.00201657; For: 0.00326698] [0:25:37.865758]\n",
      "Lambda B: 53.456436\n",
      "LR: 0.000307\n",
      "Training:  21%|██▏       | 10699/50000 [25:51<1:30:01,  7.28it/s][Iteration 010700/050000] [BC: 0.00004659; Div: 0.00209875; For: 0.00328292] [0:25:52.183468]\n",
      "Lambda B: 51.999600\n",
      "LR: 0.000305\n",
      "Training:  22%|██▏       | 10799/50000 [26:08<1:29:55,  7.27it/s] [Iteration 010800/050000] [BC: 0.00004386; Div: 0.00210120; For: 0.00322019] [0:26:08.845183]\n",
      "Lambda B: 50.582466\n",
      "LR: 0.000304\n",
      "Training:  22%|██▏       | 10899/50000 [26:22<1:29:12,  7.31it/s][Iteration 010900/050000] [BC: 0.00007154; Div: 0.00243724; For: 0.00366181] [0:26:23.171807]\n",
      "Lambda B: 49.203954\n",
      "LR: 0.000303\n",
      "Training:  22%|██▏       | 10999/50000 [26:37<1:28:30,  7.34it/s][Iteration 011000/050000] [BC: 0.00005045; Div: 0.00222475; For: 0.00330866] [0:26:37.455260]\n",
      "Lambda B: 47.863009\n",
      "LR: 0.000301\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.74it/s]\n",
      "Validation [Cube: BC: 0.727; Div: 0.043; For: 0.087; Sig: 14.659]\n",
      "Training:  22%|██▏       | 11099/50000 [26:52<1:28:25,  7.33it/s][Iteration 011100/050000] [BC: 0.00005940; Div: 0.00221096; For: 0.00345267] [0:26:52.503139]\n",
      "Lambda B: 46.558609\n",
      "LR: 0.000300\n",
      "Training:  22%|██▏       | 11199/50000 [27:06<1:27:57,  7.35it/s][Iteration 011200/050000] [BC: 0.00005744; Div: 0.00210979; For: 0.00333919] [0:27:06.781960]\n",
      "Lambda B: 45.289758\n",
      "LR: 0.000299\n",
      "Training:  23%|██▎       | 11299/50000 [27:20<1:27:48,  7.35it/s][Iteration 011300/050000] [BC: 0.00007172; Div: 0.00205172; For: 0.00339216] [0:27:21.089929]\n",
      "Lambda B: 44.055486\n",
      "LR: 0.000297\n",
      "Training:  23%|██▎       | 11399/50000 [27:35<1:27:38,  7.34it/s][Iteration 011400/050000] [BC: 0.00008259; Div: 0.00216230; For: 0.00342767] [0:27:35.378451]\n",
      "Lambda B: 42.854852\n",
      "LR: 0.000296\n",
      "Training:  23%|██▎       | 11499/50000 [27:49<1:27:51,  7.30it/s][Iteration 011500/050000] [BC: 0.00004413; Div: 0.00177594; For: 0.00277885] [0:27:49.663889]\n",
      "Lambda B: 41.686938\n",
      "LR: 0.000294\n",
      "Training:  23%|██▎       | 11599/50000 [28:03<1:27:16,  7.33it/s][Iteration 011600/050000] [BC: 0.00004448; Div: 0.00170250; For: 0.00263221] [0:28:03.941541]\n",
      "Lambda B: 40.550854\n",
      "LR: 0.000293\n",
      "Training:  23%|██▎       | 11699/50000 [28:18<1:27:41,  7.28it/s][Iteration 011700/050000] [BC: 0.00003633; Div: 0.00152120; For: 0.00234304] [0:28:18.311395]\n",
      "Lambda B: 39.445730\n",
      "LR: 0.000292\n",
      "Training:  24%|██▎       | 11799/50000 [28:32<1:27:36,  7.27it/s][Iteration 011800/050000] [BC: 0.00004310; Div: 0.00157300; For: 0.00239992] [0:28:32.699846]\n",
      "Lambda B: 38.370725\n",
      "LR: 0.000290\n",
      "Training:  24%|██▍       | 11899/50000 [28:46<1:27:10,  7.28it/s][Iteration 011900/050000] [BC: 0.00007840; Div: 0.00214483; For: 0.00307554] [0:28:47.090728]\n",
      "Lambda B: 37.325016\n",
      "LR: 0.000289\n",
      "Training:  24%|██▍       | 11999/50000 [29:01<1:26:53,  7.29it/s][Iteration 012000/050000] [BC: 0.00005407; Div: 0.00159525; For: 0.00245213] [0:29:01.471551]\n",
      "Lambda B: 36.307805\n",
      "LR: 0.000288\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.50it/s]\n",
      "Validation [Cube: BC: 1.201; Div: 0.046; For: 0.082; Sig: 13.645]\n",
      "Training:  24%|██▍       | 12099/50000 [29:16<1:26:48,  7.28it/s][Iteration 012100/050000] [BC: 0.00004883; Div: 0.00165261; For: 0.00247829] [0:29:16.630717]\n",
      "Lambda B: 35.318317\n",
      "LR: 0.000286\n",
      "Training:  24%|██▍       | 12199/50000 [29:30<1:26:37,  7.27it/s][Iteration 012200/050000] [BC: 0.00004224; Div: 0.00154569; For: 0.00225555] [0:29:31.023301]\n",
      "Lambda B: 34.355795\n",
      "LR: 0.000285\n",
      "Training:  25%|██▍       | 12299/50000 [29:45<1:26:23,  7.27it/s][Iteration 012300/050000] [BC: 0.00006605; Div: 0.00169043; For: 0.00290380] [0:29:45.404840]\n",
      "Lambda B: 33.419504\n",
      "LR: 0.000284\n",
      "Training:  25%|██▍       | 12399/50000 [29:59<1:26:09,  7.27it/s][Iteration 012400/050000] [BC: 0.00004462; Div: 0.00147269; For: 0.00225036] [0:29:59.797678]\n",
      "Lambda B: 32.508730\n",
      "LR: 0.000282\n",
      "Training:  25%|██▍       | 12499/50000 [30:13<1:25:59,  7.27it/s][Iteration 012500/050000] [BC: 0.00004481; Div: 0.00135661; For: 0.00205572] [0:30:14.192374]\n",
      "Lambda B: 31.622777\n",
      "LR: 0.000281\n",
      "Training:  25%|██▌       | 12599/50000 [30:28<1:25:48,  7.26it/s][Iteration 012600/050000] [BC: 0.00004474; Div: 0.00132499; For: 0.00207790] [0:30:28.583198]\n",
      "Lambda B: 30.760968\n",
      "LR: 0.000280\n",
      "Training:  25%|██▌       | 12699/50000 [30:42<1:25:20,  7.28it/s][Iteration 012700/050000] [BC: 0.00003323; Div: 0.00117828; For: 0.00180377] [0:30:42.958067]\n",
      "Lambda B: 29.922646\n",
      "LR: 0.000279\n",
      "Training:  26%|██▌       | 12799/50000 [30:57<1:25:12,  7.28it/s][Iteration 012800/050000] [BC: 0.00002551; Div: 0.00107883; For: 0.00164441] [0:30:57.354059]\n",
      "Lambda B: 29.107171\n",
      "LR: 0.000277\n",
      "Training:  26%|██▌       | 12899/50000 [31:11<1:25:19,  7.25it/s][Iteration 012900/050000] [BC: 0.00002508; Div: 0.00106798; For: 0.00158684] [0:31:11.742788]\n",
      "Lambda B: 28.313920\n",
      "LR: 0.000276\n",
      "Training:  26%|██▌       | 12999/50000 [31:25<1:24:51,  7.27it/s][Iteration 013000/050000] [BC: 0.00002426; Div: 0.00104122; For: 0.00151698] [0:31:26.145603]\n",
      "Lambda B: 27.542287\n",
      "LR: 0.000275\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 65.98it/s]\n",
      "Validation [Cube: BC: 0.803; Div: 0.028; For: 0.067; Sig: 11.503]\n",
      "Training:  26%|██▌       | 13099/50000 [31:41<1:24:31,  7.28it/s][Iteration 013100/050000] [BC: 0.00006231; Div: 0.00142762; For: 0.00216206] [0:31:41.264965]\n",
      "Lambda B: 26.791683\n",
      "LR: 0.000274\n",
      "Training:  26%|██▋       | 13199/50000 [31:58<1:24:17,  7.28it/s] [Iteration 013200/050000] [BC: 0.00004688; Div: 0.00125833; For: 0.00185527] [0:31:58.315044]\n",
      "Lambda B: 26.061535\n",
      "LR: 0.000272\n",
      "Training:  27%|██▋       | 13299/50000 [32:12<1:24:07,  7.27it/s][Iteration 013300/050000] [BC: 0.00004605; Div: 0.00118686; For: 0.00188743] [0:32:12.714896]\n",
      "Lambda B: 25.351286\n",
      "LR: 0.000271\n",
      "Training:  27%|██▋       | 13399/50000 [32:26<1:24:03,  7.26it/s][Iteration 013400/050000] [BC: 0.00002732; Div: 0.00093290; For: 0.00144342] [0:32:27.106199]\n",
      "Lambda B: 24.660393\n",
      "LR: 0.000270\n",
      "Training:  27%|██▋       | 13499/50000 [32:41<1:23:07,  7.32it/s][Iteration 013500/050000] [BC: 0.00002673; Div: 0.00090252; For: 0.00138161] [0:32:41.446109]\n",
      "Lambda B: 23.988329\n",
      "LR: 0.000269\n",
      "Training:  27%|██▋       | 13599/50000 [32:55<1:22:53,  7.32it/s][Iteration 013600/050000] [BC: 0.00003747; Div: 0.00094204; For: 0.00149753] [0:32:55.719852]\n",
      "Lambda B: 23.334581\n",
      "LR: 0.000267\n",
      "Training:  27%|██▋       | 13699/50000 [33:09<1:22:51,  7.30it/s][Iteration 013700/050000] [BC: 0.00004533; Div: 0.00105391; For: 0.00165898] [0:33:10.007515]\n",
      "Lambda B: 22.698649\n",
      "LR: 0.000266\n",
      "Training:  28%|██▊       | 13799/50000 [33:24<1:22:39,  7.30it/s][Iteration 013800/050000] [BC: 0.00005188; Div: 0.00121700; For: 0.00186926] [0:33:24.303316]\n",
      "Lambda B: 22.080047\n",
      "LR: 0.000265\n",
      "Training:  28%|██▊       | 13899/50000 [33:38<1:22:08,  7.32it/s][Iteration 013900/050000] [BC: 0.00003771; Div: 0.00102550; For: 0.00156428] [0:33:38.595835]\n",
      "Lambda B: 21.478305\n",
      "LR: 0.000264\n",
      "Training:  28%|██▊       | 13999/50000 [33:52<1:21:34,  7.36it/s][Iteration 014000/050000] [BC: 0.00003968; Div: 0.00100810; For: 0.00163187] [0:33:52.878031]\n",
      "Lambda B: 20.892961\n",
      "LR: 0.000262\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 67.32it/s]\n",
      "Validation [Cube: BC: 0.676; Div: 0.021; For: 0.060; Sig: 10.735]\n",
      "Training:  28%|██▊       | 14099/50000 [34:07<1:21:32,  7.34it/s][Iteration 014100/050000] [BC: 0.00003268; Div: 0.00090355; For: 0.00143765] [0:34:07.897350]\n",
      "Lambda B: 20.323570\n",
      "LR: 0.000261\n",
      "Training:  28%|██▊       | 14199/50000 [34:21<1:21:24,  7.33it/s][Iteration 014200/050000] [BC: 0.00003339; Div: 0.00095362; For: 0.00140000] [0:34:22.191402]\n",
      "Lambda B: 19.769696\n",
      "LR: 0.000260\n",
      "Training:  29%|██▊       | 14299/50000 [34:36<1:21:20,  7.32it/s][Iteration 014300/050000] [BC: 0.00003909; Div: 0.00096775; For: 0.00150417] [0:34:36.490308]\n",
      "Lambda B: 19.230917\n",
      "LR: 0.000259\n",
      "Training:  29%|██▉       | 14399/50000 [34:50<1:20:59,  7.33it/s][Iteration 014400/050000] [BC: 0.00004139; Div: 0.00097597; For: 0.00157205] [0:34:50.780963]\n",
      "Lambda B: 18.706821\n",
      "LR: 0.000258\n",
      "Training:  29%|██▉       | 14499/50000 [35:04<1:20:58,  7.31it/s][Iteration 014500/050000] [BC: 0.00004138; Div: 0.00102572; For: 0.00157339] [0:35:05.078261]\n",
      "Lambda B: 18.197009\n",
      "LR: 0.000256\n",
      "Training:  29%|██▉       | 14599/50000 [35:19<1:20:39,  7.32it/s][Iteration 014600/050000] [BC: 0.00002802; Div: 0.00073858; For: 0.00114833] [0:35:19.401761]\n",
      "Lambda B: 17.701090\n",
      "LR: 0.000255\n",
      "Training:  29%|██▉       | 14699/50000 [35:33<1:20:27,  7.31it/s][Iteration 014700/050000] [BC: 0.00003070; Div: 0.00073791; For: 0.00124930] [0:35:33.682662]\n",
      "Lambda B: 17.218686\n",
      "LR: 0.000254\n",
      "Training:  30%|██▉       | 14799/50000 [35:47<1:20:06,  7.32it/s][Iteration 014800/050000] [BC: 0.00003585; Div: 0.00078734; For: 0.00136087] [0:35:47.954827]\n",
      "Lambda B: 16.749429\n",
      "LR: 0.000253\n",
      "Training:  30%|██▉       | 14899/50000 [36:02<1:19:40,  7.34it/s][Iteration 014900/050000] [BC: 0.00002973; Div: 0.00067819; For: 0.00111198] [0:36:02.249550]\n",
      "Lambda B: 16.292960\n",
      "LR: 0.000252\n",
      "Training:  30%|██▉       | 14999/50000 [36:16<1:19:36,  7.33it/s][Iteration 015000/050000] [BC: 0.00002417; Div: 0.00059381; For: 0.00097241] [0:36:16.557888]\n",
      "Lambda B: 15.848932\n",
      "LR: 0.000251\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.65it/s]\n",
      "Validation [Cube: BC: 0.614; Div: 0.026; For: 0.053; Sig: 9.304]\n",
      "Training:  30%|███       | 15099/50000 [36:31<1:19:16,  7.34it/s][Iteration 015100/050000] [BC: 0.00002357; Div: 0.00058034; For: 0.00095151] [0:36:31.580282]\n",
      "Lambda B: 15.417005\n",
      "LR: 0.000249\n",
      "Training:  30%|███       | 15199/50000 [36:45<1:19:01,  7.34it/s][Iteration 015200/050000] [BC: 0.00002733; Div: 0.00059095; For: 0.00100545] [0:36:45.860156]\n",
      "Lambda B: 14.996848\n",
      "LR: 0.000248\n",
      "Training:  31%|███       | 15299/50000 [36:59<1:19:07,  7.31it/s][Iteration 015300/050000] [BC: 0.00005483; Div: 0.00112834; For: 0.00167137] [0:37:00.155497]\n",
      "Lambda B: 14.588143\n",
      "LR: 0.000247\n",
      "Training:  31%|███       | 15399/50000 [37:14<1:19:01,  7.30it/s][Iteration 015400/050000] [BC: 0.00003421; Div: 0.00076898; For: 0.00125442] [0:37:14.482899]\n",
      "Lambda B: 14.190575\n",
      "LR: 0.000246\n",
      "Training:  31%|███       | 15499/50000 [37:28<1:19:00,  7.28it/s][Iteration 015500/050000] [BC: 0.00003156; Div: 0.00066089; For: 0.00098642] [0:37:28.860606]\n",
      "Lambda B: 13.803843\n",
      "LR: 0.000245\n",
      "Training:  31%|███       | 15599/50000 [37:42<1:18:10,  7.33it/s][Iteration 015600/050000] [BC: 0.00002395; Div: 0.00051926; For: 0.00083730] [0:37:43.202830]\n",
      "Lambda B: 13.427650\n",
      "LR: 0.000244\n",
      "Training:  31%|███▏      | 15699/50000 [37:57<1:17:50,  7.34it/s][Iteration 015700/050000] [BC: 0.00003412; Div: 0.00059054; For: 0.00095215] [0:37:57.494546]\n",
      "Lambda B: 13.061709\n",
      "LR: 0.000243\n",
      "Training:  32%|███▏      | 15799/50000 [38:11<1:17:46,  7.33it/s][Iteration 015800/050000] [BC: 0.00003244; Div: 0.00051188; For: 0.00087725] [0:38:11.817269]\n",
      "Lambda B: 12.705741\n",
      "LR: 0.000242\n",
      "Training:  32%|███▏      | 15899/50000 [38:25<1:17:42,  7.31it/s][Iteration 015900/050000] [BC: 0.00002272; Div: 0.00050467; For: 0.00081426] [0:38:26.106893]\n",
      "Lambda B: 12.359474\n",
      "LR: 0.000240\n",
      "Training:  32%|███▏      | 15999/50000 [38:40<1:17:04,  7.35it/s][Iteration 016000/050000] [BC: 0.00002111; Div: 0.00048073; For: 0.00078191] [0:38:40.367770]\n",
      "Lambda B: 12.022644\n",
      "LR: 0.000239\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.73it/s]\n",
      "Validation [Cube: BC: 1.036; Div: 0.017; For: 0.051; Sig: 9.169]\n",
      "Training:  32%|███▏      | 16099/50000 [38:55<1:17:17,  7.31it/s][Iteration 016100/050000] [BC: 0.00002780; Div: 0.00049375; For: 0.00080808] [0:38:55.375897]\n",
      "Lambda B: 11.694994\n",
      "LR: 0.000238\n",
      "Training:  32%|███▏      | 16199/50000 [39:12<1:16:51,  7.33it/s] [Iteration 016200/050000] [BC: 0.00002044; Div: 0.00043744; For: 0.00072820] [0:39:12.888540]\n",
      "Lambda B: 11.376273\n",
      "LR: 0.000237\n",
      "Training:  33%|███▎      | 16299/50000 [39:26<1:16:53,  7.31it/s][Iteration 016300/050000] [BC: 0.00002122; Div: 0.00049626; For: 0.00077846] [0:39:27.178932]\n",
      "Lambda B: 11.066238\n",
      "LR: 0.000236\n",
      "Training:  33%|███▎      | 16399/50000 [39:41<1:16:53,  7.28it/s][Iteration 016400/050000] [BC: 0.00001869; Div: 0.00040463; For: 0.00067459] [0:39:41.611260]\n",
      "Lambda B: 10.764652\n",
      "LR: 0.000235\n",
      "Training:  33%|███▎      | 16499/50000 [39:55<1:16:38,  7.28it/s][Iteration 016500/050000] [BC: 0.00001855; Div: 0.00038558; For: 0.00064894] [0:39:55.987167]\n",
      "Lambda B: 10.471285\n",
      "LR: 0.000234\n",
      "Training:  33%|███▎      | 16599/50000 [40:10<1:16:24,  7.29it/s][Iteration 016600/050000] [BC: 0.00001898; Div: 0.00038501; For: 0.00064064] [0:40:10.359739]\n",
      "Lambda B: 10.185914\n",
      "LR: 0.000233\n",
      "Training:  33%|███▎      | 16699/50000 [40:24<1:16:22,  7.27it/s][Iteration 016700/050000] [BC: 0.00001830; Div: 0.00035605; For: 0.00060664] [0:40:24.744701]\n",
      "Lambda B: 9.908319\n",
      "LR: 0.000232\n",
      "Training:  34%|███▎      | 16799/50000 [40:38<1:16:06,  7.27it/s][Iteration 016800/050000] [BC: 0.00001994; Div: 0.00039173; For: 0.00063994] [0:40:39.129707]\n",
      "Lambda B: 9.638290\n",
      "LR: 0.000231\n",
      "Training:  34%|███▍      | 16899/50000 [40:53<1:15:51,  7.27it/s][Iteration 016900/050000] [BC: 0.00001926; Div: 0.00036023; For: 0.00060600] [0:40:53.514007]\n",
      "Lambda B: 9.375620\n",
      "LR: 0.000230\n",
      "Training:  34%|███▍      | 16999/50000 [41:07<1:15:36,  7.27it/s][Iteration 017000/050000] [BC: 0.00001898; Div: 0.00033817; For: 0.00057698] [0:41:07.910391]\n",
      "Lambda B: 9.120108\n",
      "LR: 0.000229\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.11it/s]\n",
      "Validation [Cube: BC: 0.545; Div: 0.020; For: 0.043; Sig: 7.631]\n",
      "Training:  34%|███▍      | 17099/50000 [41:22<1:15:27,  7.27it/s][Iteration 017100/050000] [BC: 0.00002048; Div: 0.00037714; For: 0.00061310] [0:41:23.059869]\n",
      "Lambda B: 8.871560\n",
      "LR: 0.000227\n",
      "Training:  34%|███▍      | 17199/50000 [41:37<1:15:21,  7.25it/s][Iteration 017200/050000] [BC: 0.00001903; Div: 0.00032104; For: 0.00055312] [0:41:37.463902]\n",
      "Lambda B: 8.629785\n",
      "LR: 0.000226\n",
      "Training:  35%|███▍      | 17299/50000 [41:51<1:14:59,  7.27it/s][Iteration 017300/050000] [BC: 0.00001944; Div: 0.00032607; For: 0.00055699] [0:41:51.855061]\n",
      "Lambda B: 8.394600\n",
      "LR: 0.000225\n",
      "Training:  35%|███▍      | 17399/50000 [42:06<1:14:46,  7.27it/s][Iteration 017400/050000] [BC: 0.00001918; Div: 0.00031362; For: 0.00054289] [0:42:06.240842]\n",
      "Lambda B: 8.165824\n",
      "LR: 0.000224\n",
      "Training:  35%|███▍      | 17499/50000 [42:20<1:14:33,  7.26it/s][Iteration 017500/050000] [BC: 0.00002168; Div: 0.00037167; For: 0.00060188] [0:42:20.633672]\n",
      "Lambda B: 7.943282\n",
      "LR: 0.000223\n",
      "Training:  35%|███▌      | 17599/50000 [42:34<1:14:13,  7.28it/s][Iteration 017600/050000] [BC: 0.00002024; Div: 0.00033411; For: 0.00055365] [0:42:35.021485]\n",
      "Lambda B: 7.726806\n",
      "LR: 0.000222\n",
      "Training:  35%|███▌      | 17699/50000 [42:49<1:14:05,  7.27it/s][Iteration 017700/050000] [BC: 0.00001902; Div: 0.00028295; For: 0.00049483] [0:42:49.418226]\n",
      "Lambda B: 7.516229\n",
      "LR: 0.000221\n",
      "Training:  36%|███▌      | 17799/50000 [43:03<1:13:43,  7.28it/s][Iteration 017800/050000] [BC: 0.00002053; Div: 0.00031947; For: 0.00053028] [0:43:03.802926]\n",
      "Lambda B: 7.311391\n",
      "LR: 0.000220\n",
      "Training:  36%|███▌      | 17899/50000 [43:17<1:13:44,  7.25it/s][Iteration 017900/050000] [BC: 0.00001942; Div: 0.00027186; For: 0.00047607] [0:43:18.192911]\n",
      "Lambda B: 7.112135\n",
      "LR: 0.000219\n",
      "Training:  36%|███▌      | 17999/50000 [43:32<1:13:27,  7.26it/s][Iteration 018000/050000] [BC: 0.00002090; Div: 0.00030846; For: 0.00052419] [0:43:32.587454]\n",
      "Lambda B: 6.918310\n",
      "LR: 0.000218\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.50it/s]\n",
      "Validation [Cube: BC: 0.623; Div: 0.017; For: 0.040; Sig: 7.170]\n",
      "Training:  36%|███▌      | 18099/50000 [43:47<1:13:07,  7.27it/s][Iteration 018100/050000] [BC: 0.00001997; Div: 0.00026650; For: 0.00046635] [0:43:47.705269]\n",
      "Lambda B: 6.729767\n",
      "LR: 0.000217\n",
      "Training:  36%|███▋      | 18199/50000 [44:01<1:12:17,  7.33it/s][Iteration 018200/050000] [BC: 0.00002102; Div: 0.00028385; For: 0.00049445] [0:44:02.064929]\n",
      "Lambda B: 6.546362\n",
      "LR: 0.000216\n",
      "Training:  37%|███▋      | 18299/50000 [44:16<1:11:56,  7.34it/s][Iteration 018300/050000] [BC: 0.00001998; Div: 0.00026577; For: 0.00045879] [0:44:16.343507]\n",
      "Lambda B: 6.367955\n",
      "LR: 0.000215\n",
      "Training:  37%|███▋      | 18399/50000 [44:30<1:12:04,  7.31it/s][Iteration 018400/050000] [BC: 0.00002412; Div: 0.00039024; For: 0.00060340] [0:44:30.638700]\n",
      "Lambda B: 6.194411\n",
      "LR: 0.000214\n",
      "Training:  37%|███▋      | 18499/50000 [44:44<1:11:52,  7.30it/s][Iteration 018500/050000] [BC: 0.00001984; Div: 0.00023655; For: 0.00042079] [0:44:44.936210]\n",
      "Lambda B: 6.025596\n",
      "LR: 0.000213\n",
      "Training:  37%|███▋      | 18599/50000 [44:59<1:11:17,  7.34it/s][Iteration 018600/050000] [BC: 0.00002034; Div: 0.00023457; For: 0.00041714] [0:44:59.226014]\n",
      "Lambda B: 5.861382\n",
      "LR: 0.000212\n",
      "Training:  37%|███▋      | 18699/50000 [45:13<1:11:13,  7.32it/s][Iteration 018700/050000] [BC: 0.00002018; Div: 0.00022794; For: 0.00040659] [0:45:13.529019]\n",
      "Lambda B: 5.701643\n",
      "LR: 0.000211\n",
      "Training:  38%|███▊      | 18799/50000 [45:27<1:10:46,  7.35it/s][Iteration 018800/050000] [BC: 0.00002080; Div: 0.00022853; For: 0.00040448] [0:45:27.816925]\n",
      "Lambda B: 5.546257\n",
      "LR: 0.000210\n",
      "Training:  38%|███▊      | 18899/50000 [45:41<1:10:59,  7.30it/s][Iteration 018900/050000] [BC: 0.00002121; Div: 0.00024707; For: 0.00043406] [0:45:42.128821]\n",
      "Lambda B: 5.395106\n",
      "LR: 0.000209\n",
      "Training:  38%|███▊      | 18999/50000 [45:56<1:10:49,  7.29it/s][Iteration 019000/050000] [BC: 0.00002106; Div: 0.00023731; For: 0.00040702] [0:45:56.431612]\n",
      "Lambda B: 5.248075\n",
      "LR: 0.000208\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.33it/s]\n",
      "Validation [Cube: BC: 0.579; Div: 0.018; For: 0.037; Sig: 6.541]\n",
      "Training:  38%|███▊      | 19099/50000 [46:11<1:10:38,  7.29it/s][Iteration 019100/050000] [BC: 0.00002217; Div: 0.00024659; For: 0.00043134] [0:46:11.445346]\n",
      "Lambda B: 5.105050\n",
      "LR: 0.000207\n",
      "Training:  38%|███▊      | 19199/50000 [46:25<1:10:07,  7.32it/s][Iteration 019200/050000] [BC: 0.00002134; Div: 0.00022277; For: 0.00039549] [0:46:25.751069]\n",
      "Lambda B: 4.965923\n",
      "LR: 0.000207\n",
      "Training:  39%|███▊      | 19299/50000 [46:39<1:09:43,  7.34it/s][Iteration 019300/050000] [BC: 0.00002397; Div: 0.00032174; For: 0.00053177] [0:46:40.042680]\n",
      "Lambda B: 4.830588\n",
      "LR: 0.000206\n",
      "Training:  39%|███▉      | 19399/50000 [46:54<1:09:33,  7.33it/s][Iteration 019400/050000] [BC: 0.00002109; Div: 0.00019951; For: 0.00035560] [0:46:54.344551]\n",
      "Lambda B: 4.698941\n",
      "LR: 0.000205\n",
      "Training:  39%|███▉      | 19499/50000 [47:08<1:09:39,  7.30it/s][Iteration 019500/050000] [BC: 0.00002153; Div: 0.00020278; For: 0.00036067] [0:47:08.642784]\n",
      "Lambda B: 4.570882\n",
      "LR: 0.000204\n",
      "Training:  39%|███▉      | 19599/50000 [47:22<1:09:23,  7.30it/s][Iteration 019600/050000] [BC: 0.00002199; Div: 0.00020271; For: 0.00036192] [0:47:22.941493]\n",
      "Lambda B: 4.446313\n",
      "LR: 0.000203\n",
      "Training:  39%|███▉      | 19699/50000 [47:37<1:08:57,  7.32it/s][Iteration 019700/050000] [BC: 0.00002199; Div: 0.00019335; For: 0.00035040] [0:47:37.229537]\n",
      "Lambda B: 4.325138\n",
      "LR: 0.000202\n",
      "Training:  40%|███▉      | 19799/50000 [47:55<1:08:43,  7.32it/s] [Iteration 019800/050000] [BC: 0.00002186; Div: 0.00018281; For: 0.00033046] [0:47:55.349399]\n",
      "Lambda B: 4.207266\n",
      "LR: 0.000201\n",
      "Training:  40%|███▉      | 19899/50000 [48:09<1:08:31,  7.32it/s][Iteration 019900/050000] [BC: 0.00002353; Div: 0.00024081; For: 0.00040541] [0:48:09.625901]\n",
      "Lambda B: 4.092607\n",
      "LR: 0.000200\n",
      "Training:  40%|███▉      | 19999/50000 [48:23<1:08:07,  7.34it/s][Iteration 020000/050000] [BC: 0.00002342; Div: 0.00021431; For: 0.00037667] [0:48:23.905612]\n",
      "Lambda B: 3.981072\n",
      "LR: 0.000199\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.67it/s]\n",
      "Validation [Cube: BC: 0.611; Div: 0.015; For: 0.036; Sig: 6.411]\n",
      "Training:  40%|████      | 20099/50000 [48:38<1:08:28,  7.28it/s][Iteration 020100/050000] [BC: 0.00002297; Div: 0.00020100; For: 0.00035613] [0:48:38.996922]\n",
      "Lambda B: 3.872576\n",
      "LR: 0.000198\n",
      "Training:  40%|████      | 20199/50000 [48:53<1:08:17,  7.27it/s][Iteration 020200/050000] [BC: 0.00002258; Div: 0.00017510; For: 0.00031519] [0:48:53.383672]\n",
      "Lambda B: 3.767038\n",
      "LR: 0.000197\n",
      "Training:  41%|████      | 20299/50000 [49:07<1:07:30,  7.33it/s][Iteration 020300/050000] [BC: 0.00002363; Div: 0.00020060; For: 0.00035338] [0:49:07.699176]\n",
      "Lambda B: 3.664376\n",
      "LR: 0.000196\n",
      "Training:  41%|████      | 20399/50000 [49:21<1:07:10,  7.34it/s][Iteration 020400/050000] [BC: 0.00002363; Div: 0.00018377; For: 0.00032772] [0:49:22.004821]\n",
      "Lambda B: 3.564511\n",
      "LR: 0.000195\n",
      "Training:  41%|████      | 20499/50000 [49:36<1:07:15,  7.31it/s][Iteration 020500/050000] [BC: 0.00002388; Div: 0.00020270; For: 0.00034453] [0:49:36.299851]\n",
      "Lambda B: 3.467369\n",
      "LR: 0.000195\n",
      "Training:  41%|████      | 20599/50000 [49:50<1:06:49,  7.33it/s][Iteration 020600/050000] [BC: 0.00002444; Div: 0.00021211; For: 0.00033576] [0:49:50.585497]\n",
      "Lambda B: 3.372873\n",
      "LR: 0.000194\n",
      "Training:  41%|████▏     | 20699/50000 [50:04<1:06:33,  7.34it/s][Iteration 020700/050000] [BC: 0.00002336; Div: 0.00015358; For: 0.00028227] [0:50:04.885761]\n",
      "Lambda B: 3.280953\n",
      "LR: 0.000193\n",
      "Training:  42%|████▏     | 20799/50000 [50:18<1:06:24,  7.33it/s][Iteration 020800/050000] [BC: 0.00002411; Div: 0.00016386; For: 0.00030526] [0:50:19.183661]\n",
      "Lambda B: 3.191538\n",
      "LR: 0.000192\n",
      "Training:  42%|████▏     | 20899/50000 [50:33<1:06:23,  7.31it/s][Iteration 020900/050000] [BC: 0.00002404; Div: 0.00015184; For: 0.00028294] [0:50:33.461563]\n",
      "Lambda B: 3.104560\n",
      "LR: 0.000191\n",
      "Training:  42%|████▏     | 20999/50000 [50:47<1:06:23,  7.28it/s][Iteration 021000/050000] [BC: 0.00002647; Div: 0.00024999; For: 0.00039633] [0:50:47.742694]\n",
      "Lambda B: 3.019952\n",
      "LR: 0.000190\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.43it/s]\n",
      "Validation [Cube: BC: 0.627; Div: 0.012; For: 0.032; Sig: 5.651]\n",
      "Training:  42%|████▏     | 21099/50000 [51:02<1:06:16,  7.27it/s][Iteration 021100/050000] [BC: 0.00002403; Div: 0.00013655; For: 0.00025805] [0:51:02.874086]\n",
      "Lambda B: 2.937650\n",
      "LR: 0.000189\n",
      "Training:  42%|████▏     | 21199/50000 [51:17<1:05:58,  7.28it/s][Iteration 021200/050000] [BC: 0.00002427; Div: 0.00013348; For: 0.00025276] [0:51:17.269237]\n",
      "Lambda B: 2.857591\n",
      "LR: 0.000188\n",
      "Training:  43%|████▎     | 21299/50000 [51:31<1:07:05,  7.13it/s][Iteration 021300/050000] [BC: 0.00002528; Div: 0.00014711; For: 0.00027358] [0:51:31.945346]\n",
      "Lambda B: 2.779713\n",
      "LR: 0.000187\n",
      "Training:  43%|████▎     | 21399/50000 [51:46<1:05:30,  7.28it/s][Iteration 021400/050000] [BC: 0.00002669; Div: 0.00020936; For: 0.00037085] [0:51:46.357193]\n",
      "Lambda B: 2.703958\n",
      "LR: 0.000187\n",
      "Training:  43%|████▎     | 21499/50000 [52:00<1:06:41,  7.12it/s][Iteration 021500/050000] [BC: 0.00002653; Div: 0.00016414; For: 0.00029490] [0:52:00.804380]\n",
      "Lambda B: 2.630268\n",
      "LR: 0.000186\n",
      "Training:  43%|████▎     | 21599/50000 [52:15<1:06:22,  7.13it/s][Iteration 021600/050000] [BC: 0.00002532; Div: 0.00013163; For: 0.00024373] [0:52:15.480072]\n",
      "Lambda B: 2.558586\n",
      "LR: 0.000185\n",
      "Training:  43%|████▎     | 21699/50000 [52:29<1:06:13,  7.12it/s][Iteration 021700/050000] [BC: 0.00002553; Div: 0.00012419; For: 0.00023651] [0:52:30.155573]\n",
      "Lambda B: 2.488857\n",
      "LR: 0.000184\n",
      "Training:  44%|████▎     | 21799/50000 [52:44<1:06:06,  7.11it/s][Iteration 021800/050000] [BC: 0.00002598; Div: 0.00012889; For: 0.00023765] [0:52:44.833228]\n",
      "Lambda B: 2.421029\n",
      "LR: 0.000183\n",
      "Training:  44%|████▍     | 21899/50000 [52:59<1:05:53,  7.11it/s][Iteration 021900/050000] [BC: 0.00002778; Div: 0.00017303; For: 0.00031417] [0:52:59.521880]\n",
      "Lambda B: 2.355049\n",
      "LR: 0.000182\n",
      "Training:  44%|████▍     | 21999/50000 [53:13<1:05:15,  7.15it/s][Iteration 022000/050000] [BC: 0.00002627; Div: 0.00012111; For: 0.00022174] [0:53:14.202145]\n",
      "Lambda B: 2.290868\n",
      "LR: 0.000182\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 65.59it/s]\n",
      "Validation [Cube: BC: 0.641; Div: 0.012; For: 0.031; Sig: 5.506]\n",
      "Training:  44%|████▍     | 22099/50000 [53:29<1:05:01,  7.15it/s][Iteration 022100/050000] [BC: 0.00002748; Div: 0.00015317; For: 0.00027658] [0:53:29.644235]\n",
      "Lambda B: 2.228435\n",
      "LR: 0.000181\n",
      "Training:  44%|████▍     | 22199/50000 [53:44<1:05:09,  7.11it/s][Iteration 022200/050000] [BC: 0.00002681; Div: 0.00011066; For: 0.00021375] [0:53:44.324870]\n",
      "Lambda B: 2.167704\n",
      "LR: 0.000180\n",
      "Training:  45%|████▍     | 22299/50000 [53:58<1:03:32,  7.27it/s][Iteration 022300/050000] [BC: 0.00002700; Div: 0.00011250; For: 0.00021442] [0:53:58.699732]\n",
      "Lambda B: 2.108628\n",
      "LR: 0.000179\n",
      "Training:  45%|████▍     | 22399/50000 [54:12<1:03:09,  7.28it/s][Iteration 022400/050000] [BC: 0.00002898; Div: 0.00019698; For: 0.00030864] [0:54:13.088034]\n",
      "Lambda B: 2.051162\n",
      "LR: 0.000178\n",
      "Training:  45%|████▍     | 22499/50000 [54:27<1:03:11,  7.25it/s][Iteration 022500/050000] [BC: 0.00002892; Div: 0.00012641; For: 0.00023442] [0:54:27.488140]\n",
      "Lambda B: 1.995262\n",
      "LR: 0.000177\n",
      "Training:  45%|████▌     | 22599/50000 [54:41<1:02:45,  7.28it/s][Iteration 022600/050000] [BC: 0.00002796; Div: 0.00010779; For: 0.00021270] [0:54:41.869573]\n",
      "Lambda B: 1.940886\n",
      "LR: 0.000177\n",
      "Training:  45%|████▌     | 22699/50000 [54:56<1:02:41,  7.26it/s][Iteration 022700/050000] [BC: 0.00002786; Div: 0.00009245; For: 0.00018385] [0:54:56.274131]\n",
      "Lambda B: 1.887991\n",
      "LR: 0.000176\n",
      "Training:  46%|████▌     | 22799/50000 [55:10<1:02:18,  7.28it/s][Iteration 022800/050000] [BC: 0.00002905; Div: 0.00011067; For: 0.00021755] [0:55:10.664547]\n",
      "Lambda B: 1.836538\n",
      "LR: 0.000175\n",
      "Training:  46%|████▌     | 22899/50000 [55:24<1:01:38,  7.33it/s][Iteration 022900/050000] [BC: 0.00002893; Div: 0.00010524; For: 0.00021278] [0:55:24.985405]\n",
      "Lambda B: 1.786488\n",
      "LR: 0.000174\n",
      "Training:  46%|████▌     | 22999/50000 [55:39<1:01:19,  7.34it/s][Iteration 023000/050000] [BC: 0.00003055; Div: 0.00015008; For: 0.00026894] [0:55:39.272652]\n",
      "Lambda B: 1.737801\n",
      "LR: 0.000173\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.83it/s]\n",
      "Validation [Cube: BC: 0.687; Div: 0.009; For: 0.027; Sig: 4.813]\n",
      "Training:  46%|████▌     | 23099/50000 [55:54<1:01:03,  7.34it/s][Iteration 023100/050000] [BC: 0.00002905; Div: 0.00009015; For: 0.00017232] [0:55:54.270301]\n",
      "Lambda B: 1.690441\n",
      "LR: 0.000173\n",
      "Training:  46%|████▋     | 23199/50000 [56:08<1:01:02,  7.32it/s][Iteration 023200/050000] [BC: 0.00002955; Div: 0.00009455; For: 0.00018197] [0:56:08.563314]\n",
      "Lambda B: 1.644372\n",
      "LR: 0.000172\n",
      "Training:  47%|████▋     | 23299/50000 [56:22<1:00:58,  7.30it/s][Iteration 023300/050000] [BC: 0.00002983; Div: 0.00008518; For: 0.00017042] [0:56:22.855663]\n",
      "Lambda B: 1.599558\n",
      "LR: 0.000171\n",
      "Training:  47%|████▋     | 23399/50000 [56:36<1:00:22,  7.34it/s][Iteration 023400/050000] [BC: 0.00003063; Div: 0.00011185; For: 0.00020170] [0:56:37.139767]\n",
      "Lambda B: 1.555966\n",
      "LR: 0.000170\n",
      "Training:  47%|████▋     | 23499/50000 [56:51<1:00:22,  7.32it/s][Iteration 023500/050000] [BC: 0.00003120; Div: 0.00011663; For: 0.00021137] [0:56:51.432325]\n",
      "Lambda B: 1.513561\n",
      "LR: 0.000169\n",
      "Training:  47%|████▋     | 23599/50000 [57:05<59:53,  7.35it/s]  [Iteration 023600/050000] [BC: 0.00003098; Div: 0.00008243; For: 0.00016646] [0:57:05.718463]\n",
      "Lambda B: 1.472313\n",
      "LR: 0.000169\n",
      "Training:  47%|████▋     | 23699/50000 [57:19<59:59,  7.31it/s]  [Iteration 023700/050000] [BC: 0.00003176; Div: 0.00011072; For: 0.00019160] [0:57:20.025933]\n",
      "Lambda B: 1.432188\n",
      "LR: 0.000168\n",
      "Training:  48%|████▊     | 23799/50000 [57:34<59:28,  7.34it/s]  [Iteration 023800/050000] [BC: 0.00003215; Div: 0.00012268; For: 0.00022601] [0:57:34.338391]\n",
      "Lambda B: 1.393157\n",
      "LR: 0.000167\n",
      "Training:  48%|████▊     | 23899/50000 [57:48<59:30,  7.31it/s]  [Iteration 023900/050000] [BC: 0.00003947; Div: 0.00028334; For: 0.00041043] [0:57:48.645063]\n",
      "Lambda B: 1.355189\n",
      "LR: 0.000166\n",
      "Training:  48%|████▊     | 23999/50000 [58:02<59:14,  7.31it/s]  [Iteration 024000/050000] [BC: 0.00003152; Div: 0.00006354; For: 0.00013367] [0:58:02.920420]\n",
      "Lambda B: 1.318257\n",
      "LR: 0.000166\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 41.26it/s]\n",
      "Validation [Cube: BC: 0.705; Div: 0.010; For: 0.024; Sig: 4.242]\n",
      "Training:  48%|████▊     | 24099/50000 [58:22<58:47,  7.34it/s]   [Iteration 024100/050000] [BC: 0.00003171; Div: 0.00006222; For: 0.00013011] [0:58:22.633720]\n",
      "Lambda B: 1.282331\n",
      "LR: 0.000165\n",
      "Training:  48%|████▊     | 24199/50000 [58:36<58:24,  7.36it/s]  [Iteration 024200/050000] [BC: 0.00003202; Div: 0.00006131; For: 0.00012925] [0:58:36.922390]\n",
      "Lambda B: 1.247384\n",
      "LR: 0.000164\n",
      "Training:  49%|████▊     | 24299/50000 [58:50<58:45,  7.29it/s]  [Iteration 024300/050000] [BC: 0.00003238; Div: 0.00006002; For: 0.00012855] [0:58:51.222293]\n",
      "Lambda B: 1.213389\n",
      "LR: 0.000163\n",
      "Training:  49%|████▉     | 24399/50000 [59:05<58:10,  7.33it/s]  [Iteration 024400/050000] [BC: 0.00003306; Div: 0.00006481; For: 0.00013786] [0:59:05.493335]\n",
      "Lambda B: 1.180321\n",
      "LR: 0.000163\n",
      "Training:  49%|████▉     | 24499/50000 [59:19<57:56,  7.34it/s]  [Iteration 024500/050000] [BC: 0.00003407; Div: 0.00009674; For: 0.00015901] [0:59:19.768007]\n",
      "Lambda B: 1.148154\n",
      "LR: 0.000162\n",
      "Training:  49%|████▉     | 24599/50000 [59:33<57:47,  7.32it/s]  [Iteration 024600/050000] [BC: 0.00003374; Div: 0.00006434; For: 0.00013750] [0:59:34.053612]\n",
      "Lambda B: 1.116863\n",
      "LR: 0.000161\n",
      "Training:  49%|████▉     | 24699/50000 [59:48<57:29,  7.33it/s]  [Iteration 024700/050000] [BC: 0.00003547; Div: 0.00012192; For: 0.00022367] [0:59:48.348863]\n",
      "Lambda B: 1.086426\n",
      "LR: 0.000160\n",
      "Training:  50%|████▉     | 24799/50000 [1:00:02<57:30,  7.30it/s][Iteration 024800/050000] [BC: 0.00003412; Div: 0.00005508; For: 0.00011754] [1:00:02.806948]\n",
      "Lambda B: 1.056818\n",
      "LR: 0.000160\n",
      "Training:  50%|████▉     | 24899/50000 [1:00:16<57:04,  7.33it/s]  [Iteration 024900/050000] [BC: 0.00003451; Div: 0.00005564; For: 0.00011849] [1:00:17.197051]\n",
      "Lambda B: 1.028016\n",
      "LR: 0.000159\n",
      "Training:  50%|████▉     | 24999/50000 [1:00:31<56:49,  7.33it/s]  [Iteration 025000/050000] [BC: 0.00003565; Div: 0.00008915; For: 0.00014842] [1:00:31.485462]\n",
      "Lambda B: 1.000000\n",
      "LR: 0.000158\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.39it/s]\n",
      "Validation [Cube: BC: 0.735; Div: 0.010; For: 0.022; Sig: 3.865]\n",
      "Training:  50%|█████     | 25099/50000 [1:00:46<56:42,  7.32it/s]  [Iteration 025100/050000] [BC: 0.00003502; Div: 0.00005453; For: 0.00011623] [1:00:46.486129]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000157\n",
      "Training:  50%|█████     | 25199/50000 [1:01:00<56:43,  7.29it/s]  [Iteration 025200/050000] [BC: 0.00003528; Div: 0.00006456; For: 0.00013220] [1:01:00.791578]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000157\n",
      "Training:  51%|█████     | 25299/50000 [1:01:14<55:59,  7.35it/s]  [Iteration 025300/050000] [BC: 0.00003538; Div: 0.00005861; For: 0.00012820] [1:01:15.074397]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000156\n",
      "Training:  51%|█████     | 25399/50000 [1:01:29<55:47,  7.35it/s]  [Iteration 025400/050000] [BC: 0.00003585; Div: 0.00006342; For: 0.00014110] [1:01:29.360074]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000155\n",
      "Training:  51%|█████     | 25499/50000 [1:01:43<55:59,  7.29it/s]  [Iteration 025500/050000] [BC: 0.00003606; Div: 0.00006938; For: 0.00014245] [1:01:43.643595]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000155\n",
      "Training:  51%|█████     | 25599/50000 [1:01:57<55:26,  7.33it/s]  [Iteration 025600/050000] [BC: 0.00003721; Div: 0.00009232; For: 0.00018337] [1:01:57.938612]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000154\n",
      "Training:  51%|█████▏    | 25699/50000 [1:02:12<55:38,  7.28it/s]  [Iteration 025700/050000] [BC: 0.00003674; Div: 0.00013124; For: 0.00018425] [1:02:12.287505]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000153\n",
      "Training:  52%|█████▏    | 25799/50000 [1:02:26<55:26,  7.28it/s]  [Iteration 025800/050000] [BC: 0.00003585; Div: 0.00006137; For: 0.00012981] [1:02:26.679587]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000152\n",
      "Training:  52%|█████▏    | 25899/50000 [1:02:40<55:14,  7.27it/s]  [Iteration 025900/050000] [BC: 0.00003506; Div: 0.00004670; For: 0.00010206] [1:02:41.086549]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000152\n",
      "Training:  52%|█████▏    | 25999/50000 [1:02:55<55:04,  7.26it/s]  [Iteration 026000/050000] [BC: 0.00003527; Div: 0.00004974; For: 0.00010854] [1:02:55.487290]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000151\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.17it/s]\n",
      "Validation [Cube: BC: 0.738; Div: 0.008; For: 0.022; Sig: 3.872]\n",
      "Training:  52%|█████▏    | 26099/50000 [1:03:10<54:45,  7.27it/s]  [Iteration 026100/050000] [BC: 0.00003590; Div: 0.00007042; For: 0.00013852] [1:03:10.624049]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000150\n",
      "Training:  52%|█████▏    | 26199/50000 [1:03:24<54:32,  7.27it/s]  [Iteration 026200/050000] [BC: 0.00003637; Div: 0.00007905; For: 0.00017270] [1:03:25.028343]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000150\n",
      "Training:  53%|█████▎    | 26299/50000 [1:03:39<54:22,  7.27it/s]  [Iteration 026300/050000] [BC: 0.00003674; Div: 0.00007928; For: 0.00016569] [1:03:39.431735]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000149\n",
      "Training:  53%|█████▎    | 26399/50000 [1:03:53<54:09,  7.26it/s]  [Iteration 026400/050000] [BC: 0.00003535; Div: 0.00005537; For: 0.00010661] [1:03:53.839213]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000148\n",
      "Training:  53%|█████▎    | 26499/50000 [1:04:08<53:52,  7.27it/s]  [Iteration 026500/050000] [BC: 0.00003515; Div: 0.00004899; For: 0.00010324] [1:04:08.242450]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000148\n",
      "Training:  53%|█████▎    | 26599/50000 [1:04:22<53:34,  7.28it/s]  [Iteration 026600/050000] [BC: 0.00003563; Div: 0.00005761; For: 0.00011710] [1:04:22.626798]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000147\n",
      "Training:  53%|█████▎    | 26699/50000 [1:04:36<53:20,  7.28it/s]  [Iteration 026700/050000] [BC: 0.00003553; Div: 0.00005828; For: 0.00011884] [1:04:37.018106]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000146\n",
      "Training:  54%|█████▎    | 26799/50000 [1:04:51<53:13,  7.27it/s]  [Iteration 026800/050000] [BC: 0.00003614; Div: 0.00006860; For: 0.00013474] [1:04:51.400899]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000146\n",
      "Training:  54%|█████▍    | 26899/50000 [1:05:05<52:53,  7.28it/s]  [Iteration 026900/050000] [BC: 0.00003792; Div: 0.00010272; For: 0.00020905] [1:05:05.799382]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000145\n",
      "Training:  54%|█████▍    | 26999/50000 [1:05:19<52:39,  7.28it/s]  [Iteration 027000/050000] [BC: 0.00003537; Div: 0.00005065; For: 0.00010968] [1:05:20.203584]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000144\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.25it/s]\n",
      "Validation [Cube: BC: 0.758; Div: 0.008; For: 0.021; Sig: 3.738]\n",
      "Training:  54%|█████▍    | 27099/50000 [1:05:35<52:27,  7.28it/s]  [Iteration 027100/050000] [BC: 0.00003527; Div: 0.00004937; For: 0.00010231] [1:05:35.335246]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000144\n",
      "Training:  54%|█████▍    | 27199/50000 [1:05:49<52:13,  7.28it/s]  [Iteration 027200/050000] [BC: 0.00003547; Div: 0.00005563; For: 0.00011574] [1:05:49.727047]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000143\n",
      "Training:  55%|█████▍    | 27299/50000 [1:06:03<51:59,  7.28it/s]  [Iteration 027300/050000] [BC: 0.00003569; Div: 0.00006019; For: 0.00011869] [1:06:04.130406]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000142\n",
      "Training:  55%|█████▍    | 27399/50000 [1:06:18<51:42,  7.28it/s]  [Iteration 027400/050000] [BC: 0.00003605; Div: 0.00007895; For: 0.00014322] [1:06:18.540143]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000142\n",
      "Training:  55%|█████▍    | 27499/50000 [1:06:32<51:38,  7.26it/s]  [Iteration 027500/050000] [BC: 0.00003557; Div: 0.00005267; For: 0.00011745] [1:06:32.947864]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000141\n",
      "Training:  55%|█████▌    | 27599/50000 [1:06:47<50:51,  7.34it/s]  [Iteration 027600/050000] [BC: 0.00003568; Div: 0.00005895; For: 0.00012235] [1:06:47.245118]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000140\n",
      "Training:  55%|█████▌    | 27699/50000 [1:07:01<50:42,  7.33it/s]  [Iteration 027700/050000] [BC: 0.00003534; Div: 0.00004734; For: 0.00010422] [1:07:01.540537]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000140\n",
      "Training:  56%|█████▌    | 27799/50000 [1:07:15<50:29,  7.33it/s]  [Iteration 027800/050000] [BC: 0.00003670; Div: 0.00009063; For: 0.00016219] [1:07:15.850270]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000139\n",
      "Training:  56%|█████▌    | 27899/50000 [1:07:29<50:08,  7.35it/s]  [Iteration 027900/050000] [BC: 0.00003520; Div: 0.00005244; For: 0.00010924] [1:07:30.136679]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000138\n",
      "Training:  56%|█████▌    | 27999/50000 [1:07:44<50:06,  7.32it/s]  [Iteration 028000/050000] [BC: 0.00003621; Div: 0.00007376; For: 0.00013282] [1:07:44.438738]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000138\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 67.03it/s]\n",
      "Validation [Cube: BC: 0.769; Div: 0.007; For: 0.021; Sig: 3.779]\n",
      "Training:  56%|█████▌    | 28099/50000 [1:07:59<49:51,  7.32it/s]  [Iteration 028100/050000] [BC: 0.00003553; Div: 0.00005267; For: 0.00011228] [1:07:59.469296]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000137\n",
      "Training:  56%|█████▋    | 28199/50000 [1:08:13<49:31,  7.34it/s]  [Iteration 028200/050000] [BC: 0.00003594; Div: 0.00006443; For: 0.00013118] [1:08:13.764472]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000136\n",
      "Training:  57%|█████▋    | 28299/50000 [1:08:27<49:19,  7.33it/s]  [Iteration 028300/050000] [BC: 0.00003553; Div: 0.00005418; For: 0.00011413] [1:08:28.070155]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000136\n",
      "Training:  57%|█████▋    | 28399/50000 [1:08:42<49:10,  7.32it/s]  [Iteration 028400/050000] [BC: 0.00003579; Div: 0.00006209; For: 0.00012403] [1:08:42.359768]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000135\n",
      "Training:  57%|█████▋    | 28499/50000 [1:08:56<49:00,  7.31it/s]  [Iteration 028500/050000] [BC: 0.00003541; Div: 0.00005308; For: 0.00011510] [1:08:56.673584]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000135\n",
      "Training:  57%|█████▋    | 28599/50000 [1:09:10<48:41,  7.33it/s]  [Iteration 028600/050000] [BC: 0.00003580; Div: 0.00006027; For: 0.00011943] [1:09:10.977913]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000134\n",
      "Training:  57%|█████▋    | 28699/50000 [1:09:25<48:27,  7.33it/s]  [Iteration 028700/050000] [BC: 0.00003807; Div: 0.00012591; For: 0.00017793] [1:09:25.278116]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000133\n",
      "Training:  58%|█████▊    | 28799/50000 [1:09:39<48:12,  7.33it/s]  [Iteration 028800/050000] [BC: 0.00003503; Div: 0.00004514; For: 0.00009823] [1:09:39.608694]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000133\n",
      "Training:  58%|█████▊    | 28899/50000 [1:09:53<48:06,  7.31it/s]  [Iteration 028900/050000] [BC: 0.00003513; Div: 0.00004543; For: 0.00009941] [1:09:53.902367]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000132\n",
      "Training:  58%|█████▊    | 28999/50000 [1:10:07<47:50,  7.32it/s]  [Iteration 029000/050000] [BC: 0.00003568; Div: 0.00006312; For: 0.00013241] [1:10:08.196799]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000132\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.93it/s]\n",
      "Validation [Cube: BC: 0.763; Div: 0.009; For: 0.021; Sig: 3.697]\n",
      "Training:  58%|█████▊    | 29099/50000 [1:10:22<47:26,  7.34it/s]  [Iteration 029100/050000] [BC: 0.00003523; Div: 0.00004413; For: 0.00010046] [1:10:23.215683]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000131\n",
      "Training:  58%|█████▊    | 29199/50000 [1:10:37<47:17,  7.33it/s]  [Iteration 029200/050000] [BC: 0.00003698; Div: 0.00007811; For: 0.00015235] [1:10:37.507426]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000130\n",
      "Training:  59%|█████▊    | 29299/50000 [1:10:51<47:04,  7.33it/s]  [Iteration 029300/050000] [BC: 0.00003493; Div: 0.00004440; For: 0.00009496] [1:10:51.805936]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000130\n",
      "Training:  59%|█████▉    | 29399/50000 [1:11:11<47:15,  7.27it/s]   [Iteration 029400/050000] [BC: 0.00003557; Div: 0.00005768; For: 0.00012252] [1:11:11.938881]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000129\n",
      "Training:  59%|█████▉    | 29499/50000 [1:11:26<46:55,  7.28it/s]  [Iteration 029500/050000] [BC: 0.00003718; Div: 0.00008220; For: 0.00015931] [1:11:26.318458]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000129\n",
      "Training:  59%|█████▉    | 29599/50000 [1:11:40<46:24,  7.33it/s]  [Iteration 029600/050000] [BC: 0.00003499; Div: 0.00004314; For: 0.00009514] [1:11:40.647929]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000128\n",
      "Training:  59%|█████▉    | 29699/50000 [1:11:54<46:12,  7.32it/s]  [Iteration 029700/050000] [BC: 0.00003509; Div: 0.00004439; For: 0.00009751] [1:11:54.938114]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000127\n",
      "Training:  60%|█████▉    | 29799/50000 [1:12:09<45:55,  7.33it/s]  [Iteration 029800/050000] [BC: 0.00003541; Div: 0.00005808; For: 0.00012207] [1:12:09.255555]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000127\n",
      "Training:  60%|█████▉    | 29899/50000 [1:12:23<45:38,  7.34it/s]  [Iteration 029900/050000] [BC: 0.00003636; Div: 0.00008305; For: 0.00015015] [1:12:23.552281]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000126\n",
      "Training:  60%|█████▉    | 29999/50000 [1:12:37<45:24,  7.34it/s]  [Iteration 030000/050000] [BC: 0.00003496; Div: 0.00004346; For: 0.00009606] [1:12:37.846214]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000126\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.69it/s]\n",
      "Validation [Cube: BC: 0.736; Div: 0.009; For: 0.021; Sig: 3.689]\n",
      "Training:  60%|██████    | 30099/50000 [1:12:52<45:17,  7.32it/s]  [Iteration 030100/050000] [BC: 0.00003504; Div: 0.00004489; For: 0.00009849] [1:12:52.902283]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000125\n",
      "Training:  60%|██████    | 30199/50000 [1:13:07<45:01,  7.33it/s]  [Iteration 030200/050000] [BC: 0.00003550; Div: 0.00005095; For: 0.00010404] [1:13:07.238933]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000124\n",
      "Training:  61%|██████    | 30299/50000 [1:13:21<44:55,  7.31it/s]  [Iteration 030300/050000] [BC: 0.00003548; Div: 0.00005628; For: 0.00011705] [1:13:21.533210]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000124\n",
      "Training:  61%|██████    | 30399/50000 [1:13:35<44:52,  7.28it/s]  [Iteration 030400/050000] [BC: 0.00003553; Div: 0.00005644; For: 0.00011714] [1:13:35.933845]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000123\n",
      "Training:  61%|██████    | 30499/50000 [1:13:50<44:43,  7.27it/s]  [Iteration 030500/050000] [BC: 0.00003560; Div: 0.00005698; For: 0.00012181] [1:13:50.343621]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000123\n",
      "Training:  61%|██████    | 30599/50000 [1:14:04<44:28,  7.27it/s]  [Iteration 030600/050000] [BC: 0.00003557; Div: 0.00005509; For: 0.00011063] [1:14:04.740864]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000122\n",
      "Training:  61%|██████▏   | 30699/50000 [1:14:18<44:14,  7.27it/s]  [Iteration 030700/050000] [BC: 0.00003521; Div: 0.00005058; For: 0.00010533] [1:14:19.132348]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000122\n",
      "Training:  62%|██████▏   | 30799/50000 [1:14:33<43:57,  7.28it/s]  [Iteration 030800/050000] [BC: 0.00003627; Div: 0.00006644; For: 0.00013715] [1:14:33.549253]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000121\n",
      "Training:  62%|██████▏   | 30899/50000 [1:14:47<43:44,  7.28it/s]  [Iteration 030900/050000] [BC: 0.00003629; Div: 0.00008286; For: 0.00014706] [1:14:47.937714]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000120\n",
      "Training:  62%|██████▏   | 30999/50000 [1:15:02<43:32,  7.27it/s]  [Iteration 031000/050000] [BC: 0.00003518; Div: 0.00004874; For: 0.00009870] [1:15:02.327465]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000120\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.48it/s]\n",
      "Validation [Cube: BC: 0.750; Div: 0.008; For: 0.020; Sig: 3.677]\n",
      "Training:  62%|██████▏   | 31099/50000 [1:15:17<43:16,  7.28it/s]  [Iteration 031100/050000] [BC: 0.00003493; Div: 0.00004305; For: 0.00009462] [1:15:17.493180]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000119\n",
      "Training:  62%|██████▏   | 31199/50000 [1:15:31<43:04,  7.28it/s]  [Iteration 031200/050000] [BC: 0.00003529; Div: 0.00004906; For: 0.00010984] [1:15:31.885006]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000119\n",
      "Training:  63%|██████▎   | 31299/50000 [1:15:46<42:46,  7.29it/s]  [Iteration 031300/050000] [BC: 0.00003530; Div: 0.00005111; For: 0.00010590] [1:15:46.279993]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000118\n",
      "Training:  63%|██████▎   | 31399/50000 [1:16:00<42:38,  7.27it/s]  [Iteration 031400/050000] [BC: 0.00003579; Div: 0.00007286; For: 0.00013045] [1:16:00.676075]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000118\n",
      "Training:  63%|██████▎   | 31499/50000 [1:16:14<42:25,  7.27it/s]  [Iteration 031500/050000] [BC: 0.00003621; Div: 0.00006789; For: 0.00015430] [1:16:15.058366]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000117\n",
      "Training:  63%|██████▎   | 31599/50000 [1:16:29<42:14,  7.26it/s]  [Iteration 031600/050000] [BC: 0.00003484; Div: 0.00004188; For: 0.00009201] [1:16:29.445872]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000117\n",
      "Training:  63%|██████▎   | 31699/50000 [1:16:43<41:55,  7.27it/s]  [Iteration 031700/050000] [BC: 0.00003484; Div: 0.00004217; For: 0.00009300] [1:16:43.858793]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000116\n",
      "Training:  64%|██████▎   | 31799/50000 [1:16:58<41:41,  7.28it/s]  [Iteration 031800/050000] [BC: 0.00003499; Div: 0.00004711; For: 0.00009808] [1:16:58.261665]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000116\n",
      "Training:  64%|██████▍   | 31899/50000 [1:17:12<41:33,  7.26it/s]  [Iteration 031900/050000] [BC: 0.00003528; Div: 0.00005047; For: 0.00010274] [1:17:12.670130]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000115\n",
      "Training:  64%|██████▍   | 31999/50000 [1:17:26<41:16,  7.27it/s]  [Iteration 032000/050000] [BC: 0.00003545; Div: 0.00005251; For: 0.00011058] [1:17:27.069669]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000115\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.53it/s]\n",
      "Validation [Cube: BC: 0.778; Div: 0.007; For: 0.021; Sig: 3.827]\n",
      "Training:  64%|██████▍   | 32099/50000 [1:17:42<41:00,  7.28it/s]  [Iteration 032100/050000] [BC: 0.00003545; Div: 0.00006201; For: 0.00012300] [1:17:42.243904]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000114\n",
      "Training:  64%|██████▍   | 32199/50000 [1:17:56<40:39,  7.30it/s]  [Iteration 032200/050000] [BC: 0.00003512; Div: 0.00004392; For: 0.00010008] [1:17:56.631100]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000113\n",
      "Training:  65%|██████▍   | 32299/50000 [1:18:10<40:13,  7.33it/s]  [Iteration 032300/050000] [BC: 0.00003531; Div: 0.00004834; For: 0.00010764] [1:18:10.927442]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000113\n",
      "Training:  65%|██████▍   | 32399/50000 [1:18:25<39:57,  7.34it/s]  [Iteration 032400/050000] [BC: 0.00003503; Div: 0.00004700; For: 0.00010389] [1:18:25.251427]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000112\n",
      "Training:  65%|██████▍   | 32499/50000 [1:18:39<39:47,  7.33it/s]  [Iteration 032500/050000] [BC: 0.00003542; Div: 0.00005634; For: 0.00011245] [1:18:39.539590]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000112\n",
      "Training:  65%|██████▌   | 32599/50000 [1:18:53<39:36,  7.32it/s]  [Iteration 032600/050000] [BC: 0.00003563; Div: 0.00005519; For: 0.00011559] [1:18:53.855980]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000111\n",
      "Training:  65%|██████▌   | 32699/50000 [1:19:07<39:29,  7.30it/s]  [Iteration 032700/050000] [BC: 0.00003549; Div: 0.00006693; For: 0.00012299] [1:19:08.166648]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000111\n",
      "Training:  66%|██████▌   | 32799/50000 [1:19:22<39:12,  7.31it/s]  [Iteration 032800/050000] [BC: 0.00003509; Div: 0.00004493; For: 0.00009659] [1:19:22.473308]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000110\n",
      "Training:  66%|██████▌   | 32899/50000 [1:19:36<38:53,  7.33it/s]  [Iteration 032900/050000] [BC: 0.00003472; Div: 0.00004262; For: 0.00009385] [1:19:36.773434]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000110\n",
      "Training:  66%|██████▌   | 32999/50000 [1:19:50<38:33,  7.35it/s]  [Iteration 033000/050000] [BC: 0.00003529; Div: 0.00005443; For: 0.00011225] [1:19:51.056027]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000109\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 67.10it/s]\n",
      "Validation [Cube: BC: 0.768; Div: 0.009; For: 0.021; Sig: 3.732]\n",
      "Training:  66%|██████▌   | 33099/50000 [1:20:05<38:41,  7.28it/s]  [Iteration 033100/050000] [BC: 0.00003531; Div: 0.00005494; For: 0.00011388] [1:20:06.077400]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000109\n",
      "Training:  66%|██████▋   | 33199/50000 [1:20:20<38:09,  7.34it/s]  [Iteration 033200/050000] [BC: 0.00003493; Div: 0.00004451; For: 0.00009668] [1:20:20.376374]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000108\n",
      "Training:  67%|██████▋   | 33299/50000 [1:20:34<37:54,  7.34it/s]  [Iteration 033300/050000] [BC: 0.00003503; Div: 0.00004877; For: 0.00010006] [1:20:34.661392]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000108\n",
      "Training:  67%|██████▋   | 33399/50000 [1:20:48<37:45,  7.33it/s]  [Iteration 033400/050000] [BC: 0.00003549; Div: 0.00005573; For: 0.00011359] [1:20:48.943464]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000107\n",
      "Training:  67%|██████▋   | 33499/50000 [1:21:03<37:30,  7.33it/s]  [Iteration 033500/050000] [BC: 0.00003546; Div: 0.00005547; For: 0.00011362] [1:21:03.231501]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000107\n",
      "Training:  67%|██████▋   | 33599/50000 [1:21:17<37:14,  7.34it/s]  [Iteration 033600/050000] [BC: 0.00003509; Div: 0.00004956; For: 0.00010039] [1:21:17.541360]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000106\n",
      "Training:  67%|██████▋   | 33699/50000 [1:21:31<37:06,  7.32it/s]  [Iteration 033700/050000] [BC: 0.00003487; Div: 0.00004708; For: 0.00010048] [1:21:31.842327]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000106\n",
      "Training:  68%|██████▊   | 33799/50000 [1:21:45<36:45,  7.35it/s]  [Iteration 033800/050000] [BC: 0.00003522; Div: 0.00005508; For: 0.00011137] [1:21:46.132470]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000105\n",
      "Training:  68%|██████▊   | 33899/50000 [1:22:00<36:39,  7.32it/s]  [Iteration 033900/050000] [BC: 0.00003509; Div: 0.00004824; For: 0.00010621] [1:22:00.421746]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000105\n",
      "Training:  68%|██████▊   | 33999/50000 [1:22:14<36:16,  7.35it/s]  [Iteration 034000/050000] [BC: 0.00003511; Div: 0.00004988; For: 0.00010667] [1:22:14.722046]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000104\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 67.05it/s]\n",
      "Validation [Cube: BC: 0.753; Div: 0.008; For: 0.020; Sig: 3.661]\n",
      "Training:  68%|██████▊   | 34099/50000 [1:22:29<36:24,  7.28it/s]  [Iteration 034100/050000] [BC: 0.00003563; Div: 0.00007058; For: 0.00011905] [1:22:29.807964]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000104\n",
      "Training:  68%|██████▊   | 34199/50000 [1:22:43<36:09,  7.28it/s]  [Iteration 034200/050000] [BC: 0.00003510; Div: 0.00004590; For: 0.00009590] [1:22:44.215042]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000104\n",
      "Training:  69%|██████▊   | 34299/50000 [1:22:58<35:46,  7.32it/s]  [Iteration 034300/050000] [BC: 0.00003500; Div: 0.00004871; For: 0.00010268] [1:22:58.559174]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000103\n",
      "Training:  69%|██████▉   | 34399/50000 [1:23:12<35:30,  7.32it/s]  [Iteration 034400/050000] [BC: 0.00003503; Div: 0.00004992; For: 0.00010168] [1:23:12.854368]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000103\n",
      "Training:  69%|██████▉   | 34499/50000 [1:23:26<35:12,  7.34it/s]  [Iteration 034500/050000] [BC: 0.00003488; Div: 0.00004605; For: 0.00009945] [1:23:27.151511]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000102\n",
      "Training:  69%|██████▉   | 34599/50000 [1:23:41<34:57,  7.34it/s]  [Iteration 034600/050000] [BC: 0.00003482; Div: 0.00004281; For: 0.00009474] [1:23:41.441403]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000102\n",
      "Training:  69%|██████▉   | 34699/50000 [1:23:55<34:56,  7.30it/s]  [Iteration 034700/050000] [BC: 0.00003589; Div: 0.00007438; For: 0.00016157] [1:23:55.744216]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000101\n",
      "Training:  70%|██████▉   | 34799/50000 [1:24:09<34:30,  7.34it/s]  [Iteration 034800/050000] [BC: 0.00003473; Div: 0.00004324; For: 0.00009225] [1:24:10.053528]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000101\n",
      "Training:  70%|██████▉   | 34899/50000 [1:24:24<34:19,  7.33it/s]  [Iteration 034900/050000] [BC: 0.00003469; Div: 0.00004126; For: 0.00009057] [1:24:24.330419]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000100\n",
      "Training:  70%|██████▉   | 34999/50000 [1:24:38<34:07,  7.33it/s]  [Iteration 035000/050000] [BC: 0.00003474; Div: 0.00004383; For: 0.00009385] [1:24:38.613360]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000100\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.27it/s]\n",
      "Validation [Cube: BC: 0.758; Div: 0.007; For: 0.020; Sig: 3.659]\n",
      "Training:  70%|███████   | 35099/50000 [1:24:53<34:03,  7.29it/s]  [Iteration 035100/050000] [BC: 0.00003487; Div: 0.00004850; For: 0.00009793] [1:24:53.795138]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000099\n",
      "Training:  70%|███████   | 35199/50000 [1:25:07<33:54,  7.28it/s]  [Iteration 035200/050000] [BC: 0.00003514; Div: 0.00005195; For: 0.00010326] [1:25:08.179818]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000099\n",
      "Training:  71%|███████   | 35299/50000 [1:25:22<33:37,  7.29it/s]  [Iteration 035300/050000] [BC: 0.00003470; Div: 0.00004164; For: 0.00009311] [1:25:22.559944]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000098\n",
      "Training:  71%|███████   | 35399/50000 [1:25:36<33:26,  7.28it/s]  [Iteration 035400/050000] [BC: 0.00003528; Div: 0.00005526; For: 0.00010642] [1:25:36.945163]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000098\n",
      "Training:  71%|███████   | 35499/50000 [1:25:51<33:10,  7.29it/s]  [Iteration 035500/050000] [BC: 0.00003471; Div: 0.00004421; For: 0.00009605] [1:25:51.323050]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000097\n",
      "Training:  71%|███████   | 35599/50000 [1:26:05<32:59,  7.28it/s]  [Iteration 035600/050000] [BC: 0.00003483; Div: 0.00004683; For: 0.00010447] [1:26:05.700992]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000097\n",
      "Training:  71%|███████▏  | 35699/50000 [1:26:19<32:48,  7.27it/s]  [Iteration 035700/050000] [BC: 0.00003517; Div: 0.00004820; For: 0.00010651] [1:26:20.110681]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000097\n",
      "Training:  72%|███████▏  | 35799/50000 [1:26:34<32:33,  7.27it/s]  [Iteration 035800/050000] [BC: 0.00003501; Div: 0.00004856; For: 0.00010094] [1:26:34.505411]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000096\n",
      "Training:  72%|███████▏  | 35899/50000 [1:26:55<32:55,  7.14it/s]  [Iteration 035900/050000] [BC: 0.00003470; Div: 0.00004670; For: 0.00009650] [1:26:55.960114]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000096\n",
      "Training:  72%|███████▏  | 35999/50000 [1:27:10<32:40,  7.14it/s]  [Iteration 036000/050000] [BC: 0.00003507; Div: 0.00004913; For: 0.00010364] [1:27:10.628084]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000095\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 65.26it/s]\n",
      "Validation [Cube: BC: 0.760; Div: 0.009; For: 0.021; Sig: 3.790]\n",
      "Training:  72%|███████▏  | 36099/50000 [1:27:25<32:30,  7.13it/s]  [Iteration 036100/050000] [BC: 0.00003537; Div: 0.00005797; For: 0.00012596] [1:27:26.082054]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000095\n",
      "Training:  72%|███████▏  | 36199/50000 [1:27:40<32:18,  7.12it/s]  [Iteration 036200/050000] [BC: 0.00003459; Div: 0.00004425; For: 0.00009254] [1:27:40.771586]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000094\n",
      "Training:  73%|███████▎  | 36299/50000 [1:27:55<32:04,  7.12it/s]  [Iteration 036300/050000] [BC: 0.00003468; Div: 0.00004285; For: 0.00009198] [1:27:55.467222]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000094\n",
      "Training:  73%|███████▎  | 36399/50000 [1:28:09<31:49,  7.12it/s]  [Iteration 036400/050000] [BC: 0.00003474; Div: 0.00004266; For: 0.00009282] [1:28:10.156934]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000094\n",
      "Training:  73%|███████▎  | 36499/50000 [1:28:24<31:34,  7.13it/s]  [Iteration 036500/050000] [BC: 0.00003537; Div: 0.00005910; For: 0.00011464] [1:28:24.839682]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000093\n",
      "Training:  73%|███████▎  | 36599/50000 [1:28:39<31:19,  7.13it/s]  [Iteration 036600/050000] [BC: 0.00003457; Div: 0.00004311; For: 0.00009349] [1:28:39.530783]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000093\n",
      "Training:  73%|███████▎  | 36699/50000 [1:28:53<31:05,  7.13it/s]  [Iteration 036700/050000] [BC: 0.00003475; Div: 0.00004667; For: 0.00009772] [1:28:54.214904]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000092\n",
      "Training:  74%|███████▎  | 36799/50000 [1:29:08<30:52,  7.13it/s]  [Iteration 036800/050000] [BC: 0.00003461; Div: 0.00004444; For: 0.00009500] [1:29:08.900594]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000092\n",
      "Training:  74%|███████▍  | 36899/50000 [1:29:23<29:50,  7.32it/s]  [Iteration 036900/050000] [BC: 0.00003510; Div: 0.00005319; For: 0.00010861] [1:29:23.281478]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000091\n",
      "Training:  74%|███████▍  | 36999/50000 [1:29:37<29:35,  7.32it/s]  [Iteration 037000/050000] [BC: 0.00003486; Div: 0.00004851; For: 0.00009949] [1:29:37.587840]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000091\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.25it/s]\n",
      "Validation [Cube: BC: 0.744; Div: 0.007; For: 0.020; Sig: 3.622]\n",
      "Training:  74%|███████▍  | 37099/50000 [1:29:52<29:19,  7.33it/s]  [Iteration 037100/050000] [BC: 0.00003453; Div: 0.00004196; For: 0.00009064] [1:29:52.645131]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000091\n",
      "Training:  74%|███████▍  | 37199/50000 [1:30:06<29:10,  7.31it/s]  [Iteration 037200/050000] [BC: 0.00003484; Div: 0.00004436; For: 0.00009628] [1:30:06.936705]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000090\n",
      "Training:  75%|███████▍  | 37299/50000 [1:30:21<29:01,  7.29it/s]  [Iteration 037300/050000] [BC: 0.00003470; Div: 0.00004345; For: 0.00009369] [1:30:21.241788]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000090\n",
      "Training:  75%|███████▍  | 37399/50000 [1:30:35<28:38,  7.33it/s]  [Iteration 037400/050000] [BC: 0.00003491; Div: 0.00005188; For: 0.00010933] [1:30:35.545896]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000089\n",
      "Training:  75%|███████▍  | 37499/50000 [1:30:49<28:26,  7.32it/s]  [Iteration 037500/050000] [BC: 0.00003477; Div: 0.00004678; For: 0.00010004] [1:30:49.846334]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000089\n",
      "Training:  75%|███████▌  | 37599/50000 [1:31:03<28:12,  7.33it/s]  [Iteration 037600/050000] [BC: 0.00003452; Div: 0.00004254; For: 0.00009281] [1:31:04.149910]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000089\n",
      "Training:  75%|███████▌  | 37699/50000 [1:31:18<28:03,  7.31it/s]  [Iteration 037700/050000] [BC: 0.00003499; Div: 0.00004983; For: 0.00010940] [1:31:18.438235]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000088\n",
      "Training:  76%|███████▌  | 37799/50000 [1:31:32<27:46,  7.32it/s]  [Iteration 037800/050000] [BC: 0.00003469; Div: 0.00004468; For: 0.00009300] [1:31:32.749505]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000088\n",
      "Training:  76%|███████▌  | 37899/50000 [1:31:46<27:28,  7.34it/s]  [Iteration 037900/050000] [BC: 0.00003499; Div: 0.00005216; For: 0.00010718] [1:31:47.030282]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000087\n",
      "Training:  76%|███████▌  | 37999/50000 [1:32:01<27:16,  7.33it/s]  [Iteration 038000/050000] [BC: 0.00003458; Div: 0.00004184; For: 0.00009126] [1:32:01.311289]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000087\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.88it/s]\n",
      "Validation [Cube: BC: 0.750; Div: 0.008; For: 0.020; Sig: 3.604]\n",
      "Training:  76%|███████▌  | 38099/50000 [1:32:16<27:05,  7.32it/s]  [Iteration 038100/050000] [BC: 0.00003463; Div: 0.00004403; For: 0.00009650] [1:32:16.368670]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000086\n",
      "Training:  76%|███████▋  | 38199/50000 [1:32:30<26:50,  7.33it/s]  [Iteration 038200/050000] [BC: 0.00003475; Div: 0.00004771; For: 0.00009801] [1:32:30.663792]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000086\n",
      "Training:  77%|███████▋  | 38299/50000 [1:32:44<26:42,  7.30it/s]  [Iteration 038300/050000] [BC: 0.00003459; Div: 0.00004687; For: 0.00009706] [1:32:44.956552]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000086\n",
      "Training:  77%|███████▋  | 38399/50000 [1:32:59<26:25,  7.32it/s]  [Iteration 038400/050000] [BC: 0.00003449; Div: 0.00004221; For: 0.00009298] [1:32:59.244647]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000085\n",
      "Training:  77%|███████▋  | 38499/50000 [1:33:13<26:14,  7.30it/s]  [Iteration 038500/050000] [BC: 0.00003463; Div: 0.00004403; For: 0.00009486] [1:33:13.538271]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000085\n",
      "Training:  77%|███████▋  | 38599/50000 [1:33:27<25:53,  7.34it/s]  [Iteration 038600/050000] [BC: 0.00003483; Div: 0.00004930; For: 0.00010734] [1:33:27.826716]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000085\n",
      "Training:  77%|███████▋  | 38699/50000 [1:33:41<25:44,  7.32it/s]  [Iteration 038700/050000] [BC: 0.00003440; Div: 0.00004080; For: 0.00008891] [1:33:42.132814]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000084\n",
      "Training:  78%|███████▊  | 38799/50000 [1:33:56<25:41,  7.27it/s]  [Iteration 038800/050000] [BC: 0.00003447; Div: 0.00004154; For: 0.00009075] [1:33:56.503883]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000084\n",
      "Training:  78%|███████▊  | 38899/50000 [1:34:10<25:10,  7.35it/s]  [Iteration 038900/050000] [BC: 0.00003471; Div: 0.00004645; For: 0.00009738] [1:34:10.889321]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000083\n",
      "Training:  78%|███████▊  | 38999/50000 [1:34:24<24:59,  7.33it/s]  [Iteration 039000/050000] [BC: 0.00003474; Div: 0.00004963; For: 0.00010238] [1:34:25.209813]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000083\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.59it/s]\n",
      "Validation [Cube: BC: 0.765; Div: 0.008; For: 0.020; Sig: 3.623]\n",
      "Training:  78%|███████▊  | 39099/50000 [1:34:40<24:55,  7.29it/s]  [Iteration 039100/050000] [BC: 0.00003452; Div: 0.00004348; For: 0.00009421] [1:34:40.285150]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000083\n",
      "Training:  78%|███████▊  | 39199/50000 [1:34:54<24:29,  7.35it/s]  [Iteration 039200/050000] [BC: 0.00003440; Div: 0.00004256; For: 0.00009064] [1:34:54.599799]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000082\n",
      "Training:  79%|███████▊  | 39299/50000 [1:35:08<24:23,  7.31it/s][Iteration 039300/050000] [BC: 0.00003468; Div: 0.00004760; For: 0.00009789] [1:35:08.916442]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000082\n",
      "Training:  79%|███████▉  | 39399/50000 [1:35:22<24:06,  7.33it/s][Iteration 039400/050000] [BC: 0.00003477; Div: 0.00004829; For: 0.00010260] [1:35:23.209560]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000081\n",
      "Training:  79%|███████▉  | 39499/50000 [1:35:37<23:55,  7.32it/s][Iteration 039500/050000] [BC: 0.00003450; Div: 0.00004360; For: 0.00009215] [1:35:37.515475]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000081\n",
      "Training:  79%|███████▉  | 39599/50000 [1:35:51<23:45,  7.30it/s][Iteration 039600/050000] [BC: 0.00003446; Div: 0.00004269; For: 0.00009335] [1:35:51.827302]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000081\n",
      "Training:  79%|███████▉  | 39699/50000 [1:36:05<23:33,  7.29it/s][Iteration 039700/050000] [BC: 0.00003457; Div: 0.00004423; For: 0.00009591] [1:36:06.184877]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000080\n",
      "Training:  80%|███████▉  | 39799/50000 [1:36:20<23:23,  7.27it/s][Iteration 039800/050000] [BC: 0.00003463; Div: 0.00004524; For: 0.00009524] [1:36:20.594274]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000080\n",
      "Training:  80%|███████▉  | 39899/50000 [1:36:34<23:09,  7.27it/s][Iteration 039900/050000] [BC: 0.00003457; Div: 0.00004457; For: 0.00009365] [1:36:34.991894]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000080\n",
      "Training:  80%|███████▉  | 39999/50000 [1:36:49<22:53,  7.28it/s][Iteration 040000/050000] [BC: 0.00003437; Div: 0.00004127; For: 0.00009099] [1:36:49.391462]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000079\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.68it/s]\n",
      "Validation [Cube: BC: 0.754; Div: 0.008; For: 0.020; Sig: 3.635]\n",
      "Training:  80%|████████  | 40099/50000 [1:37:04<22:39,  7.28it/s]  [Iteration 040100/050000] [BC: 0.00003469; Div: 0.00004761; For: 0.00010072] [1:37:04.549272]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000079\n",
      "Training:  80%|████████  | 40199/50000 [1:37:18<22:29,  7.26it/s][Iteration 040200/050000] [BC: 0.00003443; Div: 0.00004562; For: 0.00009431] [1:37:18.949173]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000079\n",
      "Training:  81%|████████  | 40299/50000 [1:37:33<22:11,  7.29it/s][Iteration 040300/050000] [BC: 0.00003463; Div: 0.00004676; For: 0.00009849] [1:37:33.348267]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000078\n",
      "Training:  81%|████████  | 40399/50000 [1:37:47<21:59,  7.27it/s][Iteration 040400/050000] [BC: 0.00003439; Div: 0.00004175; For: 0.00009212] [1:37:47.756999]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000078\n",
      "Training:  81%|████████  | 40499/50000 [1:38:01<21:47,  7.27it/s][Iteration 040500/050000] [BC: 0.00003440; Div: 0.00004365; For: 0.00009275] [1:38:02.152904]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000077\n",
      "Training:  81%|████████  | 40599/50000 [1:38:16<21:35,  7.26it/s][Iteration 040600/050000] [BC: 0.00003445; Div: 0.00004546; For: 0.00009653] [1:38:16.567024]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000077\n",
      "Training:  81%|████████▏ | 40699/50000 [1:38:30<21:18,  7.28it/s][Iteration 040700/050000] [BC: 0.00003436; Div: 0.00004288; For: 0.00009207] [1:38:30.965174]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000077\n",
      "Training:  82%|████████▏ | 40799/50000 [1:38:45<21:05,  7.27it/s][Iteration 040800/050000] [BC: 0.00003446; Div: 0.00004288; For: 0.00009345] [1:38:45.374995]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000076\n",
      "Training:  82%|████████▏ | 40899/50000 [1:38:59<20:53,  7.26it/s][Iteration 040900/050000] [BC: 0.00003452; Div: 0.00004269; For: 0.00009078] [1:38:59.785634]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000076\n",
      "Training:  82%|████████▏ | 40999/50000 [1:39:13<20:37,  7.28it/s][Iteration 041000/050000] [BC: 0.00003443; Div: 0.00004382; For: 0.00009465] [1:39:14.200181]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000076\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.39it/s]\n",
      "Validation [Cube: BC: 0.756; Div: 0.008; For: 0.020; Sig: 3.641]\n",
      "Training:  82%|████████▏ | 41099/50000 [1:39:29<20:24,  7.27it/s]  [Iteration 041100/050000] [BC: 0.00003439; Div: 0.00004572; For: 0.00009932] [1:39:29.383349]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000075\n",
      "Training:  82%|████████▏ | 41199/50000 [1:39:43<20:11,  7.27it/s][Iteration 041200/050000] [BC: 0.00003440; Div: 0.00004179; For: 0.00009184] [1:39:43.782892]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000075\n",
      "Training:  83%|████████▎ | 41299/50000 [1:39:57<19:55,  7.28it/s][Iteration 041300/050000] [BC: 0.00003425; Div: 0.00004101; For: 0.00008838] [1:39:58.191198]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000075\n",
      "Training:  83%|████████▎ | 41399/50000 [1:40:12<19:41,  7.28it/s][Iteration 041400/050000] [BC: 0.00003444; Div: 0.00004230; For: 0.00009189] [1:40:12.591016]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000074\n",
      "Training:  83%|████████▎ | 41499/50000 [1:40:26<19:30,  7.26it/s][Iteration 041500/050000] [BC: 0.00003448; Div: 0.00004576; For: 0.00009674] [1:40:27.009086]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000074\n",
      "Training:  83%|████████▎ | 41599/50000 [1:40:41<19:05,  7.33it/s][Iteration 041600/050000] [BC: 0.00003431; Div: 0.00004359; For: 0.00009178] [1:40:41.318038]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000074\n",
      "Training:  83%|████████▎ | 41699/50000 [1:40:55<18:50,  7.34it/s][Iteration 041700/050000] [BC: 0.00003441; Div: 0.00004312; For: 0.00009105] [1:40:55.596355]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000073\n",
      "Training:  84%|████████▎ | 41799/50000 [1:41:09<18:38,  7.33it/s][Iteration 041800/050000] [BC: 0.00003435; Div: 0.00004165; For: 0.00009239] [1:41:09.884105]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000073\n",
      "Training:  84%|████████▍ | 41899/50000 [1:41:23<18:21,  7.35it/s][Iteration 041900/050000] [BC: 0.00003462; Div: 0.00004775; For: 0.00010418] [1:41:24.176675]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000073\n",
      "Training:  84%|████████▍ | 41999/50000 [1:41:38<18:13,  7.31it/s][Iteration 042000/050000] [BC: 0.00003431; Div: 0.00004387; For: 0.00009101] [1:41:38.470045]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000072\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.61it/s]\n",
      "Validation [Cube: BC: 0.744; Div: 0.009; For: 0.020; Sig: 3.572]\n",
      "Training:  84%|████████▍ | 42099/50000 [1:41:53<18:00,  7.31it/s]  [Iteration 042100/050000] [BC: 0.00003419; Div: 0.00004006; For: 0.00008748] [1:41:53.492346]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000072\n",
      "Training:  84%|████████▍ | 42199/50000 [1:42:07<17:46,  7.32it/s][Iteration 042200/050000] [BC: 0.00003425; Div: 0.00004283; For: 0.00009012] [1:42:07.797591]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000072\n",
      "Training:  85%|████████▍ | 42299/50000 [1:42:21<17:30,  7.33it/s][Iteration 042300/050000] [BC: 0.00003426; Div: 0.00004037; For: 0.00008831] [1:42:22.099728]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000071\n",
      "Training:  85%|████████▍ | 42399/50000 [1:42:36<17:16,  7.33it/s][Iteration 042400/050000] [BC: 0.00003478; Div: 0.00005704; For: 0.00011087] [1:42:36.423181]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000071\n",
      "Training:  85%|████████▍ | 42499/50000 [1:42:50<17:04,  7.32it/s][Iteration 042500/050000] [BC: 0.00003462; Div: 0.00004906; For: 0.00009619] [1:42:50.776681]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000071\n",
      "Training:  85%|████████▌ | 42599/50000 [1:43:04<16:50,  7.32it/s][Iteration 042600/050000] [BC: 0.00003408; Div: 0.00003934; For: 0.00008578] [1:43:05.068734]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000070\n",
      "Training:  85%|████████▌ | 42699/50000 [1:43:19<16:38,  7.31it/s][Iteration 042700/050000] [BC: 0.00003417; Div: 0.00003992; For: 0.00008765] [1:43:19.364384]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000070\n",
      "Training:  86%|████████▌ | 42799/50000 [1:43:33<16:26,  7.30it/s][Iteration 042800/050000] [BC: 0.00003418; Div: 0.00004001; For: 0.00008745] [1:43:33.676463]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000070\n",
      "Training:  86%|████████▌ | 42899/50000 [1:43:47<16:07,  7.34it/s][Iteration 042900/050000] [BC: 0.00003414; Div: 0.00003977; For: 0.00008697] [1:43:47.964752]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000069\n",
      "Training:  86%|████████▌ | 42999/50000 [1:44:02<15:55,  7.32it/s][Iteration 043000/050000] [BC: 0.00003439; Div: 0.00004397; For: 0.00009761] [1:44:02.258666]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000069\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.55it/s]\n",
      "Validation [Cube: BC: 0.756; Div: 0.006; For: 0.020; Sig: 3.528]\n",
      "Training:  86%|████████▌ | 43099/50000 [1:44:17<15:40,  7.34it/s]  [Iteration 043100/050000] [BC: 0.00003479; Div: 0.00005481; For: 0.00011246] [1:44:17.279475]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000069\n",
      "Training:  86%|████████▋ | 43199/50000 [1:44:31<15:25,  7.35it/s][Iteration 043200/050000] [BC: 0.00003418; Div: 0.00003913; For: 0.00008654] [1:44:31.582411]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000068\n",
      "Training:  87%|████████▋ | 43299/50000 [1:44:45<15:15,  7.32it/s][Iteration 043300/050000] [BC: 0.00003408; Div: 0.00003970; For: 0.00008637] [1:44:45.885166]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000068\n",
      "Training:  87%|████████▋ | 43399/50000 [1:44:59<15:08,  7.26it/s][Iteration 043400/050000] [BC: 0.00003420; Div: 0.00004007; For: 0.00008814] [1:45:00.213790]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000068\n",
      "Training:  87%|████████▋ | 43499/50000 [1:45:14<14:52,  7.29it/s][Iteration 043500/050000] [BC: 0.00003422; Div: 0.00004184; For: 0.00008970] [1:45:14.604895]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000067\n",
      "Training:  87%|████████▋ | 43599/50000 [1:45:28<14:32,  7.34it/s][Iteration 043600/050000] [BC: 0.00003412; Div: 0.00003964; For: 0.00008648] [1:45:28.959641]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000067\n",
      "Training:  87%|████████▋ | 43699/50000 [1:45:51<14:17,  7.35it/s]  [Iteration 043700/050000] [BC: 0.00003430; Div: 0.00004780; For: 0.00009682] [1:45:51.390610]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000067\n",
      "Training:  88%|████████▊ | 43799/50000 [1:46:05<14:04,  7.34it/s][Iteration 043800/050000] [BC: 0.00003414; Div: 0.00004011; For: 0.00008774] [1:46:05.671115]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000067\n",
      "Training:  88%|████████▊ | 43899/50000 [1:46:19<13:51,  7.34it/s][Iteration 043900/050000] [BC: 0.00003405; Div: 0.00003935; For: 0.00008592] [1:46:19.963204]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000066\n",
      "Training:  88%|████████▊ | 43999/50000 [1:46:34<13:37,  7.34it/s][Iteration 044000/050000] [BC: 0.00003415; Div: 0.00004242; For: 0.00009222] [1:46:34.236034]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000066\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.75it/s]\n",
      "Validation [Cube: BC: 0.751; Div: 0.007; For: 0.020; Sig: 3.606]\n",
      "Training:  88%|████████▊ | 44099/50000 [1:46:49<13:24,  7.33it/s][Iteration 044100/050000] [BC: 0.00003424; Div: 0.00004027; For: 0.00008812] [1:46:49.242962]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000066\n",
      "Training:  88%|████████▊ | 44199/50000 [1:47:03<13:11,  7.33it/s][Iteration 044200/050000] [BC: 0.00003441; Div: 0.00004612; For: 0.00009786] [1:47:03.533024]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000065\n",
      "Training:  89%|████████▊ | 44299/50000 [1:47:17<13:04,  7.26it/s][Iteration 044300/050000] [BC: 0.00003411; Div: 0.00004060; For: 0.00008800] [1:47:17.862517]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000065\n",
      "Training:  89%|████████▉ | 44399/50000 [1:47:32<12:50,  7.27it/s][Iteration 044400/050000] [BC: 0.00003412; Div: 0.00004006; For: 0.00008736] [1:47:32.251119]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000065\n",
      "Training:  89%|████████▉ | 44499/50000 [1:47:46<12:37,  7.26it/s][Iteration 044500/050000] [BC: 0.00003436; Div: 0.00004804; For: 0.00009853] [1:47:46.647297]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000064\n",
      "Training:  89%|████████▉ | 44599/50000 [1:48:00<12:21,  7.28it/s][Iteration 044600/050000] [BC: 0.00003408; Div: 0.00003977; For: 0.00008648] [1:48:01.029027]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000064\n",
      "Training:  89%|████████▉ | 44699/50000 [1:48:15<12:24,  7.12it/s][Iteration 044700/050000] [BC: 0.00003432; Div: 0.00004919; For: 0.00009711] [1:48:15.487199]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000064\n",
      "Training:  90%|████████▉ | 44799/50000 [1:48:29<12:09,  7.13it/s][Iteration 044800/050000] [BC: 0.00003404; Div: 0.00003959; For: 0.00008580] [1:48:30.158912]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000064\n",
      "Training:  90%|████████▉ | 44899/50000 [1:48:44<11:55,  7.13it/s][Iteration 044900/050000] [BC: 0.00003402; Div: 0.00003948; For: 0.00008551] [1:48:44.845791]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000063\n",
      "Training:  90%|████████▉ | 44999/50000 [1:48:59<11:40,  7.14it/s][Iteration 045000/050000] [BC: 0.00003403; Div: 0.00004142; For: 0.00008841] [1:48:59.529333]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000063\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 64.84it/s]\n",
      "Validation [Cube: BC: 0.746; Div: 0.007; For: 0.020; Sig: 3.549]\n",
      "Training:  90%|█████████ | 45099/50000 [1:49:14<11:27,  7.13it/s][Iteration 045100/050000] [BC: 0.00003418; Div: 0.00004254; For: 0.00009180] [1:49:14.965222]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000063\n",
      "Training:  90%|█████████ | 45199/50000 [1:49:29<11:12,  7.14it/s][Iteration 045200/050000] [BC: 0.00003419; Div: 0.00004137; For: 0.00008922] [1:49:29.656061]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000062\n",
      "Training:  91%|█████████ | 45299/50000 [1:49:44<10:58,  7.14it/s][Iteration 045300/050000] [BC: 0.00003410; Div: 0.00003993; For: 0.00008736] [1:49:44.338979]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000062\n",
      "Training:  91%|█████████ | 45399/50000 [1:49:58<10:45,  7.12it/s][Iteration 045400/050000] [BC: 0.00003416; Div: 0.00004135; For: 0.00009026] [1:49:59.035947]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000062\n",
      "Training:  91%|█████████ | 45499/50000 [1:50:13<10:30,  7.14it/s][Iteration 045500/050000] [BC: 0.00003410; Div: 0.00004063; For: 0.00008824] [1:50:13.722903]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000062\n",
      "Training:  91%|█████████ | 45599/50000 [1:50:28<10:19,  7.11it/s][Iteration 045600/050000] [BC: 0.00003409; Div: 0.00004053; For: 0.00008835] [1:50:28.408367]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000061\n",
      "Training:  91%|█████████▏| 45699/50000 [1:50:42<10:04,  7.12it/s][Iteration 045700/050000] [BC: 0.00003421; Div: 0.00004350; For: 0.00009318] [1:50:43.083636]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000061\n",
      "Training:  92%|█████████▏| 45799/50000 [1:50:57<09:48,  7.14it/s][Iteration 045800/050000] [BC: 0.00003404; Div: 0.00003928; For: 0.00008637] [1:50:57.740943]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000061\n",
      "Training:  92%|█████████▏| 45899/50000 [1:51:12<09:35,  7.13it/s][Iteration 045900/050000] [BC: 0.00003410; Div: 0.00004230; For: 0.00008999] [1:51:12.414884]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000060\n",
      "Training:  92%|█████████▏| 45999/50000 [1:51:26<09:19,  7.15it/s][Iteration 046000/050000] [BC: 0.00003404; Div: 0.00003964; For: 0.00008682] [1:51:27.123983]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000060\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 64.17it/s]\n",
      "Validation [Cube: BC: 0.722; Div: 0.008; For: 0.020; Sig: 3.489]\n",
      "Training:  92%|█████████▏| 46099/50000 [1:51:42<09:05,  7.15it/s][Iteration 046100/050000] [BC: 0.00003403; Div: 0.00004093; For: 0.00008790] [1:51:42.536518]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000060\n",
      "Training:  92%|█████████▏| 46199/50000 [1:51:56<08:37,  7.35it/s][Iteration 046200/050000] [BC: 0.00003423; Div: 0.00004293; For: 0.00009218] [1:51:56.897645]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000060\n",
      "Training:  93%|█████████▎| 46299/50000 [1:52:10<08:25,  7.32it/s][Iteration 046300/050000] [BC: 0.00003427; Div: 0.00004482; For: 0.00009615] [1:52:11.202518]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000059\n",
      "Training:  93%|█████████▎| 46399/50000 [1:52:25<08:19,  7.20it/s][Iteration 046400/050000] [BC: 0.00003396; Div: 0.00003974; For: 0.00008634] [1:52:25.524169]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000059\n",
      "Training:  93%|█████████▎| 46499/50000 [1:52:39<07:57,  7.33it/s][Iteration 046500/050000] [BC: 0.00003395; Div: 0.00004026; For: 0.00008761] [1:52:39.807515]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000059\n",
      "Training:  93%|█████████▎| 46599/50000 [1:52:53<07:43,  7.34it/s][Iteration 046600/050000] [BC: 0.00003397; Div: 0.00004020; For: 0.00008695] [1:52:54.114022]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000058\n",
      "Training:  93%|█████████▎| 46699/50000 [1:53:08<07:30,  7.32it/s][Iteration 046700/050000] [BC: 0.00003404; Div: 0.00004096; For: 0.00008785] [1:53:08.413701]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000058\n",
      "Training:  94%|█████████▎| 46799/50000 [1:53:22<07:18,  7.29it/s][Iteration 046800/050000] [BC: 0.00003395; Div: 0.00004074; For: 0.00008667] [1:53:22.722066]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000058\n",
      "Training:  94%|█████████▍| 46899/50000 [1:53:36<07:03,  7.31it/s][Iteration 046900/050000] [BC: 0.00003402; Div: 0.00004301; For: 0.00009133] [1:53:37.025454]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000058\n",
      "Training:  94%|█████████▍| 46999/50000 [1:53:51<06:49,  7.33it/s][Iteration 047000/050000] [BC: 0.00003398; Div: 0.00004091; For: 0.00008792] [1:53:51.331986]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000057\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.17it/s]\n",
      "Validation [Cube: BC: 0.746; Div: 0.007; For: 0.020; Sig: 3.535]\n",
      "Training:  94%|█████████▍| 47099/50000 [1:54:06<06:35,  7.33it/s][Iteration 047100/050000] [BC: 0.00003395; Div: 0.00003948; For: 0.00008627] [1:54:06.414618]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000057\n",
      "Training:  94%|█████████▍| 47199/50000 [1:54:20<06:20,  7.35it/s][Iteration 047200/050000] [BC: 0.00003402; Div: 0.00004215; For: 0.00008907] [1:54:20.721855]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000057\n",
      "Training:  95%|█████████▍| 47299/50000 [1:54:34<06:07,  7.34it/s][Iteration 047300/050000] [BC: 0.00003392; Div: 0.00004086; For: 0.00008821] [1:54:35.021453]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000057\n",
      "Training:  95%|█████████▍| 47399/50000 [1:54:49<05:54,  7.35it/s][Iteration 047400/050000] [BC: 0.00003390; Div: 0.00004008; For: 0.00008645] [1:54:49.318503]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000056\n",
      "Training:  95%|█████████▍| 47499/50000 [1:55:03<05:41,  7.32it/s][Iteration 047500/050000] [BC: 0.00003406; Div: 0.00004130; For: 0.00008966] [1:55:03.614484]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000056\n",
      "Training:  95%|█████████▌| 47599/50000 [1:55:17<05:27,  7.33it/s][Iteration 047600/050000] [BC: 0.00003394; Div: 0.00004008; For: 0.00008732] [1:55:17.921750]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000056\n",
      "Training:  95%|█████████▌| 47699/50000 [1:55:31<05:13,  7.34it/s][Iteration 047700/050000] [BC: 0.00003405; Div: 0.00004282; For: 0.00009233] [1:55:32.209992]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000056\n",
      "Training:  96%|█████████▌| 47799/50000 [1:55:46<05:01,  7.31it/s][Iteration 047800/050000] [BC: 0.00003387; Div: 0.00004125; For: 0.00008718] [1:55:46.500506]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000055\n",
      "Training:  96%|█████████▌| 47899/50000 [1:56:00<04:47,  7.31it/s][Iteration 047900/050000] [BC: 0.00003397; Div: 0.00004017; For: 0.00008822] [1:56:00.788830]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000055\n",
      "Training:  96%|█████████▌| 47999/50000 [1:56:14<04:34,  7.28it/s][Iteration 048000/050000] [BC: 0.00003387; Div: 0.00003880; For: 0.00008462] [1:56:15.092029]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000055\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.59it/s]\n",
      "Validation [Cube: BC: 0.746; Div: 0.008; For: 0.020; Sig: 3.531]\n",
      "Training:  96%|█████████▌| 48099/50000 [1:56:30<04:21,  7.27it/s][Iteration 048100/050000] [BC: 0.00003380; Div: 0.00004017; For: 0.00008649] [1:56:30.252117]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000055\n",
      "Training:  96%|█████████▋| 48199/50000 [1:56:44<04:06,  7.32it/s][Iteration 048200/050000] [BC: 0.00003387; Div: 0.00004061; For: 0.00008742] [1:56:44.613637]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000054\n",
      "Training:  97%|█████████▋| 48299/50000 [1:56:58<03:51,  7.34it/s][Iteration 048300/050000] [BC: 0.00003397; Div: 0.00004071; For: 0.00008780] [1:56:58.911776]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000054\n",
      "Training:  97%|█████████▋| 48399/50000 [1:57:12<03:39,  7.31it/s][Iteration 048400/050000] [BC: 0.00003393; Div: 0.00004011; For: 0.00008683] [1:57:13.206417]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000054\n",
      "Training:  97%|█████████▋| 48499/50000 [1:57:27<03:24,  7.33it/s][Iteration 048500/050000] [BC: 0.00003393; Div: 0.00004195; For: 0.00008915] [1:57:27.512116]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000054\n",
      "Training:  97%|█████████▋| 48599/50000 [1:57:41<03:11,  7.33it/s][Iteration 048600/050000] [BC: 0.00003388; Div: 0.00003895; For: 0.00008529] [1:57:41.819009]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000053\n",
      "Training:  97%|█████████▋| 48699/50000 [1:57:55<02:57,  7.33it/s][Iteration 048700/050000] [BC: 0.00003406; Div: 0.00004747; For: 0.00009593] [1:57:56.111484]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000053\n",
      "Training:  98%|█████████▊| 48799/50000 [1:58:10<02:43,  7.32it/s][Iteration 048800/050000] [BC: 0.00003387; Div: 0.00003952; For: 0.00008630] [1:58:10.418284]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000053\n",
      "Training:  98%|█████████▊| 48899/50000 [1:58:24<02:30,  7.33it/s][Iteration 048900/050000] [BC: 0.00003389; Div: 0.00003905; For: 0.00008470] [1:58:24.717972]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000053\n",
      "Training:  98%|█████████▊| 48999/50000 [1:58:38<02:17,  7.29it/s][Iteration 049000/050000] [BC: 0.00003381; Div: 0.00003869; For: 0.00008461] [1:58:39.080160]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000052\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 66.55it/s]\n",
      "Validation [Cube: BC: 0.736; Div: 0.008; For: 0.020; Sig: 3.495]\n",
      "Training:  98%|█████████▊| 49099/50000 [1:58:53<02:03,  7.28it/s][Iteration 049100/050000] [BC: 0.00003377; Div: 0.00003869; For: 0.00008447] [1:58:54.213190]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000052\n",
      "Training:  98%|█████████▊| 49199/50000 [1:59:08<01:52,  7.12it/s][Iteration 049200/050000] [BC: 0.00003403; Div: 0.00004328; For: 0.00009165] [1:59:08.888837]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000052\n",
      "Training:  99%|█████████▊| 49299/50000 [1:59:23<01:38,  7.10it/s][Iteration 049300/050000] [BC: 0.00003389; Div: 0.00003957; For: 0.00008590] [1:59:23.571655]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000052\n",
      "Training:  99%|█████████▉| 49399/50000 [1:59:38<01:24,  7.11it/s][Iteration 049400/050000] [BC: 0.00003373; Div: 0.00003944; For: 0.00008518] [1:59:38.277877]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000051\n",
      "Training:  99%|█████████▉| 49499/50000 [1:59:52<01:10,  7.10it/s][Iteration 049500/050000] [BC: 0.00003384; Div: 0.00004144; For: 0.00008816] [1:59:52.959647]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000051\n",
      "Training:  99%|█████████▉| 49599/50000 [2:00:07<00:56,  7.12it/s][Iteration 049600/050000] [BC: 0.00003383; Div: 0.00004255; For: 0.00008970] [2:00:07.638367]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000051\n",
      "Training:  99%|█████████▉| 49699/50000 [2:00:22<00:42,  7.12it/s][Iteration 049700/050000] [BC: 0.00003370; Div: 0.00003924; For: 0.00008483] [2:00:22.315865]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000051\n",
      "Training: 100%|█████████▉| 49799/50000 [2:00:36<00:28,  7.12it/s][Iteration 049800/050000] [BC: 0.00003379; Div: 0.00003940; For: 0.00008513] [2:00:37.021201]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000050\n",
      "Training: 100%|█████████▉| 49899/50000 [2:00:51<00:14,  7.15it/s][Iteration 049900/050000] [BC: 0.00003378; Div: 0.00003893; For: 0.00008506] [2:00:51.711468]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000050\n",
      "Training: 100%|█████████▉| 49999/50000 [2:01:06<00:00,  7.15it/s][Iteration 050000/050000] [BC: 0.00003397; Div: 0.00004156; For: 0.00008806] [2:01:06.388808]\n",
      "Lambda B: 0.999724\n",
      "LR: 0.000050\n",
      "Validation: 100%|██████████| 27/27 [00:00<00:00, 64.87it/s]\n",
      "Validation [Cube: BC: 0.739; Div: 0.007; For: 0.020; Sig: 3.541]\n",
      "Training: 100%|██████████| 50000/50000 [2:01:07<00:00,  6.88it/s]\n",
      "TOTAL RUNTIME: 2:01:07.800457\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "trainer.train(total_iterations, batch_size, \n",
    "              log_interval=log_interval, validation_interval=validation_interval, \n",
    "              num_workers=num_workers)\n",
    "log.info(f'TOTAL RUNTIME: {datetime.now() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = load_cube('/home/tensor/workspace/pinn_study/organize/run/dim256_bin1_pfTrue_ld0.1_lf0.1/extrapolation_result.nf2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential Field: 100%|██████████| 6/6 [00:00<00:00, 26.20it/s]\n",
      "Potential Field: 100%|██████████| 6/6 [00:00<00:00, 29.46it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics(B, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
