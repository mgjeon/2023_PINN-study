{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 16 from C header, got 96 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 96 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from datetime import datetime\n",
    "from astropy.nddata import block_reduce\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda import get_device_name\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nf2.data.dataset import ImageDataset\n",
    "from nf2.data.loader import _load_potential_field_data, RandomCoordinateSampler\n",
    "from nf2.train.model import BModel, jacobian, VectorPotentialModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nlfff:\n",
    "\n",
    "      def __init__(self,filename):\n",
    "            self.filename=filename\n",
    "\n",
    "            nc=netCDF4.Dataset(self.filename,'r')\n",
    "            self.NOAA=nc.NOAA\n",
    "            self.year_month_day_time=nc.year_month_day_time\n",
    "            self.project=nc.project\n",
    "            self.production_date=nc.production_date\n",
    "            self.version=nc.version\n",
    "            self.data_doi=nc.data_doi\n",
    "            self.http_link=nc.http_link\n",
    "            self.Distributor=nc.Distributor\n",
    "            \n",
    "            nc_x=nc.variables['x']\n",
    "            self.x=nc_x[:]\n",
    "            print(nc_x.long_name,' unit:',nc_x.units)\n",
    "            nc_y=nc.variables['y']\n",
    "            self.y=nc_y[:]\n",
    "            print(nc_y.long_name,' unit:',nc_y.units)\n",
    "            nc_z=nc.variables['z']\n",
    "            self.z=nc_z[:]\n",
    "            print(nc_z.long_name,' unit:',nc_z.units)\n",
    "            \n",
    "            nc_bx=nc.variables['Bx']\n",
    "            self.bx=nc_bx[:].transpose(2,1,0)\n",
    "            print(nc_bx.long_name,' unit:',nc_bx.units)\n",
    "            nc_by=nc.variables['By']\n",
    "            self.by=nc_by[:].transpose(2,1,0)\n",
    "            print(nc_by.long_name,' unit:',nc_by.units)\n",
    "            nc_bz=nc.variables['Bz']\n",
    "            self.bz=nc_bz[:].transpose(2,1,0)\n",
    "            print(nc_bz.long_name,' unit:',nc_bz.units)\n",
    "            \n",
    "            nc_bxp=nc.variables['Bx_pot']\n",
    "            self.bx_pot=nc_bxp[:].transpose(2,1,0)\n",
    "            print(nc_bxp.long_name,' unit:',nc_bxp.units)\n",
    "            nc_byp=nc.variables['By_pot']\n",
    "            self.by_pot=nc_byp[:].transpose(2,1,0)\n",
    "            print(nc_byp.long_name,' unit:',nc_byp.units)\n",
    "            nc_bzp=nc.variables['Bz_pot']\n",
    "            self.bz_pot=nc_bzp[:].transpose(2,1,0)\n",
    "            print(nc_bzp.long_name,' unit:',nc_bzp.units)\n",
    "            \n",
    "      def info(self):\n",
    "            self.Lx_Mm=max(self.x) - min(self.x)\n",
    "            self.Ly_Mm=max(self.y) - min(self.y)\n",
    "            print(f'(Lx, Ly) in Mm = ({self.Lx_Mm:.2f}, {self.Ly_Mm:.2f})\\n')\n",
    "            print(f\"NOAA\",self.NOAA)\n",
    "            print(f'year_month_day_time',self.year_month_day_time)\n",
    "            print(f\"project\",self.project)\n",
    "            print(f\"production_date\",self.production_date)\n",
    "            print(f\"version\",self.version)\n",
    "            print(f\"data_doi\",self.data_doi)\n",
    "            print(f\"http_link\",self.http_link)\n",
    "            print(f\"Distributor\",self.Distributor)\n",
    "\n",
    "      def plot(self):\n",
    "            xs=12.0\n",
    "            ys=4.0\n",
    "\n",
    "            xmin=min(self.x)\n",
    "            xmax=max(self.x)\n",
    "            ymin=min(self.y)\n",
    "            ymax=max(self.y)\n",
    "\n",
    "            plt.close()\n",
    "            fig=plt.figure(figsize=(xs,ys))\n",
    "            ax1=fig.add_axes((0.08,0.35,0.25,0.25*xs/ys*(ymax-ymin)/(xmax-xmin)))\n",
    "            ax2=fig.add_axes((0.4,0.35,0.25,0.25*xs/ys*(ymax-ymin)/(xmax-xmin)))\n",
    "            ax3=fig.add_axes((0.72,0.35,0.25,0.25*xs/ys*(ymax-ymin)/(xmax-xmin)))\n",
    "            cax1=fig.add_axes((0.08,0.15,0.25,0.05))\n",
    "            cax2=fig.add_axes((0.4,0.15,0.25,0.05))\n",
    "            cax3=fig.add_axes((0.72,0.15,0.25,0.05))\n",
    "            \n",
    "            vmin=-3000.0 \n",
    "            vmax=3000.0\n",
    "            \n",
    "            im1=ax1.pcolormesh(self.x,self.y,self.bx[:,:,0].transpose(),vmin=vmin,vmax=vmax,cmap='gist_gray',shading='auto')\n",
    "            im2=ax2.pcolormesh(self.x,self.y,self.by[:,:,0].transpose(),vmin=vmin,vmax=vmax,cmap='gist_gray',shading='auto')\n",
    "            im3=ax3.pcolormesh(self.x,self.y,self.bz[:,:,0].transpose(),vmin=vmin,vmax=vmax,cmap='gist_gray',shading='auto')\n",
    "\n",
    "            cbar1=plt.colorbar(im1,cax=cax1,orientation='horizontal')\n",
    "            cbar2=plt.colorbar(im2,cax=cax2,orientation='horizontal')\n",
    "            cbar3=plt.colorbar(im3,cax=cax3,orientation='horizontal')\n",
    "            \n",
    "            ax1.set_title('Bx [G]')\n",
    "            ax1.set_xlabel('x [Mm]')\n",
    "            ax1.set_ylabel('y [Mm]')\n",
    "            \n",
    "            ax2.set_title('By [G]')\n",
    "            ax2.set_xlabel('x [Mm]')\n",
    "            ax2.set_ylabel('y [Mm]')\n",
    "            \n",
    "            ax3.set_title('Bz [G]')\n",
    "            ax3.set_xlabel('x [Mm]')\n",
    "            ax3.set_ylabel('y [Mm]')\n",
    "            \n",
    "            #plt.pause(0.1)\n",
    "            # plt.savefig('./B.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (westward)  unit: Mm\n",
      "y (northward)  unit: Mm\n",
      "z (out ot photosphere)  unit: Mm\n",
      "Bx (westward)  unit: G\n",
      "By (northward)  unit: G\n",
      "Bz (out of photosphere)  unit: G\n",
      "Bx_pot (westward)  unit: G\n",
      "By_pot (northward)  unit: G\n",
      "Bz_pot (out of photosphere)  unit: G\n"
     ]
    }
   ],
   "source": [
    "# nc_filepath = '/home/tensor/workspace/pinn_study/_data/12673_20170905_202400/12673_20170905_202400.nc'\n",
    "nc_filepath = '/Users/mgjeon/Workspace/pinn_study/_data/12673_20170905_202400.nc'\n",
    "data = nlfff(nc_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lx: 250.724242944\n",
      "Ly: 163.262298624\n",
      "Lz: 163.262298624\n",
      "Nx: 513\n",
      "Ny: 257\n",
      "Nz: 257\n",
      "dx: 0.48969578700000227\n",
      "dy: 0.6377433539999942\n",
      "dz: 0.637743354\n",
      "dV: 1.9916739845722572e+23\n",
      "(Nx-1)*dx: 250.72424294400116\n",
      "(Ny-1)*dy: 163.2622986239985\n",
      "(Nz-1)*dz: 163.262298624\n"
     ]
    }
   ],
   "source": [
    "Lx = max(data.x) - min(data.x)\n",
    "Ly = max(data.y) - min(data.y)\n",
    "Lz = max(data.z) - min(data.z)\n",
    "\n",
    "Nx = len(data.x)\n",
    "Ny = len(data.y)\n",
    "Nz = len(data.z)\n",
    "\n",
    "dx = np.diff(data.x)[0]\n",
    "dy = np.diff(data.y)[0]\n",
    "dz = np.diff(data.z)[0]\n",
    "\n",
    "print(f'Lx: {Lx}')\n",
    "print(f'Ly: {Ly}')\n",
    "print(f'Lz: {Lz}')\n",
    "\n",
    "print(f'Nx: {Nx}')\n",
    "print(f'Ny: {Ny}')\n",
    "print(f'Nz: {Nz}')\n",
    "\n",
    "# Mm per pixel\n",
    "print(f'dx: {dx}')\n",
    "print(f'dy: {dy}')\n",
    "print(f'dz: {dz}')\n",
    "\n",
    "# Mm^3 per pixel^3\n",
    "dV = dx*dy*dz \n",
    "# cm^3 per pixel^3\n",
    "dV = dx*dy*dz*(1e8**3)\n",
    "print(f'dV: {dV}')\n",
    "\n",
    "# (Nx-1) : # of pixels in x-direction\n",
    "# (Nx-1)*dx : Mm in x-direction\n",
    "print(f'(Nx-1)*dx: {(Nx-1)*dx}')\n",
    "print(f'(Ny-1)*dy: {(Ny-1)*dy}')\n",
    "print(f'(Nz-1)*dz: {(Nz-1)*dz}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "# JSON\n",
    "base_path = '/Users/mgjeon/Workspace/pinn_study/_run/isee_spinn'\n",
    "meta_path = None\n",
    "\n",
    "# d_slice = None\n",
    "bin = 1\n",
    "\n",
    "height = 257\n",
    "spatial_norm = 320\n",
    "b_norm = 2500\n",
    "\n",
    "meta_info = None\n",
    "dim = 256\n",
    "positional_encoding = False\n",
    "use_potential_boundary = True\n",
    "potential_strides = 1\n",
    "use_vector_potential = False\n",
    "lambda_div = 1e-1\n",
    "lambda_ff = 1e-1\n",
    "decay_iterations = 50000\n",
    "device = None\n",
    "work_directory = None\n",
    "\n",
    "total_iterations = 100000\n",
    "batch_size = 10000\n",
    "log_interval = 10000\n",
    "validation_interval = 10000\n",
    "num_workers = 4\n",
    "\n",
    "# init logging\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)\n",
    "for hdlr in log.handlers[:]:  # remove all old handlers\n",
    "    log.removeHandler(hdlr)\n",
    "log.addHandler(logging.FileHandler(\"{0}/{1}.log\".format(base_path, \"info_log\")))  # set the new file handler\n",
    "log.addHandler(logging.StreamHandler())  # set the new console handler\n",
    "\n",
    "start_time = datetime.now()\n",
    "base_path = os.path.join(base_path, 'dim%d_bin%d_pf%s_ld%s_lf%s' % (\n",
    "        dim, bin, str(use_potential_boundary), lambda_div, lambda_ff))\n",
    "\n",
    "b_cube = np.array(np.stack([data.bx[:, :, 0], data.by[:, :, 0], data.bz[:, :, 0]], axis=-1))\n",
    "meta_info = None\n",
    "\n",
    "# if d_slice is not None:\n",
    "#     b_cube = b_cube[d_slice[0]:d_slice[1], d_slice[2]:d_slice[3]]\n",
    "\n",
    "# if bin > 1:\n",
    "#     b_cube = block_reduce(b_cube, (bin, bin, 1), np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_coords = np.stack(np.mgrid[:b_cube.shape[0], :b_cube.shape[1], :1], -1)\n",
    "mf_coords = mf_coords.reshape((-1, 3))\n",
    "mf_values = b_cube.reshape((-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotentialModel(nn.Module):\n",
    "\n",
    "    def __init__(self, b_n, r_p):\n",
    "        super().__init__()\n",
    "        self.register_buffer('b_n', b_n)\n",
    "        self.register_buffer('r_p', r_p)\n",
    "        c = np.zeros((1, 3))\n",
    "        c[:, 2] = (1 / np.sqrt(2 * np.pi))\n",
    "        c = torch.tensor(c, dtype=torch.float32, )\n",
    "        self.register_buffer('c', c)\n",
    "\n",
    "    def forward(self, coord):\n",
    "        v1 = self.b_n[:, None]\n",
    "        v2 = 2 * np.pi * ((-self.r_p[:, None] + coord[None, :] + self.c[None]) ** 2).sum(-1) ** 0.5\n",
    "        potential = torch.sum(v1 / v2, dim=0)\n",
    "        return potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential Boundary:   0%|          | 0/159 [01:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[39mfor\u001b[39;00m coord, \u001b[39min\u001b[39;00m tqdm(DataLoader(TensorDataset(flat_coords), batch_size\u001b[39m=\u001b[39mbatch_size, num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m),\n\u001b[1;32m     26\u001b[0m                         desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPotential Boundary\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     27\u001b[0m         coord \u001b[39m=\u001b[39m coord\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 28\u001b[0m         p_batch \u001b[39m=\u001b[39m model(coord)\n\u001b[1;32m     29\u001b[0m         potential \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [p_batch\u001b[39m.\u001b[39mcpu()]\n\u001b[1;32m     31\u001b[0m potential \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(potential)\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:153\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mDataParallel.forward\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    152\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids:\n\u001b[0;32m--> 153\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    155\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m chain(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mparameters(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mbuffers()):\n\u001b[1;32m    156\u001b[0m         \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mdevice \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mPotentialModel.forward\u001b[0;34m(self, coord)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, coord):\n\u001b[1;32m     13\u001b[0m     v1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_n[:, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m---> 14\u001b[0m     v2 \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mpi \u001b[39m*\u001b[39m ((\u001b[39m-\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mr_p[:, \u001b[39mNone\u001b[39;49;00m] \u001b[39m+\u001b[39;49m coord[\u001b[39mNone\u001b[39;49;00m, :] \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc[\u001b[39mNone\u001b[39;49;00m]) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m     15\u001b[0m     potential \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(v1 \u001b[39m/\u001b[39m v2, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m potential\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pf_batch_size = int(1024 * 512 ** 2 / np.prod(b_cube.shape[:2]))\n",
    "\n",
    "b_n = b_cube[:, :, 2]\n",
    "cube_shape = (*b_n.shape, height)\n",
    "b_n = b_n.reshape((-1)).astype(np.float32)\n",
    "coords = [np.stack(np.mgrid[:cube_shape[0], :cube_shape[1], cube_shape[2] - 2:cube_shape[2] + 1], -1),\n",
    "            np.stack(np.mgrid[:cube_shape[0], -1:2, :cube_shape[2]], -1),\n",
    "            np.stack(np.mgrid[:cube_shape[0], cube_shape[1] - 2:cube_shape[1] + 1, :cube_shape[2]], -1),\n",
    "            np.stack(np.mgrid[-1:2, :cube_shape[1], :cube_shape[2]], -1),\n",
    "            np.stack(np.mgrid[cube_shape[0] - 2:cube_shape[0] + 1, :cube_shape[1], :cube_shape[2]], -1), ]\n",
    "coords_shape = [c.shape[:-1] for c in coords]\n",
    "flat_coords = np.concatenate([c.reshape(((-1, 3))) for c in coords])\n",
    "\n",
    "r_p = np.stack(np.mgrid[:cube_shape[0], :cube_shape[1], :1], -1).reshape((-1, 3))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "with torch.no_grad():\n",
    "    b_n = torch.tensor(b_n, dtype=torch.float32, )\n",
    "    r_p = torch.tensor(r_p, dtype=torch.float32, )\n",
    "    model = nn.DataParallel(PotentialModel(b_n, r_p, )).to(device)\n",
    "\n",
    "    flat_coords = torch.tensor(flat_coords, dtype=torch.float32, )\n",
    "\n",
    "    potential = []\n",
    "    for coord, in tqdm(DataLoader(TensorDataset(flat_coords), batch_size=batch_size, num_workers=2),\n",
    "                        desc='Potential Boundary'):\n",
    "        coord = coord.to(device)\n",
    "        p_batch = model(coord)\n",
    "        potential += [p_batch.cpu()]\n",
    "\n",
    "potential = torch.cat(potential).numpy()\n",
    "idx = 0\n",
    "fields = []\n",
    "for s in coords_shape:\n",
    "    p = potential[idx:idx + np.prod(s)].reshape(s)\n",
    "    b = - 1 * np.stack(np.gradient(p, axis=[0, 1, 2], edge_order=2), axis=-1)\n",
    "    fields += [b]\n",
    "    idx += np.prod(s)\n",
    "\n",
    "fields = [fields[0][:, :, 1].reshape((-1, 3)),\n",
    "            fields[1][:, 1, :].reshape((-1, 3)), fields[2][:, 1, :].reshape((-1, 3)),\n",
    "            fields[3][1, :, :].reshape((-1, 3)), fields[4][1, :, :].reshape((-1, 3))]\n",
    "coords = [coords[0][:, :, 1].reshape((-1, 3)),\n",
    "            coords[1][:, 1, :].reshape((-1, 3)), coords[2][:, 1, :].reshape((-1, 3)),\n",
    "            coords[3][1, :, :].reshape((-1, 3)), coords[4][1, :, :].reshape((-1, 3))]\n",
    "\n",
    "pf_coords, pf_values = np.concatenate(coords), np.concatenate(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.stack(np.mgrid[:cube_shape[0]:1, :cube_shape[1]:1, :cube_shape[2]:1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 257, 257, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 257, 257, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
