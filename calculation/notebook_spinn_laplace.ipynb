{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from jax import jvp, value_and_grad\n",
    "from flax import linen as nn\n",
    "from typing import Sequence\n",
    "from functools import partial\n",
    "\n",
    "a = 9.\n",
    "b = 3.\n",
    "\n",
    "class SPINN(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, y):\n",
    "        inputs, outputs = [x, y], []\n",
    "        init = nn.initializers.glorot_normal()\n",
    "        for X in inputs:\n",
    "            for fs in self.features[:-1]:\n",
    "                X = nn.Dense(fs, kernel_init=init)(X)\n",
    "                X = nn.activation.tanh(X)\n",
    "            X = nn.Dense(self.features[-1], kernel_init=init)(X)\n",
    "            outputs += [jnp.transpose(X, (1,0))]\n",
    "        xy = jnp.einsum('fx, fy->xy', outputs[0], outputs[1])\n",
    "        return xy\n",
    "    \n",
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def update_model(optim, gradient, params, state):\n",
    "    updates, state = optim.update(gradient, state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, state\n",
    "\n",
    "def train_data_generator(nc, key):\n",
    "    keys = jax.random.split(key, 2)\n",
    "\n",
    "    xc = jax.random.uniform(keys[0], (nc, 1), minval=0., maxval=a)\n",
    "    yc = jax.random.uniform(keys[1], (nc, 1), minval=0., maxval=b)\n",
    "    xc_m, yc_m = jnp.meshgrid(xc.ravel(), yc.ravel(), indexing='ij')\n",
    "    uc = jnp.zeros(xc_m.shape)\n",
    "    \n",
    "    xb = [jnp.array([[0.]]),\n",
    "          jnp.array([[a]]),\n",
    "          xc,\n",
    "          xc]\n",
    "    yb = [yc,\n",
    "          yc,\n",
    "          jnp.array([[0.]]),\n",
    "          jnp.array([[b]])]\n",
    "    xb_m0, yb_m0 = jnp.meshgrid(xb[0].ravel(), yb[0].ravel(), indexing='ij')\n",
    "    xb_m1, yb_m1 = jnp.meshgrid(xb[1].ravel(), yb[1].ravel(), indexing='ij')\n",
    "    xb_m2, yb_m2 = jnp.meshgrid(xb[2].ravel(), yb[2].ravel(), indexing='ij')\n",
    "    xb_m3, yb_m3 = jnp.meshgrid(xb[3].ravel(), yb[3].ravel(), indexing='ij')\n",
    "\n",
    "    ub = []\n",
    "    ub += [jnp.zeros(xb_m0.shape)]\n",
    "    ub += [jnp.sinh(yb_m1)/jnp.sinh(b)]\n",
    "    ub += [jnp.zeros(xb_m2.shape)]\n",
    "    ub += [jnp.sin(xb_m3)/jnp.sin(a)]\n",
    "\n",
    "    return xc, yc, uc, xb, yb, ub\n",
    "\n",
    "def _exact_solution(x, y):\n",
    "    return (jnp.sin(x) * jnp.sinh(y)) / (jnp.sin(a) * jnp.sinh(b))\n",
    "\n",
    "def test_data_generator(nc_test):\n",
    "    xt = jnp.linspace(0, a, nc_test).reshape(-1, 1)\n",
    "    yt = jnp.linspace(0, b, nc_test).reshape(-1, 1)\n",
    "    xt = jax.lax.stop_gradient(xt)\n",
    "    yt = jax.lax.stop_gradient(yt)\n",
    "    \n",
    "    xt_m, yt_m = jnp.meshgrid(xt.ravel(), yt.ravel(), indexing='ij')\n",
    "    u_gt = _exact_solution(xt_m, yt_m)\n",
    "    return xt, yt, xt_m, yt_m, u_gt \n",
    "\n",
    "def relative_l2(u, u_gt):\n",
    "    return jnp.linalg.norm(u-u_gt) / jnp.linalg.norm(u_gt)\n",
    "\n",
    "def plot_u(xt_m, yt_m, u, i=0):\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xt_m, yt_m, c=u, cmap='viridis')\n",
    "    fig.savefig(f'figures/scatterA{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xt_m, yt_m, c=u, cmap='viridis')\n",
    "    fig.savefig(f'figures/scatterB{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xt_m, yt_m, u)\n",
    "    fig.savefig(f'figures/scatterC{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.contourf(xt_m, yt_m, u, cmap='viridis')\n",
    "    fig.savefig(f'figures/contourf{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(xt_m, yt_m, u, cmap='viridis')\n",
    "    fig.savefig(f'figures/plot_surface{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def hvp_fwdfwd(f, primals, tangents):\n",
    "    g = lambda primals: jvp(f, (primals,), tangents)[1]\n",
    "    primals_out, tangents_out = jvp(g, primals, tangents)\n",
    "    return tangents_out\n",
    "\n",
    "def loss_laplace(apply_fn, *train_data):\n",
    "    def residual_loss(params, x, y, source_term):\n",
    "        u = apply_fn(params, x, y)\n",
    "        v = jnp.ones(x.shape)\n",
    "        uxx = hvp_fwdfwd(lambda x: apply_fn(params, x, y), (x,), (v,))\n",
    "        uyy = hvp_fwdfwd(lambda y: apply_fn(params, x, y), (y,), (v,))\n",
    "        return jnp.mean((uxx + uyy - source_term)**2)\n",
    "    \n",
    "    def boundary_loss(params, x, y, u):\n",
    "        loss = 0.\n",
    "        for i in range(4):\n",
    "            loss += (1/4.) * jnp.mean((apply_fn(params, x[i], y[i]) - u[i])**2)\n",
    "        return loss\n",
    "    \n",
    "    xc, yc, uc, xb, yb, ub = train_data\n",
    "\n",
    "    fn = lambda params: residual_loss(params, xc, yc, uc) + \\\n",
    "                        boundary_loss(params, xb, yb, ub)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = 64\n",
    "NB = 64\n",
    "NC_TEST = 100\n",
    "SEED = 777\n",
    "LR = 1e-3\n",
    "EPOCHS = 50000\n",
    "N_LAYERS = 4\n",
    "FEATURES = 4\n",
    "LOG_ITER = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER):\n",
    "    key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    feat_sizes = tuple(FEATURES for _ in range(N_LAYERS))\n",
    "    model = SPINN(feat_sizes)\n",
    "    params = model.init(subkey, jnp.ones((NC, 1)), jnp.ones((NC, 1)))\n",
    "\n",
    "    xt, yt, xt_m, yt_m, u_gt = test_data_generator(NC_TEST)\n",
    "\n",
    "    apply_fn = jax.jit(model.apply)\n",
    "\n",
    "    print('Solution:')\n",
    "    u = apply_fn(params, xt, yt)\n",
    "    plot_u(xt_m, yt_m, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER):\n",
    "    key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    feat_sizes = tuple(FEATURES for _ in range(N_LAYERS))\n",
    "    model = SPINN(feat_sizes)\n",
    "    params = model.init(subkey, jnp.ones((NC, 1)), jnp.ones((NC, 1)))\n",
    "\n",
    "    optim = optax.adam(LR)\n",
    "    state = optim.init(params)\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    train_data = train_data_generator(NC, subkey)\n",
    "    xt, yt, xt_m, yt_m, u_gt = test_data_generator(NC_TEST)\n",
    "\n",
    "    apply_fn = jax.jit(model.apply)\n",
    "    loss_fn = loss_laplace(apply_fn, *train_data)\n",
    "    @jax.jit\n",
    "    def train_one_step(params, state):\n",
    "        # compute loss and gradient\n",
    "        loss, gradient = value_and_grad(loss_fn)(params)\n",
    "        # update state\n",
    "        params, state = update_model(optim, gradient, params, state)\n",
    "        return loss, params, state\n",
    "\n",
    "    start = time.time()\n",
    "    for e in trange(1, EPOCHS+1):\n",
    "        # single run\n",
    "        loss, params, state = train_one_step(params, state)\n",
    "        # if e % 100 == 0 and e < 1000:\n",
    "            # u = apply_fn(params, xt, yt)\n",
    "            # plot_u(xt_m, yt_m, u, e)\n",
    "        if e % LOG_ITER == 0:\n",
    "            u = apply_fn(params, xt, yt)\n",
    "            error = relative_l2(u, u_gt)\n",
    "            print(f'Epoch: {e}/{EPOCHS} --> loss: {loss:.8f}, error: {error:.8f}')\n",
    "    end = time.time()\n",
    "    print(f'Runtime: {((end-start)/EPOCHS*1000):.2f} ms/iter.')\n",
    "\n",
    "    print('Solution:')\n",
    "    u = apply_fn(params, xt, yt)\n",
    "    plot_u(xt_m, yt_m, u, 1)\n",
    "    plot_u(xt_m, yt_m, u-u_gt, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:\n"
     ]
    }
   ],
   "source": [
    "before(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26167/50000 [00:04<00:03, 7211.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25000/50000 --> loss: 0.00002915, error: 0.00179005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:07<00:00, 6684.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50000/50000 --> loss: 0.00001840, error: 0.00118339\n",
      "Runtime: 0.15 ms/iter.\n",
      "Solution:\n"
     ]
    }
   ],
   "source": [
    "main(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
