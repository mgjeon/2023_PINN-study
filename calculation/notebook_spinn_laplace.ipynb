{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from jax import jvp, value_and_grad\n",
    "from flax import linen as nn\n",
    "from typing import Sequence\n",
    "from functools import partial\n",
    "\n",
    "a = 9.\n",
    "b = 3.\n",
    "\n",
    "class SPINN(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, y):\n",
    "        inputs, outputs = [x, y], []\n",
    "        init = nn.initializers.glorot_normal()\n",
    "        for X in inputs:\n",
    "            for fs in self.features[:-1]:\n",
    "                X = nn.Dense(fs, kernel_init=init)(X)\n",
    "                X = nn.activation.tanh(X)\n",
    "            X = nn.Dense(self.features[-1], kernel_init=init)(X)\n",
    "            outputs += [jnp.transpose(X, (1,0))]\n",
    "        xy = jnp.einsum('fx, fy->xy', outputs[0], outputs[1])\n",
    "        return xy\n",
    "    \n",
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def update_model(optim, gradient, params, state):\n",
    "    updates, state = optim.update(gradient, state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, state\n",
    "\n",
    "def train_data_generator(nc, key):\n",
    "    keys = jax.random.split(key, 2)\n",
    "\n",
    "    xc = jax.random.uniform(keys[0], (nc, 1), minval=0., maxval=a)\n",
    "    yc = jax.random.uniform(keys[1], (nc, 1), minval=0., maxval=b)\n",
    "    xc_m, yc_m = jnp.meshgrid(xc.ravel(), yc.ravel(), indexing='ij')\n",
    "    uc = jnp.zeros(xc_m.shape)\n",
    "    \n",
    "    xb = [jnp.array([[0.]]),\n",
    "          jnp.array([[a]]),\n",
    "          xc,\n",
    "          xc]\n",
    "    yb = [yc,\n",
    "          yc,\n",
    "          jnp.array([[0.]]),\n",
    "          jnp.array([[b]])]\n",
    "    xb_m0, yb_m0 = jnp.meshgrid(xb[0].ravel(), yb[0].ravel(), indexing='ij')\n",
    "    xb_m1, yb_m1 = jnp.meshgrid(xb[1].ravel(), yb[1].ravel(), indexing='ij')\n",
    "    xb_m2, yb_m2 = jnp.meshgrid(xb[2].ravel(), yb[2].ravel(), indexing='ij')\n",
    "    xb_m3, yb_m3 = jnp.meshgrid(xb[3].ravel(), yb[3].ravel(), indexing='ij')\n",
    "\n",
    "    ub = []\n",
    "    ub += [jnp.zeros(xb_m0.shape)]\n",
    "    ub += [jnp.sinh(yb_m1)/jnp.sinh(b)]\n",
    "    ub += [jnp.zeros(xb_m2.shape)]\n",
    "    ub += [jnp.sin(xb_m3)/jnp.sin(a)]\n",
    "\n",
    "    return xc, yc, uc, xb, yb, ub\n",
    "\n",
    "def _exact_solution(x, y):\n",
    "    return (jnp.sin(x) * jnp.sinh(y)) / (jnp.sin(a) * jnp.sinh(b))\n",
    "\n",
    "def test_data_generator(nc_test):\n",
    "    xt = jnp.linspace(0, a, nc_test).reshape(-1, 1)\n",
    "    yt = jnp.linspace(0, b, nc_test).reshape(-1, 1)\n",
    "    xt = jax.lax.stop_gradient(xt)\n",
    "    yt = jax.lax.stop_gradient(yt)\n",
    "    \n",
    "    xt_m, yt_m = jnp.meshgrid(xt.ravel(), yt.ravel(), indexing='ij')\n",
    "    u_gt = _exact_solution(xt_m, yt_m)\n",
    "    return xt, yt, xt_m, yt_m, u_gt \n",
    "\n",
    "def relative_l2(u, u_gt):\n",
    "    return jnp.linalg.norm(u-u_gt) / jnp.linalg.norm(u_gt)\n",
    "\n",
    "def plot_u(xt_m, yt_m, u, i=0):\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xt_m, yt_m, c=u, cmap='viridis')\n",
    "    fig.savefig(f'figures/scatterA{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xt_m, yt_m, c=u, cmap='viridis')\n",
    "    fig.savefig(f'figures/scatterB{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xt_m, yt_m, u)\n",
    "    fig.savefig(f'figures/scatterC{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.contourf(xt_m, yt_m, u, cmap='viridis')\n",
    "    fig.savefig(f'figures/contourf{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(xt_m, yt_m, u, cmap='viridis')\n",
    "    fig.savefig(f'figures/plot_surface{i}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def hvp_fwdfwd(f, primals, tangents):\n",
    "    g = lambda primals: jvp(f, (primals,), tangents)[1]\n",
    "    primals_out, tangents_out = jvp(g, primals, tangents)\n",
    "    return tangents_out\n",
    "\n",
    "def loss_laplace(apply_fn, *train_data):\n",
    "    def residual_loss(params, x, y, source_term):\n",
    "        u = apply_fn(params, x, y)\n",
    "        v = jnp.ones(x.shape)\n",
    "        uxx = hvp_fwdfwd(lambda x: apply_fn(params, x, y), (x,), (v,))\n",
    "        uyy = hvp_fwdfwd(lambda y: apply_fn(params, x, y), (y,), (v,))\n",
    "        return jnp.mean((uxx + uyy - source_term)**2)\n",
    "    \n",
    "    def boundary_loss(params, x, y, u):\n",
    "        loss = 0.\n",
    "        for i in range(4):\n",
    "            loss += (1/4.) * jnp.mean((apply_fn(params, x[i], y[i]) - u[i])**2)\n",
    "        return loss\n",
    "    \n",
    "    xc, yc, uc, xb, yb, ub = train_data\n",
    "\n",
    "    fn = lambda params: residual_loss(params, xc, yc, uc) + \\\n",
    "                        boundary_loss(params, xb, yb, ub)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = 64\n",
    "NB = 64\n",
    "NC_TEST = 100\n",
    "SEED = 777\n",
    "LR = 1e-3\n",
    "EPOCHS = 50000\n",
    "N_LAYERS = 4\n",
    "FEATURES = 4\n",
    "LOG_ITER = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER):\n",
    "    key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    feat_sizes = tuple(FEATURES for _ in range(N_LAYERS))\n",
    "    model = SPINN(feat_sizes)\n",
    "    params = model.init(subkey, jnp.ones((NC, 1)), jnp.ones((NC, 1)))\n",
    "\n",
    "    xt, yt, xt_m, yt_m, u_gt = test_data_generator(NC_TEST)\n",
    "\n",
    "    apply_fn = jax.jit(model.apply)\n",
    "\n",
    "    print('Solution:')\n",
    "    u = apply_fn(params, xt, yt)\n",
    "    plot_u(xt_m, yt_m, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER):\n",
    "    key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    feat_sizes = tuple(FEATURES for _ in range(N_LAYERS))\n",
    "    model = SPINN(feat_sizes)\n",
    "    params = model.init(subkey, jnp.ones((NC, 1)), jnp.ones((NC, 1)))\n",
    "\n",
    "    optim = optax.adam(LR)\n",
    "    state = optim.init(params)\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    train_data = train_data_generator(NC, subkey)\n",
    "    xt, yt, xt_m, yt_m, u_gt = test_data_generator(NC_TEST)\n",
    "\n",
    "    apply_fn = jax.jit(model.apply)\n",
    "    loss_fn = loss_laplace(apply_fn, *train_data)\n",
    "    @jax.jit\n",
    "    def train_one_step(params, state):\n",
    "        # compute loss and gradient\n",
    "        loss, gradient = value_and_grad(loss_fn)(params)\n",
    "        # update state\n",
    "        params, state = update_model(optim, gradient, params, state)\n",
    "        return loss, params, state\n",
    "\n",
    "    start = time.time()\n",
    "    for e in trange(1, EPOCHS+1):\n",
    "        # single run\n",
    "        loss, params, state = train_one_step(params, state)\n",
    "        # if e % 100 == 0 and e < 1000:\n",
    "            # u = apply_fn(params, xt, yt)\n",
    "            # plot_u(xt_m, yt_m, u, e)\n",
    "        if e % LOG_ITER == 0:\n",
    "            u = apply_fn(params, xt, yt)\n",
    "            error = relative_l2(u, u_gt)\n",
    "            print(f'Epoch: {e}/{EPOCHS} --> loss: {loss:.8f}, error: {error:.8f}')\n",
    "    end = time.time()\n",
    "    print(f'Runtime: {((end-start)/EPOCHS*1000):.2f} ms/iter.')\n",
    "\n",
    "    print('Solution:')\n",
    "    u = apply_fn(params, xt, yt)\n",
    "    plot_u(xt_m, yt_m, u, 1)\n",
    "    plot_u(xt_m, yt_m, u-u_gt, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 10:06:06.760527: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.6.0 but source was compiled with: 8.8.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m before(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER)\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36mbefore\u001b[0;34m(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbefore\u001b[39m(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER):\n\u001b[0;32m----> 2\u001b[0m     key \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mPRNGKey(SEED)\n\u001b[1;32m      4\u001b[0m     key, subkey \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39msplit(key, \u001b[39m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m     feat_sizes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(FEATURES \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_LAYERS))\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/random.py:136\u001b[0m, in \u001b[0;36mPRNGKey\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(seed):\n\u001b[1;32m    134\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPRNGKey accepts a scalar seed, but was given an array of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(seed)\u001b[39m}\u001b[39;00m\u001b[39m != (). Use jax.vmap for batching\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m key \u001b[39m=\u001b[39m prng\u001b[39m.\u001b[39;49mseed_with_impl(impl, seed)\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m _return_prng_keys(\u001b[39mTrue\u001b[39;00m, key)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/prng.py:270\u001b[0m, in \u001b[0;36mseed_with_impl\u001b[0;34m(impl, seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mseed_with_impl\u001b[39m(impl: PRNGImpl, seed: Union[\u001b[39mint\u001b[39m, Array]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PRNGKeyArray:\n\u001b[0;32m--> 270\u001b[0m   \u001b[39mreturn\u001b[39;00m random_seed(seed, impl\u001b[39m=\u001b[39;49mimpl)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/prng.py:561\u001b[0m, in \u001b[0;36mrandom_seed\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m   seeds_arr \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(seeds)\n\u001b[0;32m--> 561\u001b[0m \u001b[39mreturn\u001b[39;00m random_seed_p\u001b[39m.\u001b[39;49mbind(seeds_arr, impl\u001b[39m=\u001b[39;49mimpl)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/core.py:360\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    358\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    359\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 360\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    364\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/core.py:817\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 817\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/prng.py:573\u001b[0m, in \u001b[0;36mrandom_seed_impl\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[39m@random_seed_p\u001b[39m\u001b[39m.\u001b[39mdef_impl\n\u001b[1;32m    572\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_seed_impl\u001b[39m(seeds, \u001b[39m*\u001b[39m, impl):\n\u001b[0;32m--> 573\u001b[0m   base_arr \u001b[39m=\u001b[39m random_seed_impl_base(seeds, impl\u001b[39m=\u001b[39;49mimpl)\n\u001b[1;32m    574\u001b[0m   \u001b[39mreturn\u001b[39;00m PRNGKeyArray(impl, base_arr)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/prng.py:578\u001b[0m, in \u001b[0;36mrandom_seed_impl_base\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_seed_impl_base\u001b[39m(seeds, \u001b[39m*\u001b[39m, impl):\n\u001b[1;32m    577\u001b[0m   seed \u001b[39m=\u001b[39m iterated_vmap_unary(seeds\u001b[39m.\u001b[39mndim, impl\u001b[39m.\u001b[39mseed)\n\u001b[0;32m--> 578\u001b[0m   \u001b[39mreturn\u001b[39;00m seed(seeds)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/prng.py:813\u001b[0m, in \u001b[0;36mthreefry_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    810\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPRNG key seed must be an integer; got \u001b[39m\u001b[39m{\u001b[39;00mseed\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    811\u001b[0m convert \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m k: lax\u001b[39m.\u001b[39mreshape(lax\u001b[39m.\u001b[39mconvert_element_type(k, np\u001b[39m.\u001b[39muint32), [\u001b[39m1\u001b[39m])\n\u001b[1;32m    812\u001b[0m k1 \u001b[39m=\u001b[39m convert(\n\u001b[0;32m--> 813\u001b[0m     lax\u001b[39m.\u001b[39;49mshift_right_logical(seed, lax_internal\u001b[39m.\u001b[39;49m_const(seed, \u001b[39m32\u001b[39;49m)))\n\u001b[1;32m    814\u001b[0m \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mnumpy_dtype_promotion(\u001b[39m'\u001b[39m\u001b[39mstandard\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    815\u001b[0m   \u001b[39m# TODO(jakevdp): in X64 mode, this can generate 64-bit computations for 32-bit\u001b[39;00m\n\u001b[1;32m    816\u001b[0m   \u001b[39m# inputs. We should avoid this.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m   k2 \u001b[39m=\u001b[39m convert(jnp\u001b[39m.\u001b[39mbitwise_and(seed, np\u001b[39m.\u001b[39muint32(\u001b[39m0xFFFFFFFF\u001b[39m)))\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/lax/lax.py:458\u001b[0m, in \u001b[0;36mshift_right_logical\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshift_right_logical\u001b[39m(x: ArrayLike, y: ArrayLike) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[1;32m    457\u001b[0m \u001b[39m  \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Elementwise logical right shift: :math:`x \\gg y`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m shift_right_logical_p\u001b[39m.\u001b[39;49mbind(x, y)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/core.py:360\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    358\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    359\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 360\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    364\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/core.py:817\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 817\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/dispatch.py:117\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m \u001b[39mimport\u001b[39;00m pjit\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m   compiled_fun \u001b[39m=\u001b[39m xla_primitive_callable(prim, \u001b[39m*\u001b[39;49munsafe_map(arg_spec, args),\n\u001b[1;32m    118\u001b[0m                                         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m pxla\u001b[39m.\u001b[39mDeviceAssignmentMismatchError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m   fails, \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39margs\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/util.py:253\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m   \u001b[39mreturn\u001b[39;00m cached(config\u001b[39m.\u001b[39;49m_trace_context(), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/util.py:246\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcached\u001b[39m(_, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 246\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/dispatch.py:208\u001b[0m, in \u001b[0;36mxla_primitive_callable\u001b[0;34m(prim, *arg_specs, **params)\u001b[0m\n\u001b[1;32m    206\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[39mreturn\u001b[39;00m out,\n\u001b[0;32m--> 208\u001b[0m compiled \u001b[39m=\u001b[39m _xla_callable_uncached(lu\u001b[39m.\u001b[39;49mwrap_init(prim_fun), prim\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    209\u001b[0m                                   donated_invars, \u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49marg_specs)\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prim\u001b[39m.\u001b[39mmultiple_results:\n\u001b[1;32m    211\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: compiled(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/dispatch.py:254\u001b[0m, in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    251\u001b[0m computation \u001b[39m=\u001b[39m sharded_lowering(fun, name, donated_invars, keep_unused,\n\u001b[1;32m    252\u001b[0m                                \u001b[39m*\u001b[39marg_specs, lowering_platform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    253\u001b[0m allow_prop \u001b[39m=\u001b[39m [\u001b[39mTrue\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(computation\u001b[39m.\u001b[39mcompile_args[\u001b[39m'\u001b[39m\u001b[39mglobal_out_avals\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 254\u001b[0m \u001b[39mreturn\u001b[39;00m computation\u001b[39m.\u001b[39;49mcompile(_allow_propagation_to_outputs\u001b[39m=\u001b[39;49mallow_prop)\u001b[39m.\u001b[39munsafe_call\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2816\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, _allow_propagation_to_outputs, _allow_compile_replicated)\u001b[0m\n\u001b[1;32m   2813\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m MeshExecutable\u001b[39m.\u001b[39mfrom_trivial_jaxpr(\n\u001b[1;32m   2814\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_args)\n\u001b[1;32m   2815\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2816\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m UnloadedMeshExecutable\u001b[39m.\u001b[39;49mfrom_hlo(\n\u001b[1;32m   2817\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2818\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hlo,\n\u001b[1;32m   2819\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_args,\n\u001b[1;32m   2820\u001b[0m         _allow_propagation_to_outputs\u001b[39m=\u001b[39;49m_allow_propagation_to_outputs,\n\u001b[1;32m   2821\u001b[0m         _allow_compile_replicated\u001b[39m=\u001b[39;49m_allow_compile_replicated)\n\u001b[1;32m   2822\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:3028\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(name, computation, mesh, global_in_avals, global_out_avals, in_shardings, out_shardings, spmd_lowering, tuple_args, auto_spmd_lowering, _allow_propagation_to_outputs, _allow_compile_replicated, unordered_effects, ordered_effects, host_callbacks, keepalive, kept_var_idx, backend, device_assignment, committed, pmap_nreps)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m   \u001b[39mwith\u001b[39;00m dispatch\u001b[39m.\u001b[39mlog_elapsed_time(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinished XLA compilation of \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3026\u001b[0m                                  \u001b[39m\"\u001b[39m\u001b[39min \u001b[39m\u001b[39m{elapsed_time}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3027\u001b[0m                                  event\u001b[39m=\u001b[39mdispatch\u001b[39m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 3028\u001b[0m     xla_executable \u001b[39m=\u001b[39m dispatch\u001b[39m.\u001b[39;49mcompile_or_get_cached(\n\u001b[1;32m   3029\u001b[0m         backend, computation, compile_options, host_callbacks)\n\u001b[1;32m   3031\u001b[0m   \u001b[39mif\u001b[39;00m auto_spmd_lowering:\n\u001b[1;32m   3032\u001b[0m     \u001b[39massert\u001b[39;00m mesh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/dispatch.py:526\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    522\u001b[0m     _cache_write(serialized_computation, compile_time, module_name,\n\u001b[1;32m    523\u001b[0m                  compile_options, backend, compiled, host_callbacks)\n\u001b[1;32m    524\u001b[0m     \u001b[39mreturn\u001b[39;00m compiled\n\u001b[0;32m--> 526\u001b[0m \u001b[39mreturn\u001b[39;00m backend_compile(backend, serialized_computation, compile_options,\n\u001b[1;32m    527\u001b[0m                        host_callbacks)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/jax/_src/dispatch.py:471\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options, host_callbacks)\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    467\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    468\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details."
     ]
    }
   ],
   "source": [
    "before(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26167/50000 [00:04<00:03, 7211.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25000/50000 --> loss: 0.00002915, error: 0.00179005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:07<00:00, 6684.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50000/50000 --> loss: 0.00001840, error: 0.00118339\n",
      "Runtime: 0.15 ms/iter.\n",
      "Solution:\n"
     ]
    }
   ],
   "source": [
    "main(NC, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
